{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import argv,exit\n",
    "import pandas as pd\n",
    "import json\n",
    "from  plotly.figure_factory import create_dendrogram\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from math import ceil\n",
    "from scipy.cluster.hierarchy import linkage, fcluster, cut_tree\n",
    "import multiprocessing as mp\n",
    "# from django.conf import settings\n",
    "from bokeh.plotting import figure, save\n",
    "from bokeh.embed import components\n",
    "from bokeh.models import Label, HoverTool, TapTool, CustomJS, BasicTicker, ColorBar, ColumnDataSource, LinearColorMapper, PrintfTickFormatter\n",
    "from bokeh.transform import transform\n",
    "from bokeh.events import Tap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def json_dict(path):\n",
    "    \"\"\"Converts json file to pyhton dict.\"\"\"\n",
    "    json_file=open(path)\n",
    "    json_str = json_file.read()\n",
    "    json_data = json.loads(json_str)\n",
    "    return json_data\n",
    "\n",
    "def improve_receptor_names(df_ts,compl_data):\n",
    "    \"\"\"\n",
    "    Parses the dataframe to create the data source of the plot. When defining a name for each dynamics entry: if there is any other dynamics in the \n",
    "    datadrame that is created fromt he same pdb id and ligand, all these dynamics will indicate the dynamics id\n",
    "    \"\"\"\n",
    "\n",
    "    # Simulation fullname\n",
    "    gennums = {}\n",
    "    partial_data = {}\n",
    "    for dyn_id in df_ts['Id']:\n",
    "        prot_lname = compl_data[dyn_id]['prot_lname']\n",
    "        pdb_id = compl_data[dyn_id]['pdb_id']\n",
    "        up_name = compl_data[dyn_id]['up_name']\n",
    "        recept_name=\"%s (%s)\" % (prot_lname,pdb_id) if pdb_id else \"%s (%s)\" % (prot_lname,up_name) \n",
    "        recept_name_dynid=\"%s (%s) (%s)\" % (up_name,pdb_id,dyn_id)\n",
    "\n",
    "        # In this dictionary, we will store part of the contents of compl_data for each dynamic\n",
    "        dyn_data = {}\n",
    "        dyn_data['recept_name'] = recept_name\n",
    "        dyn_data['recept_name_dynid'] = recept_name_dynid\n",
    "        for k in [\"up_name\",\"lig_sname\",\"dyn_id\",\"prot_id\",\"comp_id\",\n",
    "        \"prot_lname\",\"pdb_id\",\"lig_lname\",\"struc_fname\",\"struc_f\",\n",
    "        \"traj_fnames\",\"traj_f\",\"delta\",'class','peplig','gprot_name','gprot_chain','gpcr_chain']:\n",
    "            dyn_data[k] = compl_data[dyn_id][k]\n",
    "\n",
    "        # Dictionary for generic numberings       \n",
    "        gennums[dyn_id]=compl_data[dyn_id][\"gpcr_pdb\"]\n",
    "        gennums[dyn_id].update(compl_data[dyn_id][\"gprot_pdb\"])\n",
    "\n",
    "        partial_data[dyn_id] = dyn_data\n",
    "\n",
    "    df_ts['pdb_id'] = df_ts['Id'].apply(lambda x: partial_data[x]['pdb_id'])\n",
    "    df_ts['Name'] = df_ts['Id'].apply(lambda x: partial_data[x]['recept_name'])\n",
    "    df_ts['gprot_name'] = df_ts['Id'].apply(lambda x: partial_data[x]['gprot_name'])\n",
    "\n",
    "    return(partial_data,df_ts,gennums)\n",
    "\n",
    "def set_new_axis(df):\n",
    "    \"\"\"\n",
    "    Substitute the original Residue 3-nomenclatures single line format (1x23x23x24x24 1x23x23x24x24)\n",
    "    to 3-nomenclatures multiline format (1x\\n23\\n23\\n24\\n24\\n\\n1x\\n23\\n23\\n24\\n24)(similar to gpcrdb).\n",
    "    \"\"\"\n",
    "    def new_cell(cell):\n",
    "        cell = cell.replace(' ','\\n\\n')\n",
    "        cell = cell.replace('x','\\n')\n",
    "        cell = cell.replace('_','\\n')\n",
    "        cell = re.sub(pattern_pos1, r\"\\1x\\n\", cell)\n",
    "        cell = re.sub(pattern_pos2, r\"\\n\\n\\1x\\n\", cell)\n",
    "        return cell\n",
    "    \n",
    "    pattern_pos1 = re.compile(r\"^(\\d+)\\n\")\n",
    "    pattern_pos2 = re.compile(r\"\\n\\n(\\d+)\\n\")\n",
    "    df['Residue'] = df['Residue'].apply(new_cell)\n",
    "    return df\n",
    "\n",
    "def prepare_table(df,compl_data):\n",
    "    \"\"\"\n",
    "    This function comprises a series of operations to adapt the new tsv format to Mariona's original scripts.\n",
    "    Also returns a dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter lowfrequency\n",
    "    above_30perc = ((df > 0.30).sum(1)>1)\n",
    "    df = df[above_30perc]\n",
    "\n",
    "    # Passing frequencies from decimal to percentage\n",
    "    df= df.apply(lambda x: x*100)\n",
    "\n",
    "    # Get rid of multinidexes\n",
    "    Residues = pd.Series([a for a in df.index.map(' '.join)])\n",
    "    df['Residue'] = [a for a in df.index.map(' '.join)]\n",
    "\n",
    "    # Introduce jumplines in Generic numberings \n",
    "    df = set_new_axis(df)\n",
    "    df = df.set_index('Residue')\n",
    "\n",
    "    #Find non-standard simulations\n",
    "    standard_simulations = { dyn for (dyn,entry) in compl_data.items() if entry['is_gpcrmd_community']}\n",
    "    df_standard = df[df.columns[df.columns.isin(standard_simulations)]]\n",
    "\n",
    "    return(df,df_standard)\n",
    "\n",
    "\n",
    "def flareplot_template_gpcrgprot(df, jsonpath):\n",
    "    \"\"\"\n",
    "    Create a pseudoflareplot input json with no interactions, but with all avalible Residues.\n",
    "    It will be used later as a template to create the top interactions flareplots.  \n",
    "    \"\"\"\n",
    "    #'track' entry for json file: each track is a node (Residue) in the flareplot\n",
    "    helix_colors = {'1':\"#78C5D5\",'12':\"#5FB0BF\",\n",
    "                    '2':\"#459BA8\",'23':\"#5FAF88\",\n",
    "                    '3':\"#79C268\",'34':\"#9FCD58\",\n",
    "                    '4':\"#C5D747\",'45':\"#DDD742\",\n",
    "                    '5':\"#F5D63D\",'56':\"#F3B138\",\n",
    "                    '6':\"#F18C32\",'67':\"#ED7A6A\",\n",
    "                    '7':\"#E868A1\",'78':\"#D466A4\",\n",
    "                    '8':\"#BF63A6\",'G':'#0D2B17',\n",
    "                    'Ligand--1':'#FF5050', 'Ligand': '#FF5050'}\n",
    "    allgennums = set(item for sublist in df_raw.index for item in sublist)\n",
    "    tracks = [{\n",
    "        'trackLabel': 'Degree centrality',\n",
    "        \"trackProperties\": []\n",
    "    }]\n",
    "    trees = [{\n",
    "        'treeLabel': 'Helices',\n",
    "        'treePaths': []\n",
    "    }]\n",
    "    \n",
    "    #Add ligand\n",
    "    tracks[0]['trackProperties'].append({\n",
    "        'color' : \"#FF5050\",\n",
    "        'size' : 1.0,\n",
    "        'nodeName': 'Ligand'\n",
    "    })\n",
    "    trees[0]['treePaths'].append([1, 'Ligand'])\n",
    "    unsorted_trees = []\n",
    "    unsorted_tracks = []\n",
    "    \n",
    "    added_gennums = set()\n",
    "    for gennum in allgennums:\n",
    "\n",
    "        #Skip ligands\n",
    "        if gennum.startswith('Ligand'):\n",
    "            continue\n",
    "        \n",
    "        # If this is generic numbering of G protein, append tracks after those of GPCR\n",
    "        elif (gennum.startswith('G') or gennum.startswith('H')) and (gennum not in added_gennums):\n",
    "            \n",
    "            # gennum = gennum.replace('_',':')  \n",
    "            trackprop = {\n",
    "                'color' : helix_colors['G'],\n",
    "                'size' : 1.0,\n",
    "                'nodeName': gennum\n",
    "            }\n",
    "            trees[0]['treePaths'].append([17, gennum])\n",
    "            tracks[0]['trackProperties'].append(trackprop)\n",
    "                       \n",
    "        # If this is generic numbering multi-class of GPCR\n",
    "        else:\n",
    "            split_gennum = gennum.split('x')\n",
    "            # We'll iterate over all classes (e.g.: 1x34x32x31x35 so each pos is separated by x)\n",
    "            for gennum_p in split_gennum:\n",
    "                if split_gennum.index(gennum_p) == 0:# If first case\n",
    "                    helix = gennum_p\n",
    "                    color = helix_colors[gennum_p]\n",
    "                else:                \n",
    "                    real_gennum = helix+'x'+gennum_p\n",
    "                    if real_gennum not in added_gennums:\n",
    "                        trackprop = {\n",
    "                            'color' : color,\n",
    "                            'size' : 1.0,\n",
    "                            'nodeName': real_gennum\n",
    "                        }\n",
    "                        # For each threepath, we'll put the generic numbering of the pos preced by a sorting number\n",
    "                        # e.g. 1.1x51, 2.12x34, 3.3x64....\n",
    "                        if len(helix) == 2:\n",
    "                            newhelix = int(helix[0]) + int(helix[1])\n",
    "                        else:\n",
    "                            newhelix = int(helix)*2\n",
    "                        trees[0]['treePaths'].append([newhelix, real_gennum])\n",
    "\n",
    "                        tracks[0]['trackProperties'].append(trackprop)\n",
    "                        added_gennums.add(real_gennum)\n",
    "\n",
    "    #Sort trees\n",
    "    treePaths_sorted = sorted(list(trees[0]['treePaths']), key=lambda l: (l[0],l[1]))\n",
    "    treePaths_sorted = [ str(x[0])+\".\"+x[1] for x in treePaths_sorted ]\n",
    "    trees[0]['treePaths'] = treePaths_sorted\n",
    "    \n",
    "    #Output jsondict to store\n",
    "    jsondict = { 'trees' : trees, 'tracks' : tracks }\n",
    "    \n",
    "    # Store json file\n",
    "    with open(jsonpath, 'w') as jsonfile:\n",
    "        json.dump(jsondict, jsonfile, ensure_ascii=False, indent = 4)\n",
    "        \n",
    "\n",
    "def find_resnames_resids(row,db_dict,three_to_one):\n",
    "    \"\"\"\n",
    "    Find residue names and Ids of each interacting residue pair\n",
    "    \"\"\"\n",
    "    dynid = row['Id']\n",
    "    pos_array = row['Residue'].split('\\n\\n')\n",
    "\n",
    "    # Find Generic numbering of this Residue according to the class of its GPCR\n",
    "    number_letter = [\"0\",'A','B', 'C', 'F']\n",
    "    gclass = db_dict[dynid]['class']\n",
    "    class_index = number_letter.index(gclass)\n",
    "    residues_ary = []\n",
    "    resids_ary = []\n",
    "    for pos in pos_array:\n",
    "        # If Residue is from a GPCR, select gennum of this Residue and from there, its \n",
    "        if 'x' in pos: \n",
    "            prot = 'gpcr'\n",
    "            gennum_multiclass = pos.split('\\n')\n",
    "            gennum = gennum_multiclass[0]+gennum_multiclass[class_index]\n",
    "            \n",
    "        # If from Gprot\n",
    "        else:\n",
    "            prot = 'gprot'\n",
    "            gennum = pos.replace('_','.')\n",
    "            gennum = pos.replace('\\n','.')\n",
    "\n",
    "        # \n",
    "        if gennum in db_dict[dynid][prot+'_pdb']:\n",
    "            res_sel = db_dict[dynid][prot+'_pdb'][gennum]\n",
    "            sel_split = res_sel.split('-') \n",
    "            resid = sel_split[0]\n",
    "            resname3 = sel_split[2]\n",
    "            resname = three_to_one[resname3] if resname3 in three_to_one else 'X'\n",
    "        else:\n",
    "            resname = \"(N/A)\"\n",
    "            resid = \"(N/A)\"\n",
    "        residues_ary.append(resname+gennum)\n",
    "        resids_ary.append(resid)\n",
    "    residues = ' '.join(residues_ary)\n",
    "    resids = ' '.join(resids_ary)\n",
    "\n",
    "    # Assign values to new columns\n",
    "    row['resID'] = resids\n",
    "    row['resname_gennum'] = residues\n",
    "\n",
    "    return(row)\n",
    "    \n",
    "\n",
    "def create_csvfile(outputs_path, partial_db_dict, df):\n",
    "    \"\"\"\n",
    "    This function creates the CSV file to be donwloaded from web\n",
    "    \"\"\"\n",
    "    df_csv = df.copy()\n",
    "    df_csv.index.names = ['Interacting Residues']\n",
    "\n",
    "    #Change dynX by full name of receptor, adding the dynid if there is more than a simulation for that receptor\n",
    "    df_csv.columns = df_csv.columns.map(lambda x: partial_db_dict[x][\"recept_name_dynid\"])\n",
    "\n",
    "    #Sorting by ballesteros Id's (helixloop column) and clustering order\n",
    "    df_csv['Interacting Residues'] = df_csv.index\n",
    "    df_csv['helixloop'] = df_csv['Interacting Residues'].apply(lambda x: re.sub(r'^(\\d)x',r'\\g<1>0x',x)) \n",
    "    df_csv = df_csv.sort_values([\"helixloop\"])\n",
    "\n",
    "    #Change jumplines by 'x' to avoid formatting problems\n",
    "    def new_index(cell):\n",
    "        cell = cell.replace('\\n\\n', '  ')\n",
    "        cell = cell.replace('\\n', 'x')\n",
    "        cell = cell.replace('xx', 'x')\n",
    "        return cell\n",
    "\n",
    "    df_csv['Interacting Residues'] =  df_csv['Interacting Residues'].apply(lambda x: new_index(x))\n",
    "    df_csv.index = df_csv['Interacting Residues']\n",
    "\n",
    "    #Drop columns\n",
    "    df_csv.drop(columns = ['helixloop','Interacting Residues'], inplace = True)\n",
    "\n",
    "    #Store dataframe as csv\n",
    "    df_csv.to_csv(path_or_buf = outputs_path+\"dataframe.csv\", float_format='%.1f')\n",
    "\n",
    "def split_pos(index):\n",
    "    \"\"\"\n",
    "    Divide generic numbering interaction index according to GPCR class (for GPCRs)\n",
    "    Return Gprot gennums with '_' replaced by cannonical '.'\n",
    "    \"\"\"\n",
    "    index_split = index.name.split('\\n\\n')\n",
    "    for pos in index_split:\n",
    "        if 'x' in pos:\n",
    "            gpcr_pos = []\n",
    "            pos_x = pos.split('\\n')\n",
    "            for i in range(1,5):\n",
    "                gpcr_pos.append(pos_x[0]+pos_x[i])\n",
    "        else:\n",
    "            gprot_pos = [pos.replace('_','.')]\n",
    "    allpos = gpcr_pos+gprot_pos\n",
    "    return(allpos)\n",
    "\n",
    "def dyn_flareplots(df_o, folderpath, flare_template = False):\n",
    "    \"\"\"\n",
    "    Create top20 interaction jsons for each simulation. Needed for customized selection flareplots.\n",
    "    \"\"\"\n",
    "    if df_o.empty:\n",
    "        return\n",
    "    \n",
    "    # Folder for flareplots\n",
    "    df = df_o.copy()\n",
    "    os.makedirs(folderpath, exist_ok = True)\n",
    "    # Colors, many of them\n",
    "    colors_auld = ['#800000', '#860000', '#8c0000', '#930000', '#990000', '#9f0000', '#a60000', '#ac0000', '#b20000', '#b90000', '#bf0000', '#c50000', '#cc0000', '#d20000', '#d80000', '#df0000', '#e50000', '#eb0000', '#f20000', '#f80000', '#ff0000', '#ff0700', '#ff0e00', '#ff1500', '#ff1c00', '#ff2300', '#ff2a00', '#ff3100', '#ff3800', '#ff3f00', '#ff4600', '#ff4d00', '#ff5400', '#ff5b00', '#ff6200', '#ff6900', '#ff7000', '#ff7700', '#ff7e00', '#ff8500', '#ff8c00', '#ff9100', '#ff9700', '#ff9d00', '#ffa300', '#ffa800', '#ffae00', '#ffb400', '#ffba00', '#ffbf00', '#ffc500', '#ffcb00', '#ffd100', '#ffd600', '#ffdc00', '#ffe200', '#ffe800', '#ffed00', '#fff300', '#fff900', '#ffff00', '#f2ff00', '#e5ff00', '#d8ff00', '#ccff00', '#bfff00', '#b2ff00', '#a5ff00', '#99ff00', '#8cff00', '#7fff00', '#72ff00', '#66ff00', '#59ff00', '#4cff00', '#3fff00', '#33ff00', '#26ff00', '#19ff00', '#0cff00', '#00ff00', '#0afc0a', '#15fa15', '#1ff81f', '#2af62a', '#34f434', '#3ff13f', '#49ef49', '#54ed54', '#5eeb5e', '#69e969', '#74e674', '#7ee47e', '#89e289', '#93e093', '#9ede9e', '#a8dba8', '#b3d9b3', '#bdd7bd', '#c8d5c8', '#d3d3d3']\n",
    "    colors_ylorrd = ['#800026', '#850026', '#8a0026', '#8f0026', '#940026', '#990026', '#9e0026', '#a30026', '#a80026', '#ad0026', '#b20026', '#b70026', '#bd0026', '#c00225', '#c30424', '#c60623', '#c90822', '#cc0a21', '#d00d21', '#d30f20', '#d6111f', '#d9131e', '#dc151d', '#df171c', '#e31a1c', '#e51e1d', '#e7221e', '#e9271f', '#eb2b20', '#ed2f21', '#ef3423', '#f13824', '#f33c25', '#f54126', '#f74527', '#f94928', '#fc4e2a', '#fc532b', '#fc582d', '#fc5d2e', '#fc6330', '#fc6831', '#fc6d33', '#fc7234', '#fc7836', '#fc7d37', '#fc8239', '#fc873a', '#fd8d3c', '#fd903d', '#fd933e', '#fd9640', '#fd9941', '#fd9c42', '#fd9f44', '#fda245', '#fda546', '#fda848', '#fdab49', '#fdae4a', '#feb24c', '#feb54f', '#feb853', '#febb56', '#febf5a', '#fec25d', '#fec561', '#fec864', '#fecc68', '#fecf6b', '#fed26f', '#fed572', '#fed976', '#feda79', '#fedc7d', '#fede80', '#fedf84', '#fee187', '#fee38b', '#fee48e', '#fee692', '#fee895', '#fee999', '#feeb9c', '#ffeda0', '#ffeea3', '#fff0a7', '#fff1ab', '#fff3ae', '#fff4b2', '#fff6b6', '#fff7b9', '#fff9bd', '#fffac1', '#fffcc4', '#fffdc8', '#ffffcc']\n",
    "    colors_inferno = ['#000003', '#000004', '#000006', '#010007', '#010109', '#01010B', '#02010E', '#020210', '#030212', '#040314', '#040316', '#050418', '#06041B', '#07051D', '#08061F', '#090621', '#0A0723', '#0B0726', '#0D0828', '#0E082A', '#0F092D', '#10092F', '#120A32', '#130A34', '#140B36', '#160B39', '#170B3B', '#190B3E', '#1A0B40', '#1C0C43', '#1D0C45', '#1F0C47', '#200C4A', '#220B4C', '#240B4E', '#260B50', '#270B52', '#290B54', '#2B0A56', '#2D0A58', '#2E0A5A', '#300A5C', '#32095D', '#34095F', '#350960', '#370961', '#390962', '#3B0964', '#3C0965', '#3E0966', '#400966', '#410967', '#430A68', '#450A69', '#460A69', '#480B6A', '#4A0B6A', '#4B0C6B', '#4D0C6B', '#4F0D6C', '#500D6C', '#520E6C', '#530E6D', '#550F6D', '#570F6D', '#58106D', '#5A116D', '#5B116E', '#5D126E', '#5F126E', '#60136E', '#62146E', '#63146E', '#65156E', '#66156E', '#68166E', '#6A176E', '#6B176E', '#6D186E', '#6E186E', '#70196E', '#72196D', '#731A6D', '#751B6D', '#761B6D', '#781C6D', '#7A1C6D', '#7B1D6C', '#7D1D6C', '#7E1E6C', '#801F6B', '#811F6B', '#83206B', '#85206A', '#86216A', '#88216A', '#892269', '#8B2269', '#8D2369', '#8E2468', '#902468', '#912567', '#932567', '#952666', '#962666', '#982765', '#992864', '#9B2864', '#9C2963', '#9E2963', '#A02A62', '#A12B61', '#A32B61', '#A42C60', '#A62C5F', '#A72D5F', '#A92E5E', '#AB2E5D', '#AC2F5C', '#AE305B', '#AF315B', '#B1315A', '#B23259', '#B43358', '#B53357', '#B73456', '#B83556', '#BA3655', '#BB3754', '#BD3753', '#BE3852', '#BF3951', '#C13A50', '#C23B4F', '#C43C4E', '#C53D4D', '#C73E4C', '#C83E4B', '#C93F4A', '#CB4049', '#CC4148', '#CD4247', '#CF4446', '#D04544', '#D14643', '#D24742', '#D44841', '#D54940', '#D64A3F', '#D74B3E', '#D94D3D', '#DA4E3B', '#DB4F3A', '#DC5039', '#DD5238', '#DE5337', '#DF5436', '#E05634', '#E25733', '#E35832', '#E45A31', '#E55B30', '#E65C2E', '#E65E2D', '#E75F2C', '#E8612B', '#E9622A', '#EA6428', '#EB6527', '#EC6726', '#ED6825', '#ED6A23', '#EE6C22', '#EF6D21', '#F06F1F', '#F0701E', '#F1721D', '#F2741C', '#F2751A', '#F37719', '#F37918', '#F47A16', '#F57C15', '#F57E14', '#F68012', '#F68111', '#F78310', '#F7850E', '#F8870D', '#F8880C', '#F88A0B', '#F98C09', '#F98E08', '#F99008', '#FA9107', '#FA9306', '#FA9506', '#FA9706', '#FB9906', '#FB9B06', '#FB9D06', '#FB9E07', '#FBA007', '#FBA208', '#FBA40A', '#FBA60B', '#FBA80D', '#FBAA0E', '#FBAC10', '#FBAE12', '#FBB014', '#FBB116', '#FBB318', '#FBB51A', '#FBB71C', '#FBB91E', '#FABB21', '#FABD23', '#FABF25', '#FAC128', '#F9C32A', '#F9C52C', '#F9C72F', '#F8C931', '#F8CB34', '#F8CD37', '#F7CF3A', '#F7D13C', '#F6D33F', '#F6D542', '#F5D745', '#F5D948', '#F4DB4B', '#F4DC4F', '#F3DE52', '#F3E056', '#F3E259', '#F2E45D', '#F2E660', '#F1E864', '#F1E968', '#F1EB6C', '#F1ED70', '#F1EE74', '#F1F079', '#F1F27D', '#F2F381', '#F2F485', '#F3F689', '#F4F78D', '#F5F891', '#F6FA95', '#F7FB99', '#F9FC9D', '#FAFDA0', '#FCFEA4']\n",
    "    colors_magma = ['#000003', '#000004', '#000006', '#010007', '#010109', '#01010B', '#02020D', '#02020F', '#030311', '#040313', '#040415', '#050417', '#060519', '#07051B', '#08061D', '#09071F', '#0A0722', '#0B0824', '#0C0926', '#0D0A28', '#0E0A2A', '#0F0B2C', '#100C2F', '#110C31', '#120D33', '#140D35', '#150E38', '#160E3A', '#170F3C', '#180F3F', '#1A1041', '#1B1044', '#1C1046', '#1E1049', '#1F114B', '#20114D', '#221150', '#231152', '#251155', '#261157', '#281159', '#2A115C', '#2B115E', '#2D1060', '#2F1062', '#301065', '#321067', '#341068', '#350F6A', '#370F6C', '#390F6E', '#3B0F6F', '#3C0F71', '#3E0F72', '#400F73', '#420F74', '#430F75', '#450F76', '#470F77', '#481078', '#4A1079', '#4B1079', '#4D117A', '#4F117B', '#50127B', '#52127C', '#53137C', '#55137D', '#57147D', '#58157E', '#5A157E', '#5B167E', '#5D177E', '#5E177F', '#60187F', '#61187F', '#63197F', '#651A80', '#661A80', '#681B80', '#691C80', '#6B1C80', '#6C1D80', '#6E1E81', '#6F1E81', '#711F81', '#731F81', '#742081', '#762181', '#772181', '#792281', '#7A2281', '#7C2381', '#7E2481', '#7F2481', '#812581', '#822581', '#842681', '#852681', '#872781', '#892881', '#8A2881', '#8C2980', '#8D2980', '#8F2A80', '#912A80', '#922B80', '#942B80', '#952C80', '#972C7F', '#992D7F', '#9A2D7F', '#9C2E7F', '#9E2E7E', '#9F2F7E', '#A12F7E', '#A3307E', '#A4307D', '#A6317D', '#A7317D', '#A9327C', '#AB337C', '#AC337B', '#AE347B', '#B0347B', '#B1357A', '#B3357A', '#B53679', '#B63679', '#B83778', '#B93778', '#BB3877', '#BD3977', '#BE3976', '#C03A75', '#C23A75', '#C33B74', '#C53C74', '#C63C73', '#C83D72', '#CA3E72', '#CB3E71', '#CD3F70', '#CE4070', '#D0416F', '#D1426E', '#D3426D', '#D4436D', '#D6446C', '#D7456B', '#D9466A', '#DA4769', '#DC4869', '#DD4968', '#DE4A67', '#E04B66', '#E14C66', '#E24D65', '#E44E64', '#E55063', '#E65162', '#E75262', '#E85461', '#EA5560', '#EB5660', '#EC585F', '#ED595F', '#EE5B5E', '#EE5D5D', '#EF5E5D', '#F0605D', '#F1615C', '#F2635C', '#F3655C', '#F3675B', '#F4685B', '#F56A5B', '#F56C5B', '#F66E5B', '#F6705B', '#F7715B', '#F7735C', '#F8755C', '#F8775C', '#F9795C', '#F97B5D', '#F97D5D', '#FA7F5E', '#FA805E', '#FA825F', '#FB8460', '#FB8660', '#FB8861', '#FB8A62', '#FC8C63', '#FC8E63', '#FC9064', '#FC9265', '#FC9366', '#FD9567', '#FD9768', '#FD9969', '#FD9B6A', '#FD9D6B', '#FD9F6C', '#FDA16E', '#FDA26F', '#FDA470', '#FEA671', '#FEA873', '#FEAA74', '#FEAC75', '#FEAE76', '#FEAF78', '#FEB179', '#FEB37B', '#FEB57C', '#FEB77D', '#FEB97F', '#FEBB80', '#FEBC82', '#FEBE83', '#FEC085', '#FEC286', '#FEC488', '#FEC689', '#FEC78B', '#FEC98D', '#FECB8E', '#FDCD90', '#FDCF92', '#FDD193', '#FDD295', '#FDD497', '#FDD698', '#FDD89A', '#FDDA9C', '#FDDC9D', '#FDDD9F', '#FDDFA1', '#FDE1A3', '#FCE3A5', '#FCE5A6', '#FCE6A8', '#FCE8AA', '#FCEAAC', '#FCECAE', '#FCEEB0', '#FCF0B1', '#FCF1B3', '#FCF3B5', '#FCF5B7', '#FBF7B9', '#FBF9BB', '#FBFABD', '#FBFCBF']\n",
    "    colors_ylgnbl = ['#081d58', '#0a1e5d', '#0c2062', '#0f2267', '#11246c', '#142671', '#162876', '#182a7b', '#1b2c80', '#1d2e85', '#20308a', '#22328f', '#253494', '#243795', '#243b97', '#243e99', '#24429a', '#23459c', '#23499e', '#234c9f', '#2350a1', '#2253a3', '#2257a4', '#225aa6', '#225ea8', '#2162aa', '#2166ac', '#206aae', '#206fb0', '#1f73b2', '#1f77b4', '#1f7bb6', '#1e80b8', '#1e84ba', '#1d88bc', '#1d8cbe', '#1d91c0', '#2094c0', '#2397c0', '#269ac1', '#299dc1', '#2ca0c1', '#2fa3c2', '#32a6c2', '#35a9c2', '#38acc3', '#3bafc3', '#3eb2c3', '#41b6c4', '#46b7c3', '#4bb9c2', '#50bbc1', '#55bdc1', '#5abfc0', '#60c1bf', '#65c3be', '#6ac5be', '#6fc7bd', '#74c9bc', '#79cbbb', '#7fcdbb', '#85cfba', '#8bd1b9', '#91d4b9', '#97d6b8', '#9dd8b8', '#a3dbb7', '#a9ddb6', '#afdfb6', '#b5e2b5', '#bbe4b5', '#c1e6b4', '#c7e9b4', '#caeab3', '#cdebb3', '#d0ecb3', '#d3eeb3', '#d6efb2', '#daf0b2', '#ddf1b2', '#e0f3b2', '#e3f4b1', '#e6f5b1', '#e9f6b1', '#edf8b1', '#eef8b4', '#f0f9b7', '#f1f9bb', '#f3fabe', '#f4fac1', '#f6fbc5', '#f7fcc8', '#f9fccb', '#fafdcf', '#fcfdd2', '#fdfed5', '#ffffd9']\n",
    "    colors_grlgrdgr = ['#0d2b17', '#0e2d17', '#0f2f17', '#103118', '#123318', '#133618', '#143819', '#153a19', '#173c1a', '#183e1a', '#19411a', '#1a431b', '#1c451b', '#1d471b', '#1e4a1c', '#1f4c1c', '#214e1d', '#22501d', '#23521d', '#24551e', '#26571e', '#27591e', '#285b1f', '#295e1f', '#2b6020', '#2c6220', '#2d6420', '#2f6621', '#306921', '#316b22', '#326d22', '#346f22', '#357223', '#367423', '#377623', '#397824', '#3a7a24', '#3b7d25', '#3c7f25', '#3e8125', '#3f8326', '#408626', '#418826', '#438a27', '#448c27', '#458e28', '#469128', '#489328', '#499529', '#4a9729', '#4c9a2a', '#4e9b2d', '#519c30', '#549d34', '#569e37', '#599f3a', '#5ca03e', '#5ea141', '#61a345', '#64a448', '#67a54b', '#69a64f', '#6ca752', '#6fa855', '#71a959', '#74ab5c', '#77ac60', '#79ad63', '#7cae66', '#7faf6a', '#82b06d', '#84b170', '#87b374', '#8ab477', '#8cb57b', '#8fb67e', '#92b781', '#94b885', '#97b988', '#9abb8c', '#9dbc8f', '#9fbd92', '#a2be96', '#a5bf99', '#a7c09c', '#aac1a0', '#adc3a3', '#afc4a7', '#b2c5aa', '#b5c6ad', '#b8c7b1', '#bac8b4', '#bdc9b7', '#c0cbbb', '#c2ccbe', '#c5cdc2', '#c8cec5', '#cacfc8', '#cdd0cc', '#d0d1cf', '#d3d3d3']\n",
    "    colors = colors_grlgrdgr\n",
    "    \n",
    "    dyn_list = df.columns   \n",
    "    # Split the interacting-residues-pairs in the index into different columns\n",
    "    df[['APos','BPos','CPos','FPos','GprotPos',]] = df.apply(lambda x: split_pos(x), result_type='expand', axis=1)\n",
    "\n",
    "    for dyn in dyn_list:\n",
    "\n",
    "        # Select top interactions based on its mean frequency. Also asign color based on mean value\n",
    "        color_len = len(colors) -1\n",
    "        df['color'] = df[dyn].apply(lambda x: colors[color_len-round(x*color_len/100)]) #There are 101 colors avalible in list\n",
    "\n",
    "        #Filter top 20 interaction freqeuncies\n",
    "        df = df.nlargest(20, dyn)\n",
    "\n",
    "        #'Edge' multi-entries, based on the 4 GPCR nomenclatures\n",
    "        jsondict = {}\n",
    "        for leter in ['', 'A', 'B', 'C', 'F']:\n",
    "            df_dict = pd.DataFrame(columns = [\"name1\", \"name2\", \"frames\"])\n",
    "            df_dict['name1'] = df[leter+'Pos'] if leter else df['APos'] # Class A comes as the default one\n",
    "            df_dict['name2'] = df['GprotPos']\n",
    "            df_dict['frames'] = [[1]]*len(df_dict)\n",
    "            df_dict['color'] = df['color']\n",
    "            df_dict['value'] = df[dyn]\n",
    "            leter_edges = df_dict.to_dict(orient=\"records\")\n",
    "\n",
    "            #Appending edges\n",
    "            jsondict[leter+'edges'] = leter_edges \n",
    "\n",
    "        #Writing json\n",
    "        jsonpath = folderpath + dyn + \"_top.json\"\n",
    "        with open(jsonpath, 'w') as jsonfile:\n",
    "            json.dump(jsondict, jsonfile, ensure_ascii=False, indent = 4)\n",
    "\n",
    "\n",
    "####################\n",
    "## dendrogram functions\n",
    "####################    \n",
    "\n",
    "def frequencies(df):\n",
    "    \"\"\"\n",
    "    Creates an interaction frequency numpy matrix from \n",
    "    \"\"\"\n",
    "\n",
    "    # Transpose matrix\n",
    "    df_t = df.transpose() \n",
    "    \n",
    "    # Create dictionary table with Residue tuple as keys and interaction-by-simulation-freq array as value\n",
    "    freq_table = { tuple(col.split(\"\\n\\n\")):list(df_t[col].values) for col in df_t }\n",
    "        \n",
    "    # Convert previous dictionary to numpy array, and traspose it\n",
    "    freq_matrix = (np.array([freq_table[(r1, r2)] for (r1, r2) in freq_table])).T\n",
    "\n",
    "    # Reorder according to clustering\n",
    "    return freq_matrix\n",
    "    \n",
    "def black_or_white(bgcolor):\n",
    "    \"\"\"\n",
    "    Text with this color background should be in black or white font?\n",
    "    \"\"\"\n",
    "    ary_bgcolors = re.findall(r\"[\\w']+\", bgcolor)\n",
    "    R = int(ary_bgcolors[1])\n",
    "    G = int(ary_bgcolors[2])\n",
    "    B = int(ary_bgcolors[3])\n",
    "    Lumi = (sum([R,G,B])/3)\n",
    "\n",
    "    if Lumi > 125:\n",
    "        colorfont = 'rgb(0,0,0)'\n",
    "    else:\n",
    "        colorfont = 'rgb(255,255,255)'\n",
    "\n",
    "    return colorfont\n",
    "    \n",
    "def clustering(clusters, dend_matrix, labels, linkagefun):\n",
    "    \"\"\"\n",
    "    Find the color threshold needed for the dendrogram to have \"clusters\" number of clusters. \n",
    "    Also define to which cluster each simulation belongs\n",
    "    \"\"\"\n",
    "    Z = linkagefun(dend_matrix)\n",
    "    color_threshold = Z[-1*clusters][2]+0.0000000001 #Cut slightly above the tree node\n",
    "    \n",
    "    # Defining to which cluster belongs to each simulation\n",
    "    T = fcluster(Z, t=clusters, criterion='maxclust')\n",
    "    clustdict = { \"cluster\" + str(clust) : [] for clust in T }\n",
    "    for sim,clust in zip(labels,T):\n",
    "         clustdict[\"cluster\" + str(clust)].append(sim)\n",
    "\n",
    "    return(color_threshold, clustdict)\n",
    "\n",
    "\n",
    "def annotate_clusters(fig, default_color = \"\"):\n",
    "    \"\"\"\n",
    "    Put an annotation the nodes on top of clusters\n",
    "    \"\"\"\n",
    "    prevcolor = \"\"\n",
    "    min_x = 0\n",
    "    clustcount = -1\n",
    "    clustcoords = []\n",
    "    xcords = []\n",
    "    annotations = []\n",
    "    taken_ycords = set()\n",
    "    \n",
    "    # Sorting by y coordenate (needed for later)\n",
    "    fig['data'] = sorted(fig['data'], key=lambda x: x['y'][0])\n",
    "    \n",
    "    #Iterate over all vector forms in the figure and find the ones that are cluster tops\n",
    "    for entry in fig['data']:\n",
    "\n",
    "        currentcolor = entry['marker']['color']\n",
    "        current_min_x = min(entry['x'])\n",
    "        current_max_x = max(entry['x'])\n",
    "        # For skipping upper-dendrogram, non-cluster branches\n",
    "        if (currentcolor == default_color) and ((max(entry['x']) != -0.0) or (entry['y'][0]%10 == 0)):\n",
    "            continue\n",
    "\n",
    "        #Check for false 'single-node, default color' clusters\n",
    "        if ((entry['y'][0] in taken_ycords) or (entry['y'][0] in taken_ycords)) and (currentcolor == default_color):\n",
    "            continue\n",
    "            \n",
    "        # If there has been a color change ...\n",
    "        #... OR it is a single-node cluster\n",
    "        if (prevcolor != currentcolor) or ((currentcolor == default_color) and (max(entry['x']) == -0.0) ):\n",
    "            clustcount += 1\n",
    "            xcords.append(\"\")\n",
    "            min_x = 0\n",
    "            clustcoords.append({})\n",
    "            \n",
    "        # If new entry is higher (inside the tree) than previous, select as candidate for cluster node        \n",
    "        if current_min_x <= min_x:\n",
    "\n",
    "            min_x = current_min_x\n",
    "            clustcoords[clustcount]['clusnode_x'] = entry['x'][1]\n",
    "            xcords[clustcount] = (clustcoords[clustcount]['clusnode_x'])\n",
    "            clustcoords[clustcount]['clusnode_y'] = (entry['y'][1] + entry['y'][2])/2\n",
    "            clustcoords[clustcount]['clustnumber'] = clustcount\n",
    "            clustcoords[clustcount]['color'] = currentcolor\n",
    "            clustcoords[clustcount]['xanchor'] = 'right'\n",
    "            \n",
    "            #For single-branch clusters\n",
    "            if (currentcolor == default_color) and (current_max_x == -0): \n",
    "                index_x = np.where(entry['x'] == current_max_x) \n",
    "                clustcoords[clustcount]['clusnode_y'] = entry['y'][index_x][0]\n",
    "                #If the branch contains two single-node clusters(very rare case), append another cluster label\n",
    "                if (entry['x'][0] == -0) and (entry['x'][3] == -0) and (entry['y'][2]%10 != 0):\n",
    "                    clustcount += 1\n",
    "                    clustcoords.append({\n",
    "                        'clusnode_x' : entry['x'][2],\n",
    "                        'clusnode_y' : entry['y'][2],\n",
    "                        'clustnumber' : clustcount,\n",
    "                        'color' : currentcolor,\n",
    "                        'xanchor' : 'right'\n",
    "                   })\n",
    "                    xcords.append(clustcoords[clustcount]['clusnode_x'])\n",
    "        \n",
    "        #Add occuped y-coords\n",
    "        for ycord in entry['y']:\n",
    "            if ycord%10 == 5:\n",
    "                taken_ycords.add(ycord)\n",
    "\n",
    "        prevcolor = currentcolor\n",
    "    \n",
    "    # Annotate with \"clusterN\" the vector forms found in previous loop\n",
    "    for clust in clustcoords:\n",
    "        colorfont = black_or_white(clust['color'])\n",
    "        annotations.append(dict(\n",
    "            x = clust['clusnode_x'],\n",
    "            y = clust['clusnode_y'],\n",
    "            xanchor = clust['xanchor'],\n",
    "            text = \"cluster \" + str(clust['clustnumber']+1),\n",
    "            showarrow = False,\n",
    "            bgcolor = clust['color'],\n",
    "            font = { 'size' : 12, 'color' : colorfont },\n",
    "            height = 14\n",
    "        ))\n",
    "\n",
    "    return annotations\n",
    "\n",
    "def hoverlabels_axis(fig, partial_db_dict, default_color, annotations = []):\n",
    "    \"\"\"\n",
    "    Makes hover labels from figure correspond to Y-axis labels, and make Y-axis labels correspond to dendrogram\n",
    "    colors.\n",
    "    \"\"\"\n",
    "    \n",
    "    def define_annotation_list(y_pos, bgcolor, text, colorfont, name, hovertext):\n",
    "        \"\"\"\n",
    "        Create a list of annotation objects. This annotations are meant to replace the axis labels as names of simulations\n",
    "        \"\"\"\n",
    "        return dict(\n",
    "            x = -0,\n",
    "            y = y_pos,\n",
    "            xanchor = 'left',\n",
    "            text = text,\n",
    "            hovertext = hovertext,\n",
    "            showarrow = False,\n",
    "            captureevents = True,\n",
    "            bgcolor = bgcolor,\n",
    "            font = { 'size' : 12, 'color' : colorfont },\n",
    "            height = 14\n",
    "        )\n",
    "\n",
    "    def prepare_entry(hoverentry, fig, ypos, partial_db_dict):\n",
    "        \"\"\"\n",
    "        Creates xaxis-annotations and hoverlabels based on the information contained by this dendrogram branch\n",
    "        \"\"\"                \n",
    "        dynid = dendro_leaves[int((ypos-5)/10)]\n",
    "        nodyn_id = dynid.replace('dyn','')\n",
    "        pdbcode = partial_db_dict[dynid]['pdb_id']\n",
    "        simname = partial_db_dict[dynid]['up_name']\n",
    "        peplig = partial_db_dict[dynid]['peplig']\n",
    "        ligsname = partial_db_dict[dynid]['lig_sname']\n",
    "        liglname = partial_db_dict[dynid]['lig_lname']\n",
    "        bgcolor = hoverentry['marker']['color']\n",
    "        anot_text = \"%s (%s)<b style='display: none'>%s</b>\" % (simname, pdbcode, dynid)\n",
    "        if (ligsname):\n",
    "            # If peptide ligand, take long-name of ligand (regular name)\n",
    "            if (peplig):\n",
    "                hovertext = str(\"complex with %s (dynID: %s)\" % (liglname, nodyn_id))\n",
    "            else: # Else take short name (Residue ID)\n",
    "                hovertext = str(\"complex with %s (dynID: %s)\" % (ligsname, nodyn_id))\n",
    "        else:\n",
    "            hovertext = str(\"apoform (dynID: %s)\" % (nodyn_id))            \n",
    "\n",
    "        # Annotation to corresponding simulation\n",
    "        colorfont = black_or_white(bgcolor)\n",
    "        annotations.append(define_annotation_list(ypos, bgcolor, anot_text, colorfont, dynid, hovertext))\n",
    "\n",
    "        return(fig, annotations)\n",
    "    \n",
    "    dendro_leaves = fig['layout']['yaxis']['ticktext']\n",
    "\n",
    "    # Adapting hovertool to what I want from it\n",
    "    occuped_Residues = dict()\n",
    "    for hoverentry in fig['data']:\n",
    "\n",
    "        # Silenciate all default hover entries. \n",
    "        hoverentry['hoverinfo'] = 'none'\n",
    "        \n",
    "        # If entry reaches end of plot (not intermediate node)\n",
    "        if (hoverentry['x'][0] == -0) and (int(hoverentry['y'][0])%10 == 5):\n",
    "            \n",
    "            #If entry Y-corodinate is not already occuped by another one, or if it's wrongly occuped by a middle dendrogram which reaches bottom of plot\n",
    "            if (hoverentry['y'][0] not in occuped_Residues) or (hoverentry['marker']['color'] != default_color):\n",
    "\n",
    "                occuped_Residues[hoverentry['y'][0]] = hoverentry['marker']['color']\n",
    "                (fig, annotations) = prepare_entry(hoverentry, fig, hoverentry['y'][0], partial_db_dict)\n",
    "\n",
    "                #If this entry reaches two labels at the same time (terminal U node), create yet another entry\n",
    "                if (hoverentry['x'][3] == -0) and (int(hoverentry['y'][3])%10 == 5): \n",
    "                    (fig, annotations) = prepare_entry(hoverentry, fig, hoverentry['y'][3], partial_db_dict)\n",
    "\n",
    "    fig['layout']['annotations'] = annotations\n",
    "\n",
    "    return fig\n",
    "\n",
    "def dendrogram_clustering(dend_matrix, labels, height, width, filename, clusters, partial_db_dict): \n",
    "\n",
    "    # Define linkage function (we'll be using the default one for plotly). \n",
    "    linkagefun=lambda x: linkage(x, 'complete')\n",
    "    (thres,clustdict) = clustering(clusters, dend_matrix, labels, linkagefun)\n",
    "\n",
    "    # Create color scale from the \"category20\" color scale. Not working because color_scale plotly option is inoperative\n",
    "    colors_category20 = ['rgb(31, 119, 180)', 'rgb(174, 199, 232)', 'rgb(255, 127, 14)', 'rgb(255, 187, 120)', 'rgb(44, 160, 44)', 'rgb(152, 223, 138)', 'rgb(214, 39, 40)', 'rgb(255, 152, 150)', 'rgb(148, 103, 189)', 'rgb(197, 176, 213)', 'rgb(140, 86, 75)', 'rgb(196, 156, 148)', 'rgb(227, 119, 194)', 'rgb(247, 182, 210)', 'rgb(127, 127, 127)', 'rgb(199, 199, 199)', 'rgb(188, 189, 34)', 'rgb(219, 219, 141)', 'rgb(23, 190, 207)', 'rgb(158, 218, 229)']\n",
    "    colors = colors_category20[0:clusters]\n",
    "\n",
    "    # Setting figures\n",
    "    fig = create_dendrogram(\n",
    "        dend_matrix,\n",
    "        orientation='right',\n",
    "        labels=labels,\n",
    "        linkagefun=linkagefun,\n",
    "        color_threshold = thres,\n",
    "        hovertext = labels,\n",
    "    )\n",
    "\n",
    "    fig['layout'].update({\n",
    "        'width':width, \n",
    "        'height':height,\n",
    "        'hoverdistance' : 10,\n",
    "        'plot_bgcolor' : \"#FFFFFF\"\n",
    "        })\n",
    "\n",
    "    fig['layout']['xaxis'].update({\n",
    "        'showline': False,\n",
    "        'showticklabels': False,\n",
    "        'ticks' : '',\n",
    "        'fixedrange' : True,\n",
    "        'automargin' : False\n",
    "        })\n",
    "\n",
    "    fig['layout']['yaxis'].update({\n",
    "        'side' : 'right',\n",
    "        'showline': False,\n",
    "        'ticks' : '',\n",
    "        'tickfont' : {\n",
    "            'size' : 15,\n",
    "            'color' : 'white'\n",
    "            },\n",
    "        'fixedrange' : True,\n",
    "        })\n",
    "\n",
    "    fig.update_layout(\n",
    "        margin=dict(t=0, b=0, r=150, l=100),\n",
    "    )\n",
    "\n",
    "    #Annotating cluster nodes\n",
    "    annotations = annotate_clusters(fig, 'rgb(0,116,217)') # Default color for tree\n",
    "\n",
    "    # Correcting hoverlabels\n",
    "    fig = hoverlabels_axis(fig, partial_db_dict, 'rgb(0,116,217)', annotations)\n",
    "\n",
    "    # Taking order for plot rows\n",
    "    dendro_leaves = fig['layout']['yaxis']['ticktext']\n",
    "\n",
    "    # Writing dendrogram on file\n",
    "    fig.write_html(filename, auto_open=False,config={\n",
    "        \"displayModeBar\": \"hover\",\n",
    "        \"showAxisDragHandles\": False,\n",
    "        \"showAxisRangeEntryBoxes\": False,\n",
    "        \"scrollZoom\": False,\n",
    "        \"showTips\" : False,\n",
    "        \"modeBarButtons\": [[\"toImage\"]]\n",
    "    })\n",
    "    return (list(dendro_leaves),clustdict)\n",
    "\n",
    "def create_dyntoname_file(dyn_dend_order, partial_db_dict, outputs_path):\n",
    "    \"\"\"\n",
    "    Creates a list of tuples, each one containing dynID-receptor names pairs\n",
    "    Needed to display menu dropdown's receptor names in same order as dendrogram\n",
    "    \"\"\"\n",
    "    dyn_names = [ partial_db_dict[dyn]['recept_name_dynid'] for dyn in dyn_dend_order ]\n",
    "    dyn_to_names = list(zip(dyn_dend_order, list(dyn_names)))\n",
    "    dyn_to_names.reverse()\n",
    "    with open(outputs_path+\"name_to_dyn_dict.json\", \"w\") as dyn_names_file:\n",
    "        json.dump(dyn_to_names, dyn_names_file, ensure_ascii=False, indent = 4)\n",
    "\n",
    "\n",
    "def cluster_flareplot(df, clustdict, folderpath, flare_template = False):\n",
    "    \"\"\"\n",
    "    Create json entries for significative positions (top10 mean frequency) of each cluster produced\n",
    "    \"\"\"\n",
    "    os.makedirs(folderpath,  exist_ok = True)\n",
    "    colors_grorrd = ['#800026', '#850026', '#8a0026', '#8f0026', '#940026', '#990026', '#9e0026', '#a30026', '#a80026', '#ad0026', '#b20026', '#b70026', '#bd0026', '#c00225', '#c30424', '#c60623', '#c90822', '#cc0a21', '#d00d21', '#d30f20', '#d6111f', '#d9131e', '#dc151d', '#df171c', '#e31a1c', '#e51e1d', '#e7221e', '#e9271f', '#eb2b20', '#ed2f21', '#ef3423', '#f13824', '#f33c25', '#f54126', '#f74527', '#f94928', '#fc4e2a', '#fc532b', '#fc582d', '#fc5d2e', '#fc6330', '#fc6831', '#fc6d33', '#fc7234', '#fc7836', '#fc7d37', '#fc8239', '#fc873a', '#fd8d3c', '#fd903d', '#fd933e', '#fd9640', '#fd9941', '#fd9c42', '#fd9f44', '#fda245', '#fda546', '#fda848', '#fdab49', '#fdae4a', '#feb24c', '#feb54f', '#feb853', '#febb56', '#febf5a', '#fec25d', '#fec561', '#fec864', '#fecc68', '#fecf6b', '#fed26f', '#fed572', '#fed976', '#feda79', '#fedc7d', '#fede80', '#fedf84', '#fee187', '#fee38b', '#fee48e', '#fee692', '#fee895', '#fee999', '#feeb9c', '#ffeda0', '#fbeaa4', '#f7e8a8', '#f4e6ac', '#f0e4b1', '#ece2b5', '#e9e0b9', '#e5ddbd', '#e1dbc2', '#ded9c6', '#dad7ca', '#d6d5ce', '#d3d3d3']\n",
    "    colors = colors_grorrd\n",
    "    color_len = len(colors) -1\n",
    "    \n",
    "    # Split the interacting-residues-pairs in the index into different columns\n",
    "    df[['APos','BPos','CPos','FPos','GprotPos',]] = df.apply(lambda x: split_pos(x), result_type='expand', axis=1)\n",
    "    for clust in clustdict.keys():\n",
    "\n",
    "        # Select top interactions based on its mean frequency. Also asign color based on mean value\n",
    "        df_clust = df.filter(items = clustdict[clust] + ['APos','BPos','CPos','FPos','GprotPos'])\n",
    "        df_clust['mean'] = df_clust.mean(axis = 1, numeric_only = True)\n",
    "        mean_threshold = min(df_clust['mean'].nlargest(20).tolist())\n",
    "        df_clust['color'] = df_clust['mean'].apply(lambda x: colors[color_len-round(x*color_len/100)]) #There are 101 colors avalible in list\n",
    "\n",
    "        #Filter top 20 in df_clust\n",
    "        df_clust = df_clust.nlargest(20,'mean')\n",
    "\n",
    "        #'Edge' multi-entries, based on the 4 GPCR nomenclatures\n",
    "        for leter in ['A', 'B', 'C', 'F']:\n",
    "            df_dict = pd.DataFrame(columns = [\"name1\", \"name2\", \"frames\"])\n",
    "            df_dict['name1'] = df_clust[leter+'Pos'] \n",
    "            df_dict['name2'] = df_clust['GprotPos'].str.replace('\\n','_')\n",
    "            df_dict['frames'] = [[1]]*len(df_dict)\n",
    "            df_dict['color'] = df_clust['color']\n",
    "            df_dict['value'] = df_clust['mean']\n",
    "            leter_edges = df_dict.to_dict(orient=\"records\")\n",
    "\n",
    "            #Appending edges\n",
    "            if flare_template:\n",
    "                flare_template[leter+'edges'] = leter_edges\n",
    "                jsondict = flare_template\n",
    "            else:\n",
    "                jsondict = { leter+'edges' : leter_edges }\n",
    "        #Writing json\n",
    "        jsonpath = folderpath + clust + \".json\"\n",
    "        with open(jsonpath, 'w') as jsonfile:\n",
    "            json.dump(jsondict, jsonfile, ensure_ascii=False, indent = 4)        \n",
    "        \n",
    "def dendrogramming(df,outputs_path,partial_db_dict):\n",
    "    \"\"\"\n",
    "    A mishmash of functions to create and save the dendrogram files we'll use in \n",
    "    the web application\n",
    "    \"\"\"\n",
    "\n",
    "    #Computing frequency matrix\n",
    "    dend_matrix = frequencies(df)\n",
    "\n",
    "    # Labels for dendogram\n",
    "    dendlabels_dyns = list(df.columns)\n",
    "\n",
    "    #Preparing dendrogram folders and parameters\n",
    "    dendfolder = outputs_path + \"dendrograms/\" \n",
    "    os.makedirs(dendfolder, exist_ok = True)\n",
    "    dend_height = int(df.shape[1]) * 18\n",
    "    dend_width = 450\n",
    "\n",
    "    # Computing several dendrograms and corresponding json files\n",
    "    for cluster in range(2,4):# DEBUG\n",
    "    #         for cluster in list(range(2,21)):\n",
    "        print('      computing dendrogram with '+str(cluster)+' clusters')\n",
    "        dendfile = (\"%s%iclusters_dendrogram.html\" % (dendfolder, cluster))\n",
    "        (dyn_dend_order, clustdict) = dendrogram_clustering(\n",
    "            dend_matrix,\n",
    "            dendlabels_dyns, \n",
    "            dend_height, \n",
    "            dend_width, \n",
    "            dendfile, \n",
    "            cluster, \n",
    "            partial_db_dict, \n",
    "        )\n",
    "        # Write dynamicID-cluster dictionary on a json\n",
    "        clustdir = \"%sflareplots_clusters/%sclusters/\" % (outputs_path, cluster)\n",
    "        os.makedirs(clustdir, exist_ok= True)\n",
    "        with open(clustdir + \"clustdict.json\", 'w') as clusdictfile:\n",
    "            json.dump(clustdict, clusdictfile, ensure_ascii=False, indent = 4)\n",
    "\n",
    "        #Jsons for the flareplots of this combinations of clusters\n",
    "        cluster_flareplot(df, clustdict, clustdir, flare_template)\n",
    "\n",
    "    #Store Simulation names and dyn on file\n",
    "    create_dyntoname_file(dyn_dend_order, partial_db_dict, outputs_path)\n",
    "\n",
    "    return(dyn_dend_order,dend_height)\n",
    "\n",
    "def sort_simulations(df, dyn_dend_order):\n",
    "    \"\"\"\n",
    "    Sorts the simulations in the dataframe according to the order in the list dyn_dend_order\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a dictionary with the order of each simulation row in the plot \n",
    "    dyn_dend_order_dict = { dyn_name : dyn_dend_order.index(dyn_name) for dyn_name in dyn_dend_order }\n",
    "\n",
    "    # Adding column based in new order recieved from clustering\n",
    "    df['clust_order'] =  df['Id'].apply(lambda x: dyn_dend_order_dict[x])\n",
    "\n",
    "    #Sorting by ballesteros Id's (helixloop column) and clustering order\n",
    "    df['helixloop'] = df['Residue'].apply(lambda x: re.sub(r'^(\\d)x',r'\\g<1>0x',x)) \n",
    "    df = df.sort_values([\"helixloop\",'clust_order'])\n",
    "\n",
    "    #Drop sort columns once used\n",
    "    df.drop(['helixloop','clust_order'], axis = 1, inplace = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "####################\n",
    "## heatmap functions\n",
    "####################\n",
    "\n",
    "def find_itype_freqs(df_ts,typelist):\n",
    "    \"\"\"\n",
    "    Find interaction frequencies of individual interaction types and append them to main df\n",
    "    \"\"\"\n",
    "\n",
    "    for itype in typelist:\n",
    "\n",
    "        def find_freq(row,int_dict):\n",
    "            k = (row['Id'],row['Residue'])\n",
    "            freq_i = int_dict[k] if k in int_dict else 0.0\n",
    "            return(freq_i)\n",
    "\n",
    "        # Load table of specific interaction type\n",
    "        df_path = \"%s%s.tsv\"%(interta_path, itype)\n",
    "        if not os.path.exists(df_path):\n",
    "            continue\n",
    "        df_raw = pd.read_csv(df_path, sep=\"\\s+\")\n",
    "\n",
    "        # Prepare table: filter low-freq inters, pass freqs to percentage, ....\n",
    "        (df_itype,df_standard) = prepare_table(df_raw,db_dict)\n",
    "        df_titype = df_itype.transpose().stack().reset_index()\n",
    "        df_titype.columns = ['Id','Residue','freq']\n",
    "        df_titype.set_index(['Id', 'Residue'], inplace=True)\n",
    "        int_dict = df_titype.to_dict()['freq']\n",
    "\n",
    "        # Find int-freq values for this itype, and append them to main dataframe\n",
    "        df_ts[itype] = df_ts.apply(lambda x : find_freq(x,int_dict), axis=1)\n",
    "        \n",
    "    return(df_ts)\n",
    "\n",
    "def create_hovertool(itype, itypes_order, hb_itypes, typelist):\n",
    "    \"\"\"\n",
    "    Creates a list in hovertool format from the two dictionaries above\n",
    "    \"\"\"\n",
    "\n",
    "    #Creating hovertool listzzzz\n",
    "    hoverlist = [('GPCR', '@Name'),\n",
    "                 ('Gprot', '@gprot_name'),   \n",
    "                 ('PDB id', '@pdb_id'),\n",
    "                 ('Residue', '@resname_gennum'),\n",
    "                 (typelist[itype], '@{freq}{0.00}%')\n",
    "                ]\n",
    "\n",
    "    #Hover tool:\n",
    "    hover = HoverTool(\n",
    "        tooltips=hoverlist\n",
    "    )\n",
    "\n",
    "    return hover\n",
    "  \n",
    "def define_figure(width, height, dataframe, hover, itype):\n",
    "    \"\"\"\n",
    "    Prepare bokeh figure heatmap as intended\n",
    "    \"\"\"\n",
    "\n",
    "    # Mapper colors\n",
    "    # I left here the ones just in case\n",
    "    colors_auld = ['#800000', '#860000', '#8c0000', '#930000', '#990000', '#9f0000', '#a60000', '#ac0000', '#b20000', '#b90000', '#bf0000', '#c50000', '#cc0000', '#d20000', '#d80000', '#df0000', '#e50000', '#eb0000', '#f20000', '#f80000', '#ff0000', '#ff0700', '#ff0e00', '#ff1500', '#ff1c00', '#ff2300', '#ff2a00', '#ff3100', '#ff3800', '#ff3f00', '#ff4600', '#ff4d00', '#ff5400', '#ff5b00', '#ff6200', '#ff6900', '#ff7000', '#ff7700', '#ff7e00', '#ff8500', '#ff8c00', '#ff9100', '#ff9700', '#ff9d00', '#ffa300', '#ffa800', '#ffae00', '#ffb400', '#ffba00', '#ffbf00', '#ffc500', '#ffcb00', '#ffd100', '#ffd600', '#ffdc00', '#ffe200', '#ffe800', '#ffed00', '#fff300', '#fff900', '#ffff00', '#f2ff00', '#e5ff00', '#d8ff00', '#ccff00', '#bfff00', '#b2ff00', '#a5ff00', '#99ff00', '#8cff00', '#7fff00', '#72ff00', '#66ff00', '#59ff00', '#4cff00', '#3fff00', '#33ff00', '#26ff00', '#19ff00', '#0cff00', '#00ff00', '#0afc0a', '#15fa15', '#1ff81f', '#2af62a', '#34f434', '#3ff13f', '#49ef49', '#54ed54', '#5eeb5e', '#69e969', '#74e674', '#7ee47e', '#89e289', '#93e093', '#9ede9e', '#a8dba8', '#b3d9b3', '#bdd7bd', '#c8d5c8', '#d3d3d3']\n",
    "    colors_ylorrd = ['#800026', '#850026', '#8a0026', '#8f0026', '#940026', '#990026', '#9e0026', '#a30026', '#a80026', '#ad0026', '#b20026', '#b70026', '#bd0026', '#c00225', '#c30424', '#c60623', '#c90822', '#cc0a21', '#d00d21', '#d30f20', '#d6111f', '#d9131e', '#dc151d', '#df171c', '#e31a1c', '#e51e1d', '#e7221e', '#e9271f', '#eb2b20', '#ed2f21', '#ef3423', '#f13824', '#f33c25', '#f54126', '#f74527', '#f94928', '#fc4e2a', '#fc532b', '#fc582d', '#fc5d2e', '#fc6330', '#fc6831', '#fc6d33', '#fc7234', '#fc7836', '#fc7d37', '#fc8239', '#fc873a', '#fd8d3c', '#fd903d', '#fd933e', '#fd9640', '#fd9941', '#fd9c42', '#fd9f44', '#fda245', '#fda546', '#fda848', '#fdab49', '#fdae4a', '#feb24c', '#feb54f', '#feb853', '#febb56', '#febf5a', '#fec25d', '#fec561', '#fec864', '#fecc68', '#fecf6b', '#fed26f', '#fed572', '#fed976', '#feda79', '#fedc7d', '#fede80', '#fedf84', '#fee187', '#fee38b', '#fee48e', '#fee692', '#fee895', '#fee999', '#feeb9c', '#ffeda0', '#ffeea3', '#fff0a7', '#fff1ab', '#fff3ae', '#fff4b2', '#fff6b6', '#fff7b9', '#fff9bd', '#fffac1', '#fffcc4', '#fffdc8', '#ffffcc']\n",
    "    colors_grorrd = ['#800026', '#850026', '#8a0026', '#8f0026', '#940026', '#990026', '#9e0026', '#a30026', '#a80026', '#ad0026', '#b20026', '#b70026', '#bd0026', '#c00225', '#c30424', '#c60623', '#c90822', '#cc0a21', '#d00d21', '#d30f20', '#d6111f', '#d9131e', '#dc151d', '#df171c', '#e31a1c', '#e51e1d', '#e7221e', '#e9271f', '#eb2b20', '#ed2f21', '#ef3423', '#f13824', '#f33c25', '#f54126', '#f74527', '#f94928', '#fc4e2a', '#fc532b', '#fc582d', '#fc5d2e', '#fc6330', '#fc6831', '#fc6d33', '#fc7234', '#fc7836', '#fc7d37', '#fc8239', '#fc873a', '#fd8d3c', '#fd903d', '#fd933e', '#fd9640', '#fd9941', '#fd9c42', '#fd9f44', '#fda245', '#fda546', '#fda848', '#fdab49', '#fdae4a', '#feb24c', '#feb54f', '#feb853', '#febb56', '#febf5a', '#fec25d', '#fec561', '#fec864', '#fecc68', '#fecf6b', '#fed26f', '#fed572', '#fed976', '#feda79', '#fedc7d', '#fede80', '#fedf84', '#fee187', '#fee38b', '#fee48e', '#fee692', '#fee895', '#fee999', '#feeb9c', '#ffeda0', '#fbeaa4', '#f7e8a8', '#f4e6ac', '#f0e4b1', '#ece2b5', '#e9e0b9', '#e5ddbd', '#e1dbc2', '#ded9c6', '#dad7ca', '#d6d5ce', '#d3d3d3']\n",
    "    colors_inferno = ['#000003', '#000004', '#000006', '#010007', '#010109', '#01010B', '#02010E', '#020210', '#030212', '#040314', '#040316', '#050418', '#06041B', '#07051D', '#08061F', '#090621', '#0A0723', '#0B0726', '#0D0828', '#0E082A', '#0F092D', '#10092F', '#120A32', '#130A34', '#140B36', '#160B39', '#170B3B', '#190B3E', '#1A0B40', '#1C0C43', '#1D0C45', '#1F0C47', '#200C4A', '#220B4C', '#240B4E', '#260B50', '#270B52', '#290B54', '#2B0A56', '#2D0A58', '#2E0A5A', '#300A5C', '#32095D', '#34095F', '#350960', '#370961', '#390962', '#3B0964', '#3C0965', '#3E0966', '#400966', '#410967', '#430A68', '#450A69', '#460A69', '#480B6A', '#4A0B6A', '#4B0C6B', '#4D0C6B', '#4F0D6C', '#500D6C', '#520E6C', '#530E6D', '#550F6D', '#570F6D', '#58106D', '#5A116D', '#5B116E', '#5D126E', '#5F126E', '#60136E', '#62146E', '#63146E', '#65156E', '#66156E', '#68166E', '#6A176E', '#6B176E', '#6D186E', '#6E186E', '#70196E', '#72196D', '#731A6D', '#751B6D', '#761B6D', '#781C6D', '#7A1C6D', '#7B1D6C', '#7D1D6C', '#7E1E6C', '#801F6B', '#811F6B', '#83206B', '#85206A', '#86216A', '#88216A', '#892269', '#8B2269', '#8D2369', '#8E2468', '#902468', '#912567', '#932567', '#952666', '#962666', '#982765', '#992864', '#9B2864', '#9C2963', '#9E2963', '#A02A62', '#A12B61', '#A32B61', '#A42C60', '#A62C5F', '#A72D5F', '#A92E5E', '#AB2E5D', '#AC2F5C', '#AE305B', '#AF315B', '#B1315A', '#B23259', '#B43358', '#B53357', '#B73456', '#B83556', '#BA3655', '#BB3754', '#BD3753', '#BE3852', '#BF3951', '#C13A50', '#C23B4F', '#C43C4E', '#C53D4D', '#C73E4C', '#C83E4B', '#C93F4A', '#CB4049', '#CC4148', '#CD4247', '#CF4446', '#D04544', '#D14643', '#D24742', '#D44841', '#D54940', '#D64A3F', '#D74B3E', '#D94D3D', '#DA4E3B', '#DB4F3A', '#DC5039', '#DD5238', '#DE5337', '#DF5436', '#E05634', '#E25733', '#E35832', '#E45A31', '#E55B30', '#E65C2E', '#E65E2D', '#E75F2C', '#E8612B', '#E9622A', '#EA6428', '#EB6527', '#EC6726', '#ED6825', '#ED6A23', '#EE6C22', '#EF6D21', '#F06F1F', '#F0701E', '#F1721D', '#F2741C', '#F2751A', '#F37719', '#F37918', '#F47A16', '#F57C15', '#F57E14', '#F68012', '#F68111', '#F78310', '#F7850E', '#F8870D', '#F8880C', '#F88A0B', '#F98C09', '#F98E08', '#F99008', '#FA9107', '#FA9306', '#FA9506', '#FA9706', '#FB9906', '#FB9B06', '#FB9D06', '#FB9E07', '#FBA007', '#FBA208', '#FBA40A', '#FBA60B', '#FBA80D', '#FBAA0E', '#FBAC10', '#FBAE12', '#FBB014', '#FBB116', '#FBB318', '#FBB51A', '#FBB71C', '#FBB91E', '#FABB21', '#FABD23', '#FABF25', '#FAC128', '#F9C32A', '#F9C52C', '#F9C72F', '#F8C931', '#F8CB34', '#F8CD37', '#F7CF3A', '#F7D13C', '#F6D33F', '#F6D542', '#F5D745', '#F5D948', '#F4DB4B', '#F4DC4F', '#F3DE52', '#F3E056', '#F3E259', '#F2E45D', '#F2E660', '#F1E864', '#F1E968', '#F1EB6C', '#F1ED70', '#F1EE74', '#F1F079', '#F1F27D', '#F2F381', '#F2F485', '#F3F689', '#F4F78D', '#F5F891', '#F6FA95', '#F7FB99', '#F9FC9D', '#FAFDA0', '#FCFEA4']\n",
    "    colors_magma = ['#000003', '#000004', '#000006', '#010007', '#010109', '#01010B', '#02020D', '#02020F', '#030311', '#040313', '#040415', '#050417', '#060519', '#07051B', '#08061D', '#09071F', '#0A0722', '#0B0824', '#0C0926', '#0D0A28', '#0E0A2A', '#0F0B2C', '#100C2F', '#110C31', '#120D33', '#140D35', '#150E38', '#160E3A', '#170F3C', '#180F3F', '#1A1041', '#1B1044', '#1C1046', '#1E1049', '#1F114B', '#20114D', '#221150', '#231152', '#251155', '#261157', '#281159', '#2A115C', '#2B115E', '#2D1060', '#2F1062', '#301065', '#321067', '#341068', '#350F6A', '#370F6C', '#390F6E', '#3B0F6F', '#3C0F71', '#3E0F72', '#400F73', '#420F74', '#430F75', '#450F76', '#470F77', '#481078', '#4A1079', '#4B1079', '#4D117A', '#4F117B', '#50127B', '#52127C', '#53137C', '#55137D', '#57147D', '#58157E', '#5A157E', '#5B167E', '#5D177E', '#5E177F', '#60187F', '#61187F', '#63197F', '#651A80', '#661A80', '#681B80', '#691C80', '#6B1C80', '#6C1D80', '#6E1E81', '#6F1E81', '#711F81', '#731F81', '#742081', '#762181', '#772181', '#792281', '#7A2281', '#7C2381', '#7E2481', '#7F2481', '#812581', '#822581', '#842681', '#852681', '#872781', '#892881', '#8A2881', '#8C2980', '#8D2980', '#8F2A80', '#912A80', '#922B80', '#942B80', '#952C80', '#972C7F', '#992D7F', '#9A2D7F', '#9C2E7F', '#9E2E7E', '#9F2F7E', '#A12F7E', '#A3307E', '#A4307D', '#A6317D', '#A7317D', '#A9327C', '#AB337C', '#AC337B', '#AE347B', '#B0347B', '#B1357A', '#B3357A', '#B53679', '#B63679', '#B83778', '#B93778', '#BB3877', '#BD3977', '#BE3976', '#C03A75', '#C23A75', '#C33B74', '#C53C74', '#C63C73', '#C83D72', '#CA3E72', '#CB3E71', '#CD3F70', '#CE4070', '#D0416F', '#D1426E', '#D3426D', '#D4436D', '#D6446C', '#D7456B', '#D9466A', '#DA4769', '#DC4869', '#DD4968', '#DE4A67', '#E04B66', '#E14C66', '#E24D65', '#E44E64', '#E55063', '#E65162', '#E75262', '#E85461', '#EA5560', '#EB5660', '#EC585F', '#ED595F', '#EE5B5E', '#EE5D5D', '#EF5E5D', '#F0605D', '#F1615C', '#F2635C', '#F3655C', '#F3675B', '#F4685B', '#F56A5B', '#F56C5B', '#F66E5B', '#F6705B', '#F7715B', '#F7735C', '#F8755C', '#F8775C', '#F9795C', '#F97B5D', '#F97D5D', '#FA7F5E', '#FA805E', '#FA825F', '#FB8460', '#FB8660', '#FB8861', '#FB8A62', '#FC8C63', '#FC8E63', '#FC9064', '#FC9265', '#FC9366', '#FD9567', '#FD9768', '#FD9969', '#FD9B6A', '#FD9D6B', '#FD9F6C', '#FDA16E', '#FDA26F', '#FDA470', '#FEA671', '#FEA873', '#FEAA74', '#FEAC75', '#FEAE76', '#FEAF78', '#FEB179', '#FEB37B', '#FEB57C', '#FEB77D', '#FEB97F', '#FEBB80', '#FEBC82', '#FEBE83', '#FEC085', '#FEC286', '#FEC488', '#FEC689', '#FEC78B', '#FEC98D', '#FECB8E', '#FDCD90', '#FDCF92', '#FDD193', '#FDD295', '#FDD497', '#FDD698', '#FDD89A', '#FDDA9C', '#FDDC9D', '#FDDD9F', '#FDDFA1', '#FDE1A3', '#FCE3A5', '#FCE5A6', '#FCE6A8', '#FCE8AA', '#FCEAAC', '#FCECAE', '#FCEEB0', '#FCF0B1', '#FCF1B3', '#FCF3B5', '#FCF5B7', '#FBF7B9', '#FBF9BB', '#FBFABD', '#FBFCBF']\n",
    "    colors_ylgnbl = ['#081d58', '#0a1e5d', '#0c2062', '#0f2267', '#11246c', '#142671', '#162876', '#182a7b', '#1b2c80', '#1d2e85', '#20308a', '#22328f', '#253494', '#243795', '#243b97', '#243e99', '#24429a', '#23459c', '#23499e', '#234c9f', '#2350a1', '#2253a3', '#2257a4', '#225aa6', '#225ea8', '#2162aa', '#2166ac', '#206aae', '#206fb0', '#1f73b2', '#1f77b4', '#1f7bb6', '#1e80b8', '#1e84ba', '#1d88bc', '#1d8cbe', '#1d91c0', '#2094c0', '#2397c0', '#269ac1', '#299dc1', '#2ca0c1', '#2fa3c2', '#32a6c2', '#35a9c2', '#38acc3', '#3bafc3', '#3eb2c3', '#41b6c4', '#46b7c3', '#4bb9c2', '#50bbc1', '#55bdc1', '#5abfc0', '#60c1bf', '#65c3be', '#6ac5be', '#6fc7bd', '#74c9bc', '#79cbbb', '#7fcdbb', '#85cfba', '#8bd1b9', '#91d4b9', '#97d6b8', '#9dd8b8', '#a3dbb7', '#a9ddb6', '#afdfb6', '#b5e2b5', '#bbe4b5', '#c1e6b4', '#c7e9b4', '#caeab3', '#cdebb3', '#d0ecb3', '#d3eeb3', '#d6efb2', '#daf0b2', '#ddf1b2', '#e0f3b2', '#e3f4b1', '#e6f5b1', '#e9f6b1', '#edf8b1', '#eef8b4', '#f0f9b7', '#f1f9bb', '#f3fabe', '#f4fac1', '#f6fbc5', '#f7fcc8', '#f9fccb', '#fafdcf', '#fcfdd2', '#fdfed5', '#ffffd9']\n",
    "    colors_rdylbl = ['#a50026', '#a60529', '#a80a2c', '#aa0f2f', '#ac1432', '#ae1a35', '#b01f38', '#b1243b', '#b3293e', '#b52e42', '#b73445', '#b93948', '#bb3e4b', '#bc434e', '#be4851', '#c04e54', '#c25357', '#c4585b', '#c65d5e', '#c76261', '#c96864', '#cb6d67', '#cd726a', '#cf776d', '#d17c70', '#d28274', '#d48777', '#d68c7a', '#d8917d', '#da9680', '#dc9c83', '#dda186', '#dfa689', '#e1ab8d', '#e3b090', '#e5b693', '#e7bb96', '#e8c099', '#eac59c', '#ecca9f', '#eed0a2', '#f0d5a6', '#f2daa9', '#f3dfac', '#f5e4af', '#f7eab2', '#f9efb5', '#fbf4b8', '#fdf9bb', '#ffffbf', '#fafabe', '#f6f6bd', '#f2f2bc', '#eeeebb', '#e9eaba', '#e5e6b9', '#e1e2b9', '#dddeb8', '#d9dab7', '#d4d5b6', '#d0d1b5', '#cccdb4', '#c8c9b3', '#c4c5b3', '#bfc1b2', '#bbbdb1', '#b7b9b0', '#b3b5af', '#afb1ae', '#aaacad', '#a6a8ad', '#a2a4ac', '#9ea0ab', '#9a9caa', '#9598a9', '#9194a8', '#8d90a7', '#898ca7', '#8588a6', '#8083a5', '#7c7fa4', '#787ba3', '#7477a2', '#7073a1', '#6b6fa1', '#676ba0', '#63679f', '#5f639e', '#5b5f9d', '#565a9c', '#52569b', '#4e529b', '#4a4e9a', '#464a99', '#414698', '#3d4297', '#393e96', '#353a95', '#313695']\n",
    "    colors_grlgrdgr = ['#0d2b17', '#0e2d17', '#0f2f17', '#103118', '#123318', '#133618', '#143819', '#153a19', '#173c1a', '#183e1a', '#19411a', '#1a431b', '#1c451b', '#1d471b', '#1e4a1c', '#1f4c1c', '#214e1d', '#22501d', '#23521d', '#24551e', '#26571e', '#27591e', '#285b1f', '#295e1f', '#2b6020', '#2c6220', '#2d6420', '#2f6621', '#306921', '#316b22', '#326d22', '#346f22', '#357223', '#367423', '#377623', '#397824', '#3a7a24', '#3b7d25', '#3c7f25', '#3e8125', '#3f8326', '#408626', '#418826', '#438a27', '#448c27', '#458e28', '#469128', '#489328', '#499529', '#4a9729', '#4c9a2a', '#4e9b2d', '#519c30', '#549d34', '#569e37', '#599f3a', '#5ca03e', '#5ea141', '#61a345', '#64a448', '#67a54b', '#69a64f', '#6ca752', '#6fa855', '#71a959', '#74ab5c', '#77ac60', '#79ad63', '#7cae66', '#7faf6a', '#82b06d', '#84b170', '#87b374', '#8ab477', '#8cb57b', '#8fb67e', '#92b781', '#94b885', '#97b988', '#9abb8c', '#9dbc8f', '#9fbd92', '#a2be96', '#a5bf99', '#a7c09c', '#aac1a0', '#adc3a3', '#afc4a7', '#b2c5aa', '#b5c6ad', '#b8c7b1', '#bac8b4', '#bdc9b7', '#c0cbbb', '#c2ccbe', '#c5cdc2', '#c8cec5', '#cacfc8', '#cdd0cc', '#d0d1cf', '#d3d3d3']\n",
    "    colors = colors_grlgrdgr\n",
    "    colors.reverse()\n",
    "    mapper = LinearColorMapper(palette=colors, low=0, high=100)\n",
    "\n",
    "    #Bokeh figure\n",
    "    p = figure(\n",
    "        plot_width= width,\n",
    "        plot_height=height,\n",
    "        #title=\"Example freq\",\n",
    "        y_range=list(dataframe.Id.drop_duplicates()),\n",
    "        x_range=list(dataframe.Residue.drop_duplicates()),\n",
    "        tools=[\"hover\",\"tap\",\"save\",\"reset\",\"wheel_zoom\"], \n",
    "        x_axis_location=\"above\",\n",
    "        active_drag=None,\n",
    "        toolbar_location=\"right\",\n",
    "        toolbar_sticky = False,\n",
    "        # min_border_top = 250,#leave some space for x-axis artificial labels\n",
    "        min_border_bottom = 0,\n",
    "    )\n",
    "\n",
    "    # Create rectangle for heatmap\n",
    "    mysource = ColumnDataSource(dataframe)\n",
    "    p.rect(\n",
    "        y=\"Id\", \n",
    "        x=\"Residue\",\n",
    "        width=1, \n",
    "        height=1, \n",
    "        source=mysource,\n",
    "        line_color=\"white\", \n",
    "        fill_color=transform(\"freq\", mapper),\n",
    "\n",
    "        # set visual properties for selected glyphs\n",
    "        selection_line_color=\"black\",\n",
    "        selection_fill_color=transform(\"freq\", mapper),\n",
    "        # set visual properties for non-selected glyphs\n",
    "        nonselection_fill_color=transform(\"freq\", mapper),\n",
    "        nonselection_fill_alpha=1,\n",
    "        nonselection_line_alpha=1,\n",
    "        nonselection_line_color=\"white\"\n",
    "        )\n",
    "\n",
    "    #Very poor way of creating X-axis labels. Necessary for having linejumps inside the axis labels\n",
    "    x_cord = 0\n",
    "    y_cord = len(list(dataframe.Id.drop_duplicates()))#Residue: 11 spaces above the plot's top border\n",
    "    foolabel = Label(x=-3,\n",
    "                     y=y_cord,\n",
    "                     text='\\n\\n           A: \\n           B: \\n           C: \\n           F: \\n\\nG protein: \\n\\n\\n',\n",
    "                     render_mode='css', \n",
    "                     border_line_alpha=1.0,\n",
    "                     text_font_size = \"10pt\",\n",
    "                     background_fill_color = \"#FFFFFF\")\n",
    "    p.add_layout(foolabel)\n",
    "\n",
    "    #Fore every unique Residue in the set, add a label in axis\n",
    "    for Residue in list(dataframe.Residue.drop_duplicates()):\n",
    "        Residue = Residue.replace(\"Ligand\",\"Lig\\n\\n\\n\\n\\n\")\n",
    "        foolabel = Label(x=x_cord,\n",
    "                         y=y_cord,\n",
    "                         text=Residue,\n",
    "                         render_mode='css', \n",
    "                         border_line_alpha=1.0,\n",
    "                         background_fill_color = \"#FFFFFF\",\n",
    "                         text_font_size = \"10pt\")\n",
    "        p.add_layout(foolabel)\n",
    "        x_cord +=1\n",
    "\n",
    "    # Setting axis\n",
    "    p.axis.axis_line_color = None\n",
    "    p.axis.major_tick_line_color = None\n",
    "    p.xaxis.major_label_text_font_size = \"10pt\"\n",
    "    p.yaxis.major_label_text_font_size = \"10pt\"\n",
    "    p.yaxis.visible = False\n",
    "    p.xaxis.visible = False\n",
    "    p.axis.major_label_standoff = 0\n",
    "    p.xaxis.major_label_orientation = 1\n",
    "\n",
    "    # Adding hover\n",
    "    p.add_tools(hover)\n",
    "\n",
    "    # Needed later\n",
    "    return(mysource,p)\n",
    "\n",
    "def select_tool_callback(partial_db_dict, gennum, itype, typelist, mysource):\n",
    "    \"\"\"\n",
    "    Prepares the javascript script necessary for the side-window\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # Datasource for generic numberings\n",
    "    df_gnum=pd.DataFrame(gennum)\n",
    "    gnum_source=ColumnDataSource(df_gnum)\n",
    "\n",
    "    #Select tool and callback: (SIMPLIFIED)\n",
    "    CB = CustomJS(\n",
    "        args={\"mysource\" : mysource, \"db_info\":partial_db_dict, \"gnum_info\":gnum_source, \"itype\":itype, \"typelist\" : typelist},\n",
    "        code=\"\"\"\n",
    "            var sel_ind = mysource.selected.indices[0];\n",
    "            var plot_bclass=$(\"#retracting_parts\").attr(\"class\");\n",
    "            if (sel_ind.length != 0){\n",
    "                var data = mysource.data;\n",
    "                var gnum_data=gnum_info.data;\n",
    "                var recept_name=data[\"Name\"][sel_ind];\n",
    "                var dyn_id=data[\"Id\"][sel_ind];\n",
    "                var db_dyn = db_info[dyn_id]\n",
    "                var resnamegnum = data[\"resname_gennum\"][sel_ind];\n",
    "                var gnums_array = resnamegnum.split(\" \").map(val => { return val.slice(1) })\n",
    "                var pos = data[\"resID\"][sel_ind];\n",
    "                var freq_type=data[\"freq\"][sel_ind];\n",
    "                var pos_array = pos.split(\" \");\n",
    "                var pos_string = pos_array.join(\"_\")\n",
    "\n",
    "                //We'll remove the last 4 characters of each label, corresponding to the residue name\n",
    "                var pos_ind_array = gnums_array.map(value => { return gnum_data['index'].indexOf(value); });\n",
    "                var nglsel_pos_array = pos_ind_array.map(value => { return gnum_data[dyn_id][value].slice(0,-4); });\n",
    "\n",
    "                //Put db_data of this sym into variables\n",
    "                var lig=db_dyn['lig_sname'];\n",
    "                var lig_lname=db_dyn['lig_lname'];\n",
    "                var recept=db_dyn['up_name'];\n",
    "                var dId=dyn_id.match(/\\d*$/)[0];\n",
    "                var prot_id=db_dyn['prot_id'];\n",
    "                var prot_lname=db_dyn['prot_lname'];\n",
    "                var comp_id=db_dyn['comp_id'];\n",
    "                var peplig=db_dyn['peplig']\n",
    "                var struc_fname=db_dyn['struc_fname'];\n",
    "                var struc_file=db_dyn['struc_f'];\n",
    "                var traj_fnames=db_dyn['traj_fnames'];\n",
    "                var traj_f=db_dyn['traj_f'];\n",
    "                var pdb_id=db_dyn['pdb_id'];\n",
    "                var pdb_id_nochain = pdb_id.split(\".\")[0];\n",
    "                var gpcr_chain=db_dyn['gpcr_chain'];\n",
    "                var gprot_chain=db_dyn['gprot_chain'];\n",
    "                var delta=db_dyn['delta'];\n",
    "             \n",
    "                if (plot_bclass != \"col-xs-9\"){\n",
    "                    $(\"#retracting_parts\").attr(\"class\",\"col-xs-9\");\n",
    "                    $(\"#first_col\").attr(\"class\",\"col-xs-7\");\n",
    "                    $(\"#second_col\").attr(\"class\",\"col-xs-5\");\n",
    "                    $(\"#info\").css({\"visibility\":\"visible\",\"position\":\"relative\",\"z-index\":\"auto\"});\n",
    "                }\n",
    "                \n",
    "                //Show NA comment if there is a NA in the Residue\n",
    "                if(/N\\/A/.test(resnamegnum)){\n",
    "                    $('#na_comment').show();\n",
    "                }\n",
    "\n",
    "                //Setting type specific frequencies\n",
    "                $( \"#freq_\" + itype).html(freq_type.toFixed(2) + \"%\");\n",
    "                if (itype == \"all\") {\n",
    "                    var my_type;\n",
    "                    for (my_type in typelist) {\n",
    "                        freq_type = data[my_type][sel_ind];\n",
    "                        $( \"#freq_\" + my_type).html(parseFloat(freq_type).toFixed(2) + \"%\");\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                $(\"#recept_val\").html(prot_lname + \" (\"+recept+\")\");\n",
    "                $(\"#pos_val\").html(resnamegnum);\n",
    "                $(\"#pdb_id\").html(pdb_id);\n",
    "                $(\"#pdb_link\").attr(\"href\",\"https://www.rcsb.org/structure/\" + pdb_id_nochain)\n",
    "                if (Boolean(lig)) {\n",
    "                    $(\"#lig_link\").show();\n",
    "                    if (peplig){\n",
    "                        $(\"#lig_val\").html(lig_lname);\n",
    "                        $(\"#lig_link\").attr(\"href\",\"../../../dynadb/protein/id/\"+comp_id);\n",
    "                    } else {\n",
    "                        $(\"#lig_val\").html(lig_lname + \" (\"+lig+\")\");\n",
    "                        $(\"#lig_link\").attr(\"href\",\"../../../dynadb/compound/id/\"+comp_id);\n",
    "                    }\n",
    "                }\n",
    "                else {\n",
    "                    $(\"#lig_val\").html(\"None\");\n",
    "                    $(\"#lig_link\").hide();\n",
    "                }\n",
    "                $(\"#viewer_link\").attr(\"href\",\"../../../view/\"+dId+\"/\"+pos_string);\n",
    "                $(\"#recept_link\").attr(\"href\",\"../../../dynadb/protein/id/\"+prot_id);\n",
    "                \n",
    "                console.log(gpcr_chain,gprot_chain)\n",
    "                $('#ngl_iframe')[0].contentWindow.$('body').trigger('createNewRef', \n",
    "                [struc_file, traj_fnames, traj_f ,lig, delta, pos, nglsel_pos_array, gpcr_chain, gprot_chain]);\n",
    "\n",
    "            } else {\n",
    "                if (plot_bclass != \"col-xs-12\"){\n",
    "                    $(\"#retracting_parts\").attr(\"class\",\"col-xs-12\");\n",
    "                    $(\"#info\").css({\"visibility\":\"hidden\",\"position\":\"absolute\",\"z-index\":\"-1\"});\n",
    "                } \n",
    "            }           \n",
    "        \"\"\")\n",
    "\n",
    "    p.js_on_event(Tap,CB)\n",
    "    return(p)\n",
    "\n",
    "# Three to one dictionary for residues\n",
    "three_to_one = {\n",
    "    'ALA': 'A',  # Alanine\n",
    "    'ARG': 'R',  # Arginine\n",
    "    'ASN': 'N',  # Asparagine\n",
    "    'ASP': 'D',  # Aspartic Acid\n",
    "    'CYS': 'C',  # Cysteine\n",
    "    'GLU': 'E',  # Glutamic Acid\n",
    "    'GLN': 'Q',  # Glutamine\n",
    "    'GLY': 'G',  # Glycine\n",
    "    'HIS': 'H',  # Histidine (neutral form)\n",
    "    'HSD': 'H',  # Histidine (delta-protonated)\n",
    "    'HSE': 'H',  # Histidine (epsilon-protonated)\n",
    "    'HSP': 'H',  # Histidine (protonated on both delta and epsilon)\n",
    "    'HID': 'H',  # Histidine (delta-protonated)\n",
    "    'HIE': 'H',  # Histidine (epsilon-protonated)\n",
    "    'HIP': 'H',  # Histidine (protonated on both delta and epsilon)    \n",
    "    'ILE': 'I',  # Isoleucine\n",
    "    'LEU': 'L',  # Leucine\n",
    "    'LYS': 'K',  # Lysine (neutral form)\n",
    "    'LYN': 'K',  # Lysine (protonated)\n",
    "    'MET': 'M',  # Methionine\n",
    "    'PHE': 'F',  # Phenylalanine\n",
    "    'PRO': 'P',  # Proline\n",
    "    'SER': 'S',  # Serine\n",
    "    'THR': 'T',  # Threonine\n",
    "    'TRP': 'W',  # Tryptophan\n",
    "    'TYR': 'Y',  # Tyrosine\n",
    "    'VAL': 'V'   # Valine\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####################\n",
    "## Initial variables\n",
    "####################\n",
    "\n",
    "# Set paths\n",
    "server_filespath = \"/GPCRmd/media/files/Precomputed/gpcr_gprot/web_inputs/\"\n",
    "# filespath = settings.MEDIA_ROOT\n",
    "mediaroot = \"/home/daranda/files_kasparov/\"\n",
    "precompath = mediaroot+\"Precomputed/\"\n",
    "gpcrgprot_path = precompath + \"gpcr_gprot/\"\n",
    "interta_path = gpcrgprot_path+\"inter_tables/\"\n",
    "os.makedirs(interta_path, exist_ok=True)\n",
    "\n",
    "# Load Database information from compl_info.json file\n",
    "db_dict = json_dict(precompath + \"compl_info.json\")\n",
    "\n",
    "# Load flareplot template\n",
    "df_path = \"%sall.tsv\"%interta_path\n",
    "df_raw = pd.read_csv(df_path, sep=\"\\s+\")\n",
    "template_path = gpcrgprot_path + \"template.json\" \n",
    "flareplot_template_gpcrgprot(df_raw, template_path)\n",
    "flare_template = json_dict(template_path)\n",
    "\n",
    "# Interaction types and corresponding names\n",
    "typelist =  {\n",
    "    'all' : 'all types',\n",
    "    'sb' : 'salt bridge',\n",
    "    \"pc\" : 'pi-cation',\n",
    "    \"ps\" : 'pi-stacking',\n",
    "    'ts' : 't-stacking',\n",
    "    \"vdw\" : 'van der waals',\n",
    "    'hp' : 'hydrophobic',\n",
    "    \"hbbb\" : 'backbone to backbone HB',\n",
    "    \"hbsb\" : 'sidechain to backbone HB',\n",
    "    \"hbss\" : 'sidechain to sidechain HB',\n",
    "    \"wb\" : 'water bridge',\n",
    "    \"wb2\" : 'extended water bridge',\n",
    "    \"hb\" : 'hydrogen bonds',\n",
    "}\n",
    "hb_itypes = {\n",
    "    \"hbbb\" : 'backbone to backbone',\n",
    "    \"hbsb\" : 'sidechain to backbone',\n",
    "    \"hbss\" : 'sidechain to sidechain',\n",
    "}\n",
    "other_itypes = {\n",
    "    'hp' : 'hydrophobic',\n",
    "    'sb' : 'salt bridge',\n",
    "    \"pc\" : 'pi-cation',\n",
    "    \"ps\" : 'pi-stacking',\n",
    "    'ts' : 't-stacking',\n",
    "    \"vdw\" : 'van der waals',\n",
    "    \"wb\" : 'water bridge',\n",
    "    \"wb2\" : 'extended water bridge',\n",
    "\n",
    "}\n",
    "\n",
    "itypes_order = [\n",
    "    (\"Non-polar\", \n",
    "        (\n",
    "            (\"vdw\",\"van der waals\"),\n",
    "            ('hp', \"hydrophobic\")\n",
    "        )\n",
    "    ),\n",
    "    (\"Polar/Electrostatic\", \n",
    "        (\n",
    "            (\"hb\", \"hydrogen bond\"),\n",
    "            (\"wb\", \"water bridge\"),\n",
    "            (\"wb2\", \"extended water bridge\"),\n",
    "            ('sb', \"salt bridge\"),\n",
    "            (\"pc\", \"pi-cation\")\n",
    "        )\n",
    "    ),\n",
    "    (\"Stacking\",\n",
    "        (\n",
    "            (\"ps\", \"pi-stacking\"),\n",
    "            ('ts', \"t-stacking\")\n",
    "        )\n",
    "    )\n",
    "]\n",
    "cores = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing contmaps inputs for wb\n",
      "      computing dendrogram with 2 clusters\n",
      "      computing dendrogram with 3 clusters\n",
      "                                    dyn1200  dyn1201  dyn1203  dyn1204   APos  \\\n",
      "Residue                                                                         \n",
      "5x\\n68\\n64\\n68\\n71\\n\\nG\\nH5\\n13        51.4     80.2      0.0     78.8   5x68   \n",
      "6x\\n32\\n37\\n34\\n31\\n\\nG\\nH5\\n26        30.8     71.2     34.8     40.2   6x32   \n",
      "8x\\n49\\n49\\n49\\n49\\n\\nG\\nH5\\n22        47.7     38.7     83.3      1.3   8x49   \n",
      "5x\\n71\\n67\\n71\\n74\\n\\nG\\nH5\\n13        87.1     15.8     47.7      0.0   5x71   \n",
      "2x\\n39\\n46\\n35\\n38\\n\\nG\\nH5\\n22         0.9     49.9     84.5      0.0   2x39   \n",
      "3x\\n50\\n54\\n54\\n50\\n\\nG\\nH5\\n22         3.6      0.6     45.9     66.7   3x50   \n",
      "3x\\n50\\n54\\n54\\n50\\n\\nG\\nH5\\n23        25.6     26.9     37.5     59.6   3x50   \n",
      "3x\\n50\\n54\\n54\\n50\\n\\nG\\nH5\\n24         0.5     67.6     40.6      0.2   3x50   \n",
      "6x\\n36\\n41\\n38\\n35\\n\\nG\\nH5\\n24        46.3      0.8     35.0     37.1   6x36   \n",
      "2x\\n40\\n47\\n36\\n39\\n\\nG\\nH5\\n22         1.6     31.3     58.6      5.1   2x40   \n",
      "6x\\n29\\n34\\n31\\n28\\n\\nG\\nH5\\n26        41.5      0.0     13.3     56.0   6x29   \n",
      "34x\\n55\\n55\\n55\\n55\\n\\nG\\nHN\\n52       33.8     37.1     31.2      1.0  34x55   \n",
      "34x\\n54\\n54\\n54\\n54\\n\\nG\\nhns1\\n02     56.4      3.2     49.1      6.1  34x54   \n",
      "3x\\n49\\n53\\n53\\n49\\n\\nG\\nH5\\n23        49.9     13.1     35.3      0.0   3x49   \n",
      "34x\\n53\\n53\\n53\\n53\\n\\nG\\nH5\\n23       36.1      0.8     52.9      0.0  34x53   \n",
      "\n",
      "                                     BPos   CPos   FPos     GprotPos  \n",
      "Residue                                                               \n",
      "5x\\n68\\n64\\n68\\n71\\n\\nG\\nH5\\n13      5x64   5x68   5x71    G\\nH5\\n13  \n",
      "6x\\n32\\n37\\n34\\n31\\n\\nG\\nH5\\n26      6x37   6x34   6x31    G\\nH5\\n26  \n",
      "8x\\n49\\n49\\n49\\n49\\n\\nG\\nH5\\n22      8x49   8x49   8x49    G\\nH5\\n22  \n",
      "5x\\n71\\n67\\n71\\n74\\n\\nG\\nH5\\n13      5x67   5x71   5x74    G\\nH5\\n13  \n",
      "2x\\n39\\n46\\n35\\n38\\n\\nG\\nH5\\n22      2x46   2x35   2x38    G\\nH5\\n22  \n",
      "3x\\n50\\n54\\n54\\n50\\n\\nG\\nH5\\n22      3x54   3x54   3x50    G\\nH5\\n22  \n",
      "3x\\n50\\n54\\n54\\n50\\n\\nG\\nH5\\n23      3x54   3x54   3x50    G\\nH5\\n23  \n",
      "3x\\n50\\n54\\n54\\n50\\n\\nG\\nH5\\n24      3x54   3x54   3x50    G\\nH5\\n24  \n",
      "6x\\n36\\n41\\n38\\n35\\n\\nG\\nH5\\n24      6x41   6x38   6x35    G\\nH5\\n24  \n",
      "2x\\n40\\n47\\n36\\n39\\n\\nG\\nH5\\n22      2x47   2x36   2x39    G\\nH5\\n22  \n",
      "6x\\n29\\n34\\n31\\n28\\n\\nG\\nH5\\n26      6x34   6x31   6x28    G\\nH5\\n26  \n",
      "34x\\n55\\n55\\n55\\n55\\n\\nG\\nHN\\n52    34x55  34x55  34x55    G\\nHN\\n52  \n",
      "34x\\n54\\n54\\n54\\n54\\n\\nG\\nhns1\\n02  34x54  34x54  34x54  G\\nhns1\\n02  \n",
      "3x\\n49\\n53\\n53\\n49\\n\\nG\\nH5\\n23      3x53   3x53   3x49    G\\nH5\\n23  \n",
      "34x\\n53\\n53\\n53\\n53\\n\\nG\\nH5\\n23    34x53  34x53  34x53    G\\nH5\\n23  \n",
      "No interactions avalible for this molecular partners and interaction type:wb-stnd\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#######\n",
    "## Main\n",
    "#######\n",
    "\n",
    "# typelist =  {\"all\" : 'all types'}\n",
    "typelist =  {\"wb\" : 'water bridge'}\n",
    "for itype in typelist.keys():\n",
    "\n",
    "    #####################\n",
    "    # Adjusting dataframe\n",
    "    #####################\n",
    "    \n",
    "    # Load data\n",
    "    df_path = \"%s%s.tsv\"%(interta_path, itype)\n",
    "    if not os.path.exists(df_path):\n",
    "        print(\"no data for interaction type %s. Skipping...\"%itype)\n",
    "        continue\n",
    "    df_raw = pd.read_csv(df_path, sep=\"\\s+\")\n",
    "    print(\"Computing contmaps inputs for %s\" % (itype))\n",
    "\n",
    "    # Prepare table: filter low-freq inters, pass freqs to percentage, ....\n",
    "    (df_all,df_standard) = prepare_table(df_raw,db_dict)\n",
    "\n",
    "    # Make simulation-individual flareplots\n",
    "    sim_jsons_path = '%sweb_inputs/%s/flareplots_sims/'%(gpcrgprot_path,itype) \n",
    "    dyn_flareplots(df_all, sim_jsons_path, flare_template)\n",
    "    \n",
    "    #Repeat everything for standartd and non-standard dataframes (our simulations and the simulations from everone in GPCRmd)\n",
    "    for (stnd,df) in ((\"cmpl\", df_all), (\"stnd\", df_standard)):\n",
    "        \n",
    "        # If there are no interactions with this ligandonly-itype combination\n",
    "        if df.empty:\n",
    "            print(\"No interactions avalible for this molecular partners and interaction type:%s-%s\"%(itype,stnd)) \n",
    "            continue\n",
    "\n",
    "        # Folders for heatmaps and dendrograms\n",
    "        outputs_serverpath = \"%s/%s/%s/\" %(server_filespath, itype, stnd)\n",
    "        outputs_path = \"%sweb_inputs/%s/%s/\" %(gpcrgprot_path, itype, stnd)\n",
    "        os.makedirs(outputs_path, exist_ok=True)\n",
    "        \n",
    "        # Stack matrix (one row for each interaction pair and dynamic).\n",
    "#       # Colnames are dynid,Residue and interaction frequency)\n",
    "        df_ts = df.transpose().stack().reset_index()\n",
    "        df_ts.columns = ['Id','Residue','freq']\n",
    "\n",
    "        #Obtain information of each receptor such as their names and stuff\n",
    "        (partial_db_dict,df_ts,gennum)=improve_receptor_names(df_ts,db_dict)\n",
    "        \n",
    "        # Create new column with both residue names and generic numbering of both residues interacting\n",
    "        df_ts = df_ts.apply(lambda x: find_resnames_resids(x, db_dict, three_to_one),axis=1)\n",
    "        \n",
    "        #Storing dataframe with results in a CSV file, downloadable from web\n",
    "        create_csvfile(outputs_path, partial_db_dict, df)\n",
    "\n",
    "        ######################\n",
    "        ## Create and save precomputed files for dendrograms shown left-side of heatmap\n",
    "        ######################\n",
    "        (dyn_dend_order,dend_height) = dendrogramming(df,outputs_path,partial_db_dict)\n",
    "    \n",
    "        ###########\n",
    "        ## Heatmaps\n",
    "        ###########\n",
    "\n",
    "        # Sort according to dendrogram results\n",
    "        df_ts = sort_simulations(df_ts, dyn_dend_order)\n",
    "\n",
    "        #Taking some variables for dataframe slicing\n",
    "        max_columns = 45\n",
    "        pairs_number = df.shape[0]\n",
    "        inter_number = df_ts.shape[0]\n",
    "        inter_per_pair =  inter_number/pairs_number \n",
    "        number_heatmaps = ceil((inter_number/inter_per_pair)/max_columns)\n",
    "\n",
    "        #Create heatmap folder if not yet exists\n",
    "        heatmap_serverpath = \"%sheatmaps/\" % (outputs_serverpath)\n",
    "        heatmap_path = \"%sheatmaps/\" % (outputs_path)\n",
    "        os.makedirs(heatmap_path, exist_ok=True)\n",
    "\n",
    "        # Append frequencies for all interaction types, if we are parsing itype 'all'\n",
    "        if itype=='all':\n",
    "            df_ts = find_itype_freqs(df_ts,typelist)\n",
    "        \n",
    "        #Saving dataframe for future uses in customized heatmaps\n",
    "        df_ts.to_pickle(heatmap_path+\"dataframe_for_customized.pkl\")\n",
    "\n",
    "        #Make heatmaps each 50 interacting pairs\n",
    "        div_list = []\n",
    "        heatmap_filename_list = []\n",
    "        number_heatmap_list = []\n",
    "        prev_slicepoint = 0\n",
    "        pool = mp.Pool(cores)\n",
    "        for i in range(1,number_heatmaps+1):\n",
    "            number_heatmap_list.append(str(i))\n",
    "\n",
    "            #Slice dataframe. Also definig heigth and width of the heatmap\n",
    "            slicepoint = int(i*inter_per_pair*max_columns)\n",
    "            if i == number_heatmaps:\n",
    "                df_slided = df_ts[prev_slicepoint:]\n",
    "            else:\n",
    "                df_slided = df_ts[prev_slicepoint:slicepoint]\n",
    "            w = int(df_slided.shape[0]/inter_per_pair*20+40)\n",
    "            prev_slicepoint = slicepoint\n",
    "            h=dend_height\n",
    "            \n",
    "            # Define bokeh figure and hovertool\n",
    "            hover = create_hovertool(itype, itypes_order, hb_itypes, typelist)\n",
    "            mysource,p = define_figure(w, h, df_slided, hover, itype)\n",
    "\n",
    "            # Creating javascript for side-window\n",
    "            p = select_tool_callback(partial_db_dict, gennum, itype, typelist, mysource)\n",
    "\n",
    "            # Extract bokeh plot components and store them in lists\n",
    "            script, div = components(p)\n",
    "\n",
    "            # Write heatmap on file\n",
    "            heatmap_filename = \"%s%iheatmap.html\" % (heatmap_path,i)\n",
    "            with open(heatmap_filename, 'w') as heatmap:\n",
    "                heatmap.write(script)\n",
    "            \n",
    "            # Save names of files and divs in lists, to be used by web app\n",
    "            div_list.append(div.lstrip())\n",
    "            heatmap_serverfilename = \"%s%iheatmap.html\" % (heatmap_serverpath,i)\n",
    "            heatmap_filename_list.append(heatmap_serverfilename)\n",
    "                \n",
    "        pool.close()\n",
    "        pool.join()             \n",
    "        \n",
    "        # Write server filenames of heatmaps and variables in a file\n",
    "        variables_file = outputs_path+\"variables.py\" \n",
    "        with open(variables_file, 'w') as varfile:\n",
    "            varfile.write(\"div_list = [\\'%s\\']\\n\" % \"\\',\\'\".join(div_list))\n",
    "            varfile.write(\"heatmap_filename_list = [\\'%s\\']\\n\" % \"\\',\\'\".join(heatmap_filename_list))\n",
    "            varfile.write(\"number_heatmaps_list = [\\'%s\\']\\n\" % \"\\',\\'\".join(number_heatmap_list))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
