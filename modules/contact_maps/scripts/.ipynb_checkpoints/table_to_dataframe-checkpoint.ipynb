{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib# MANDATORY TO BE IN FIRST PLACE!!\n",
    "matplotlib.use('Agg')# MANDATORY TO BE IN SECOND PLACE!!\n",
    "from sys import argv,exit\n",
    "import pandas as pd\n",
    "from  numpy import array\n",
    "from json import loads, dump\n",
    "from  plotly.figure_factory import create_dendrogram\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from math import ceil,pi\n",
    "from bokeh.plotting import figure, show, reset_output\n",
    "from bokeh.embed import components\n",
    "from bokeh.models import Label, HoverTool, TapTool, CustomJS, BasicTicker, ColorBar, ColumnDataSource, LinearColorMapper, PrintfTickFormatter\n",
    "from bokeh.transform import transform\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "import time\n",
    "\n",
    "# Be careful with this!!! Put here only because some false-positive warnings from pandas\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def json_dict(path):\n",
    "    \"\"\"Converts json file to pyhton dict.\"\"\"\n",
    "    json_file=open(path)\n",
    "    json_str = json_file.read()\n",
    "    json_data = loads(json_str)\n",
    "    return json_data\n",
    "\n",
    "def improve_receptor_names(df_ts,compl_data):\n",
    "    \"\"\"\n",
    "    Parses the dataframe to create the data source of the plot. When defining a name for each dynamics entry: if there is any other dynamics in the \n",
    "    datadrame that is created fromt he same pdb id and ligand, all these dynamics will indicate the dynamics id\n",
    "    \"\"\"\n",
    "    recept_info={}\n",
    "    recept_info_order={\n",
    "        \"upname\":0,\n",
    "        \"lig_sname\":1,\n",
    "        \"dyn_id\":2,\n",
    "        \"prot_id\":3,\n",
    "        \"comp_id\":4,\n",
    "        \"prot_lname\":5,\n",
    "        \"pdb_id\":6,\n",
    "        \"lig_lname\":7,\n",
    "        \"struc_fname\":8,\n",
    "        \"struc_f\":9,\n",
    "        \"traj_fnames\":10,\n",
    "        \"traj_f\":11,\n",
    "        \"delta\":12,\n",
    "        \"receptor_unique_name\":13,\n",
    "        'gpcr_class':14\n",
    "    }\n",
    "    dyns_by_receptor={}\n",
    "    index_dict={}\n",
    "    dyn_gpcr_pdb={}\n",
    "    for recept_id in df_ts['Id']:\n",
    "        dyn_id=recept_id\n",
    "        upname=compl_data[recept_id][\"up_name\"]\n",
    "        lig_sname=compl_data[recept_id][\"lig_sname\"]\n",
    "        lig_lname=compl_data[recept_id][\"lig_lname\"]\n",
    "        prot_id=compl_data[recept_id][\"prot_id\"]\n",
    "        comp_id=compl_data[recept_id][\"comp_id\"]\n",
    "        prot_lname=compl_data[recept_id][\"prot_lname\"]\n",
    "        pdb_id=compl_data[recept_id][\"pdb_id\"]\n",
    "        struc_fname=compl_data[recept_id][\"struc_fname\"]\n",
    "        struc_f=compl_data[recept_id][\"struc_f\"]\n",
    "        traj_fnames=compl_data[recept_id][\"traj_fnames\"]\n",
    "        traj_f=compl_data[recept_id][\"traj_f\"]\n",
    "        delta=compl_data[recept_id][\"delta\"]\n",
    "        sim__fullname=\"%s (%s) (%s)\" % (upname,pdb_id,dyn_id)\n",
    "        gpcr_class = compl_data[recept_id][\"class\"]\n",
    "        \n",
    "        if pdb_id:\n",
    "            prot_lig=(pdb_id,lig_sname)\n",
    "        else:\n",
    "            prot_lig=(upname,lig_sname)\n",
    "\n",
    "        recept_name=prot_lname+\" (\"+prot_lig[0]+\")\"\n",
    "        recept_info[dyn_id]=[upname, lig_sname,dyn_id,prot_id,comp_id,prot_lname,pdb_id,lig_lname,struc_fname,struc_f,traj_fnames,traj_f,delta,sim__fullname,gpcr_class]\n",
    "        index_dict[recept_id]=recept_name \n",
    "        dyn_gpcr_pdb[recept_name]=compl_data[recept_id][\"gpcr_pdb\"]\n",
    "\n",
    "    df_ts['Name'] = list(map(lambda x: index_dict[x], df_ts['Id']))\n",
    "    df_ts['shortName'] = list(map(lambda x: recept_info[x][13], df_ts['Id']))\n",
    "    return(recept_info,recept_info_order,df_ts,dyn_gpcr_pdb,index_dict)\n",
    "\n",
    "def filter_same_helix(df):\n",
    "    \"\"\"\n",
    "    Remove same-helix interaction pairs from dataframe. Returns same dataframe\n",
    "    \"\"\"\n",
    "    helixpattern = re.compile(r\"\"\"^(..)\\w+\\s+\\1\"\"\")#For detecting same-helix contacts, the ones like 1.22x22 1.54x54\n",
    "    helixfilter = df['Position'].str.contains(helixpattern)\n",
    "    df = df[~helixfilter]\n",
    "    return(df)\n",
    "\n",
    "def split_by_standard(df, compl_data):\n",
    "    \"\"\"\n",
    "    Return two dataframes, one with standard simulations and one with no-standard \n",
    "    \"\"\"\n",
    "    gpcrmd_people = ['Amoralpa11', 'mariona_tf', 'david', 'tste','ismresp']\n",
    "    nonstandard_simulations = set(('dyn4', 'dyn5', 'dyn6', 'dyn7', 'dyn8', 'dyn9', 'dyn10'))\n",
    "\n",
    "    #Find non-standard simulations\n",
    "    for dyn in compl_data:\n",
    "        if 'user' not in compl_data[dyn]:#To avoid obsolete entries\n",
    "            nonstandard_simulations.add(dyn)            \n",
    "        elif compl_data[dyn]['user'] not in gpcrmd_people:\n",
    "            nonstandard_simulations.add(dyn)\n",
    "            \n",
    "    df_standard = df[df.columns[~df.columns.isin(nonstandard_simulations)]]\n",
    "    \n",
    "    return(df, df_standard)\n",
    "\n",
    "def filter_lowfreq(df, main_itype):\n",
    "    \"\"\"\n",
    "    Filter low-frequency interactions. Remove all position pairs not having at least 2 simulations\n",
    "    with more than 50% interaction frequency\n",
    "    \"\"\"\n",
    "    df_purged = df.drop(['itype','Position','Position1','Position2'], 1)\n",
    "    df['above_30perc'] = (df_purged > 50).sum(1)\n",
    "    pos_topreserve = set(df['Position'][ (df['above_30perc'] > 1) & (df['itype'] == main_itype) ])\n",
    "    df.drop('above_30perc', 1, inplace = True)\n",
    "    df = df[df['Position'].isin(pos_topreserve)]\n",
    "     \n",
    "    return(df)\n",
    "\n",
    "def set_new_axis(df):\n",
    "    \"\"\"\n",
    "    Substitute the original position 3-nomenclatures single line format (1x23x23x24x24 1x23x23x24x24)\n",
    "    to 3-nomenclatures multiline format (1x\\n23\\n23\\n24\\n24\\n\\n1x\\n23\\n23\\n24\\n24)(similar to gpcrdb).\n",
    "    \"\"\"\n",
    "    def new_cell(cell):\n",
    "        cell = cell.replace(' ','\\n\\n')\n",
    "        cell = cell.replace('x','\\n')\n",
    "        cell = re.sub(pattern_pos1, r\"\\1x\\n\", cell)\n",
    "        cell = re.sub(pattern_pos2, r\"\\n\\n\\1x\\n\", cell)\n",
    "        return cell\n",
    "    \n",
    "    pattern_pos1 = re.compile(r\"^(\\d+)\\n\")\n",
    "    pattern_pos2 = re.compile(r\"\\n\\n(\\d+)\\n\")\n",
    "    df['Position'] = df['Position'].apply(new_cell)\n",
    "    return df\n",
    "\n",
    "def stack_matrix(df, itypes):\n",
    "    \"\"\"\n",
    "    Converts matrix in a stacked version: columns now are Position, dynid and itypes and rows all \n",
    "    frequencies by position and dyind\n",
    "    \"\"\"\n",
    "    df_ts = 1\n",
    "    for itype in itypes:\n",
    "        df_type = df[df[\"itype\"] == itype]\n",
    "        df_type.drop('itype', 1, inplace = True)\n",
    "        df_type.set_index('Position', inplace = True)\n",
    "        df_ts_type = df_type.transpose().stack().rename(itype).reset_index()\n",
    "        if type(df_ts) == int:\n",
    "            df_ts = df_ts_type\n",
    "        else:\n",
    "            df_ts = pd.merge( df_ts, df_ts_type, how ='outer', on=[\"level_0\", 'Position'])        \n",
    "    \n",
    "    df_ts = df_ts.fillna(\"0.0\") # Fill posible NaN in file\n",
    "\n",
    "    df_ts.rename(columns={\"level_0\": \"Id\"}, inplace=True)\n",
    "\n",
    "    return df_ts\n",
    "    \n",
    "def adapt_to_marionas(df):\n",
    "    \"\"\"\n",
    "    This function comprises a series of operations to adapt the new tsv format to Mariona's original scripts.\n",
    "    Also returns a dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    #Merging toghether both contacting aminoacid Ids\n",
    "    df['Position'] = df.Position1.str.cat(df.Position2, sep = \" \")\n",
    "\n",
    "    # Passing frequencies from decimal to percentage\n",
    "    nocols = ((\"Position1\",\"Position2\",\"itype\",\"Position\"))\n",
    "    for colname in df:\n",
    "        if colname not in nocols:\n",
    "            df[colname] = df[[colname]].apply(lambda x: x*100)\n",
    "\n",
    "    return(df)\n",
    "\n",
    "def flareplot_template(df, jsonpath):\n",
    "    \"\"\"\n",
    "    Create a pseudoflareplot input json with no interactions, but with all avalible positions.\n",
    "    It will be used later as a template to create the top interactions flareplots.  \n",
    "    \"\"\"\n",
    "    #'track' entry for json file: each track is a node (position) in the flareplot\n",
    "    helix_colors = {'1':\"#78C5D5\",'12':\"#5FB0BF\",'2':\"#459BA8\",'23':\"#5FAF88\",'3':\"#79C268\",'34':\"#9FCD58\",'4':\"#C5D747\",'45':\"#DDD742\",'5':\"#F5D63D\",'56':\"#F3B138\",'6':\"#F18C32\",'67':\"#ED7A6A\",'7':\"#E868A1\",'78':\"#D466A4\",'8':\"#BF63A6\",'Ligand--1':'#FF5050', 'Ligand': '#FF5050'}        \n",
    "    allpos = set(df['Position1']).union(set(df['Position2']))\n",
    "    tracks = [{\n",
    "        'trackLabel': 'Degree centrality',\n",
    "        \"trackProperties\": []\n",
    "    }]\n",
    "    trees = [{\n",
    "        'treeLabel': 'Helices',\n",
    "        'treePaths': []\n",
    "    }]\n",
    "    \n",
    "    #Add ligand\n",
    "    tracks[0]['trackProperties'].append({\n",
    "        'color' : \"#FF5050\",\n",
    "        'size' : 1.0,\n",
    "        'nodeName': 'Ligand'\n",
    "    })\n",
    "    trees[0]['treePaths'].append([1, 'Ligand'])\n",
    "    \n",
    "    setpos = set()\n",
    "    for multipos in allpos:\n",
    "        if multipos.startswith('Ligand'):\n",
    "            continue\n",
    "            \n",
    "        split_pos = multipos.split('x')\n",
    "        for pos in split_pos:\n",
    "            if split_pos.index(pos) == 0:\n",
    "                helix = pos\n",
    "                color = helix_colors[helix]\n",
    "            else:                \n",
    "                real_pos = helix+'x'+pos\n",
    "                if real_pos not in setpos:\n",
    "                    trackprop = {\n",
    "                        'color' : color,\n",
    "                        'size' : 1.0,\n",
    "                        'nodeName': real_pos\n",
    "                    }\n",
    "                    if len(helix) == 2:\n",
    "                        newhelix = int(helix[0]) + int(helix[1])\n",
    "                        trees[0]['treePaths'].append([newhelix, real_pos])\n",
    "                    else:\n",
    "                        newhelix = int(helix)*2\n",
    "                        trees[0]['treePaths'].append([newhelix, real_pos])\n",
    "\n",
    "                    tracks[0]['trackProperties'].append(trackprop)\n",
    "                    setpos.add(real_pos)\n",
    "\n",
    "    #Sort trees\n",
    "    treePaths_sorted = sorted(list(trees[0]['treePaths']), key=lambda l: (l[0],l[1]))\n",
    "    treePaths_sorted = [ str(x[0])+\".\"+x[1] for x in treePaths_sorted ]\n",
    "    trees[0]['treePaths'] = treePaths_sorted\n",
    "    \n",
    "    #Output jsondict to store\n",
    "    jsondict = { 'trees' : trees, 'tracks' : tracks }\n",
    "    \n",
    "    # Store json file\n",
    "    jsonpath = basepath + \"template.json\" \n",
    "    with open(jsonpath, 'w') as jsonfile:\n",
    "        dump(jsondict, jsonfile, ensure_ascii=False, indent = 4)\n",
    "\n",
    "\n",
    "def dyn_flareplots(df, folderpath, dyn_list, itype, flare_template = False):\n",
    "    \"\"\"\n",
    "    Create top20 interaction jsons for each simulation. Needed for customized selection flareplots.\n",
    "    \"\"\"\n",
    "    os.makedirs(folderpath, exist_ok = True)\n",
    "    colors_auld = ['#800000', '#860000', '#8c0000', '#930000', '#990000', '#9f0000', '#a60000', '#ac0000', '#b20000', '#b90000', '#bf0000', '#c50000', '#cc0000', '#d20000', '#d80000', '#df0000', '#e50000', '#eb0000', '#f20000', '#f80000', '#ff0000', '#ff0700', '#ff0e00', '#ff1500', '#ff1c00', '#ff2300', '#ff2a00', '#ff3100', '#ff3800', '#ff3f00', '#ff4600', '#ff4d00', '#ff5400', '#ff5b00', '#ff6200', '#ff6900', '#ff7000', '#ff7700', '#ff7e00', '#ff8500', '#ff8c00', '#ff9100', '#ff9700', '#ff9d00', '#ffa300', '#ffa800', '#ffae00', '#ffb400', '#ffba00', '#ffbf00', '#ffc500', '#ffcb00', '#ffd100', '#ffd600', '#ffdc00', '#ffe200', '#ffe800', '#ffed00', '#fff300', '#fff900', '#ffff00', '#f2ff00', '#e5ff00', '#d8ff00', '#ccff00', '#bfff00', '#b2ff00', '#a5ff00', '#99ff00', '#8cff00', '#7fff00', '#72ff00', '#66ff00', '#59ff00', '#4cff00', '#3fff00', '#33ff00', '#26ff00', '#19ff00', '#0cff00', '#00ff00', '#0afc0a', '#15fa15', '#1ff81f', '#2af62a', '#34f434', '#3ff13f', '#49ef49', '#54ed54', '#5eeb5e', '#69e969', '#74e674', '#7ee47e', '#89e289', '#93e093', '#9ede9e', '#a8dba8', '#b3d9b3', '#bdd7bd', '#c8d5c8', '#d3d3d3']\n",
    "    colors_ylorrd = ['#800026', '#850026', '#8a0026', '#8f0026', '#940026', '#990026', '#9e0026', '#a30026', '#a80026', '#ad0026', '#b20026', '#b70026', '#bd0026', '#c00225', '#c30424', '#c60623', '#c90822', '#cc0a21', '#d00d21', '#d30f20', '#d6111f', '#d9131e', '#dc151d', '#df171c', '#e31a1c', '#e51e1d', '#e7221e', '#e9271f', '#eb2b20', '#ed2f21', '#ef3423', '#f13824', '#f33c25', '#f54126', '#f74527', '#f94928', '#fc4e2a', '#fc532b', '#fc582d', '#fc5d2e', '#fc6330', '#fc6831', '#fc6d33', '#fc7234', '#fc7836', '#fc7d37', '#fc8239', '#fc873a', '#fd8d3c', '#fd903d', '#fd933e', '#fd9640', '#fd9941', '#fd9c42', '#fd9f44', '#fda245', '#fda546', '#fda848', '#fdab49', '#fdae4a', '#feb24c', '#feb54f', '#feb853', '#febb56', '#febf5a', '#fec25d', '#fec561', '#fec864', '#fecc68', '#fecf6b', '#fed26f', '#fed572', '#fed976', '#feda79', '#fedc7d', '#fede80', '#fedf84', '#fee187', '#fee38b', '#fee48e', '#fee692', '#fee895', '#fee999', '#feeb9c', '#ffeda0', '#ffeea3', '#fff0a7', '#fff1ab', '#fff3ae', '#fff4b2', '#fff6b6', '#fff7b9', '#fff9bd', '#fffac1', '#fffcc4', '#fffdc8', '#ffffcc']\n",
    "    colors_inferno = ['#000003', '#000004', '#000006', '#010007', '#010109', '#01010B', '#02010E', '#020210', '#030212', '#040314', '#040316', '#050418', '#06041B', '#07051D', '#08061F', '#090621', '#0A0723', '#0B0726', '#0D0828', '#0E082A', '#0F092D', '#10092F', '#120A32', '#130A34', '#140B36', '#160B39', '#170B3B', '#190B3E', '#1A0B40', '#1C0C43', '#1D0C45', '#1F0C47', '#200C4A', '#220B4C', '#240B4E', '#260B50', '#270B52', '#290B54', '#2B0A56', '#2D0A58', '#2E0A5A', '#300A5C', '#32095D', '#34095F', '#350960', '#370961', '#390962', '#3B0964', '#3C0965', '#3E0966', '#400966', '#410967', '#430A68', '#450A69', '#460A69', '#480B6A', '#4A0B6A', '#4B0C6B', '#4D0C6B', '#4F0D6C', '#500D6C', '#520E6C', '#530E6D', '#550F6D', '#570F6D', '#58106D', '#5A116D', '#5B116E', '#5D126E', '#5F126E', '#60136E', '#62146E', '#63146E', '#65156E', '#66156E', '#68166E', '#6A176E', '#6B176E', '#6D186E', '#6E186E', '#70196E', '#72196D', '#731A6D', '#751B6D', '#761B6D', '#781C6D', '#7A1C6D', '#7B1D6C', '#7D1D6C', '#7E1E6C', '#801F6B', '#811F6B', '#83206B', '#85206A', '#86216A', '#88216A', '#892269', '#8B2269', '#8D2369', '#8E2468', '#902468', '#912567', '#932567', '#952666', '#962666', '#982765', '#992864', '#9B2864', '#9C2963', '#9E2963', '#A02A62', '#A12B61', '#A32B61', '#A42C60', '#A62C5F', '#A72D5F', '#A92E5E', '#AB2E5D', '#AC2F5C', '#AE305B', '#AF315B', '#B1315A', '#B23259', '#B43358', '#B53357', '#B73456', '#B83556', '#BA3655', '#BB3754', '#BD3753', '#BE3852', '#BF3951', '#C13A50', '#C23B4F', '#C43C4E', '#C53D4D', '#C73E4C', '#C83E4B', '#C93F4A', '#CB4049', '#CC4148', '#CD4247', '#CF4446', '#D04544', '#D14643', '#D24742', '#D44841', '#D54940', '#D64A3F', '#D74B3E', '#D94D3D', '#DA4E3B', '#DB4F3A', '#DC5039', '#DD5238', '#DE5337', '#DF5436', '#E05634', '#E25733', '#E35832', '#E45A31', '#E55B30', '#E65C2E', '#E65E2D', '#E75F2C', '#E8612B', '#E9622A', '#EA6428', '#EB6527', '#EC6726', '#ED6825', '#ED6A23', '#EE6C22', '#EF6D21', '#F06F1F', '#F0701E', '#F1721D', '#F2741C', '#F2751A', '#F37719', '#F37918', '#F47A16', '#F57C15', '#F57E14', '#F68012', '#F68111', '#F78310', '#F7850E', '#F8870D', '#F8880C', '#F88A0B', '#F98C09', '#F98E08', '#F99008', '#FA9107', '#FA9306', '#FA9506', '#FA9706', '#FB9906', '#FB9B06', '#FB9D06', '#FB9E07', '#FBA007', '#FBA208', '#FBA40A', '#FBA60B', '#FBA80D', '#FBAA0E', '#FBAC10', '#FBAE12', '#FBB014', '#FBB116', '#FBB318', '#FBB51A', '#FBB71C', '#FBB91E', '#FABB21', '#FABD23', '#FABF25', '#FAC128', '#F9C32A', '#F9C52C', '#F9C72F', '#F8C931', '#F8CB34', '#F8CD37', '#F7CF3A', '#F7D13C', '#F6D33F', '#F6D542', '#F5D745', '#F5D948', '#F4DB4B', '#F4DC4F', '#F3DE52', '#F3E056', '#F3E259', '#F2E45D', '#F2E660', '#F1E864', '#F1E968', '#F1EB6C', '#F1ED70', '#F1EE74', '#F1F079', '#F1F27D', '#F2F381', '#F2F485', '#F3F689', '#F4F78D', '#F5F891', '#F6FA95', '#F7FB99', '#F9FC9D', '#FAFDA0', '#FCFEA4']\n",
    "    colors_magma = ['#000003', '#000004', '#000006', '#010007', '#010109', '#01010B', '#02020D', '#02020F', '#030311', '#040313', '#040415', '#050417', '#060519', '#07051B', '#08061D', '#09071F', '#0A0722', '#0B0824', '#0C0926', '#0D0A28', '#0E0A2A', '#0F0B2C', '#100C2F', '#110C31', '#120D33', '#140D35', '#150E38', '#160E3A', '#170F3C', '#180F3F', '#1A1041', '#1B1044', '#1C1046', '#1E1049', '#1F114B', '#20114D', '#221150', '#231152', '#251155', '#261157', '#281159', '#2A115C', '#2B115E', '#2D1060', '#2F1062', '#301065', '#321067', '#341068', '#350F6A', '#370F6C', '#390F6E', '#3B0F6F', '#3C0F71', '#3E0F72', '#400F73', '#420F74', '#430F75', '#450F76', '#470F77', '#481078', '#4A1079', '#4B1079', '#4D117A', '#4F117B', '#50127B', '#52127C', '#53137C', '#55137D', '#57147D', '#58157E', '#5A157E', '#5B167E', '#5D177E', '#5E177F', '#60187F', '#61187F', '#63197F', '#651A80', '#661A80', '#681B80', '#691C80', '#6B1C80', '#6C1D80', '#6E1E81', '#6F1E81', '#711F81', '#731F81', '#742081', '#762181', '#772181', '#792281', '#7A2281', '#7C2381', '#7E2481', '#7F2481', '#812581', '#822581', '#842681', '#852681', '#872781', '#892881', '#8A2881', '#8C2980', '#8D2980', '#8F2A80', '#912A80', '#922B80', '#942B80', '#952C80', '#972C7F', '#992D7F', '#9A2D7F', '#9C2E7F', '#9E2E7E', '#9F2F7E', '#A12F7E', '#A3307E', '#A4307D', '#A6317D', '#A7317D', '#A9327C', '#AB337C', '#AC337B', '#AE347B', '#B0347B', '#B1357A', '#B3357A', '#B53679', '#B63679', '#B83778', '#B93778', '#BB3877', '#BD3977', '#BE3976', '#C03A75', '#C23A75', '#C33B74', '#C53C74', '#C63C73', '#C83D72', '#CA3E72', '#CB3E71', '#CD3F70', '#CE4070', '#D0416F', '#D1426E', '#D3426D', '#D4436D', '#D6446C', '#D7456B', '#D9466A', '#DA4769', '#DC4869', '#DD4968', '#DE4A67', '#E04B66', '#E14C66', '#E24D65', '#E44E64', '#E55063', '#E65162', '#E75262', '#E85461', '#EA5560', '#EB5660', '#EC585F', '#ED595F', '#EE5B5E', '#EE5D5D', '#EF5E5D', '#F0605D', '#F1615C', '#F2635C', '#F3655C', '#F3675B', '#F4685B', '#F56A5B', '#F56C5B', '#F66E5B', '#F6705B', '#F7715B', '#F7735C', '#F8755C', '#F8775C', '#F9795C', '#F97B5D', '#F97D5D', '#FA7F5E', '#FA805E', '#FA825F', '#FB8460', '#FB8660', '#FB8861', '#FB8A62', '#FC8C63', '#FC8E63', '#FC9064', '#FC9265', '#FC9366', '#FD9567', '#FD9768', '#FD9969', '#FD9B6A', '#FD9D6B', '#FD9F6C', '#FDA16E', '#FDA26F', '#FDA470', '#FEA671', '#FEA873', '#FEAA74', '#FEAC75', '#FEAE76', '#FEAF78', '#FEB179', '#FEB37B', '#FEB57C', '#FEB77D', '#FEB97F', '#FEBB80', '#FEBC82', '#FEBE83', '#FEC085', '#FEC286', '#FEC488', '#FEC689', '#FEC78B', '#FEC98D', '#FECB8E', '#FDCD90', '#FDCF92', '#FDD193', '#FDD295', '#FDD497', '#FDD698', '#FDD89A', '#FDDA9C', '#FDDC9D', '#FDDD9F', '#FDDFA1', '#FDE1A3', '#FCE3A5', '#FCE5A6', '#FCE6A8', '#FCE8AA', '#FCEAAC', '#FCECAE', '#FCEEB0', '#FCF0B1', '#FCF1B3', '#FCF3B5', '#FCF5B7', '#FBF7B9', '#FBF9BB', '#FBFABD', '#FBFCBF']\n",
    "    colors_ylgnbl = ['#081d58', '#0a1e5d', '#0c2062', '#0f2267', '#11246c', '#142671', '#162876', '#182a7b', '#1b2c80', '#1d2e85', '#20308a', '#22328f', '#253494', '#243795', '#243b97', '#243e99', '#24429a', '#23459c', '#23499e', '#234c9f', '#2350a1', '#2253a3', '#2257a4', '#225aa6', '#225ea8', '#2162aa', '#2166ac', '#206aae', '#206fb0', '#1f73b2', '#1f77b4', '#1f7bb6', '#1e80b8', '#1e84ba', '#1d88bc', '#1d8cbe', '#1d91c0', '#2094c0', '#2397c0', '#269ac1', '#299dc1', '#2ca0c1', '#2fa3c2', '#32a6c2', '#35a9c2', '#38acc3', '#3bafc3', '#3eb2c3', '#41b6c4', '#46b7c3', '#4bb9c2', '#50bbc1', '#55bdc1', '#5abfc0', '#60c1bf', '#65c3be', '#6ac5be', '#6fc7bd', '#74c9bc', '#79cbbb', '#7fcdbb', '#85cfba', '#8bd1b9', '#91d4b9', '#97d6b8', '#9dd8b8', '#a3dbb7', '#a9ddb6', '#afdfb6', '#b5e2b5', '#bbe4b5', '#c1e6b4', '#c7e9b4', '#caeab3', '#cdebb3', '#d0ecb3', '#d3eeb3', '#d6efb2', '#daf0b2', '#ddf1b2', '#e0f3b2', '#e3f4b1', '#e6f5b1', '#e9f6b1', '#edf8b1', '#eef8b4', '#f0f9b7', '#f1f9bb', '#f3fabe', '#f4fac1', '#f6fbc5', '#f7fcc8', '#f9fccb', '#fafdcf', '#fcfdd2', '#fdfed5', '#ffffd9']\n",
    "    colors_grorrd = ['#800026', '#850026', '#8a0026', '#8f0026', '#940026', '#990026', '#9e0026', '#a30026', '#a80026', '#ad0026', '#b20026', '#b70026', '#bd0026', '#c00225', '#c30424', '#c60623', '#c90822', '#cc0a21', '#d00d21', '#d30f20', '#d6111f', '#d9131e', '#dc151d', '#df171c', '#e31a1c', '#e51e1d', '#e7221e', '#e9271f', '#eb2b20', '#ed2f21', '#ef3423', '#f13824', '#f33c25', '#f54126', '#f74527', '#f94928', '#fc4e2a', '#fc532b', '#fc582d', '#fc5d2e', '#fc6330', '#fc6831', '#fc6d33', '#fc7234', '#fc7836', '#fc7d37', '#fc8239', '#fc873a', '#fd8d3c', '#fd903d', '#fd933e', '#fd9640', '#fd9941', '#fd9c42', '#fd9f44', '#fda245', '#fda546', '#fda848', '#fdab49', '#fdae4a', '#feb24c', '#feb54f', '#feb853', '#febb56', '#febf5a', '#fec25d', '#fec561', '#fec864', '#fecc68', '#fecf6b', '#fed26f', '#fed572', '#fed976', '#feda79', '#fedc7d', '#fede80', '#fedf84', '#fee187', '#fee38b', '#fee48e', '#fee692', '#fee895', '#fee999', '#feeb9c', '#ffeda0', '#fbeaa4', '#f7e8a8', '#f4e6ac', '#f0e4b1', '#ece2b5', '#e9e0b9', '#e5ddbd', '#e1dbc2', '#ded9c6', '#dad7ca', '#d6d5ce', '#d3d3d3']\n",
    "    colors = colors_grorrd\n",
    "    for dyn in dyn_list:\n",
    "\n",
    "        # Select top interactions based on its mean frequency. Also asign color based on mean value\n",
    "        color_len = len(colors) -1\n",
    "        df_clust = df.filter(items = [dyn, 'APosition1', 'APosition2', 'BPosition1', 'BPosition2','CPosition1', 'CPosition2','FPosition1', 'FPosition2',])\n",
    "        df_clust['color'] = df_clust[dyn].apply(lambda x: colors[color_len-round(x*color_len/100)]) #There are 101 colors avalible in list\n",
    "\n",
    "        #Filter top 5 in df_clust\n",
    "        df_clust = df_clust.nlargest(20, dyn)\n",
    "\n",
    "        # 'Edge' entry for json file\n",
    "        df_dict = pd.DataFrame(columns = [\"name1\", \"name2\", \"frames\"])\n",
    "        df_dict['name1'] = df_clust['APosition1'] \n",
    "        df_dict['name2'] = df_clust['APosition2']\n",
    "        df_dict['frames'] = [[1]]*len(df_dict)\n",
    "        df_dict['color'] = df_clust['color']\n",
    "        df_dict['value'] = df_clust[dyn]\n",
    "        edges = df_dict.to_dict(orient=\"records\")\n",
    "\n",
    "        # Appending edges to flare plot template, if any submitted\n",
    "        if flare_template:\n",
    "            flare_template['edges'] = edges\n",
    "            jsondict = flare_template\n",
    "        else:\n",
    "            jsondict = { 'edges' : edges }\n",
    "\n",
    "        #'Edge' multi-entries, based on the 4 GPCR nomenclatures\n",
    "        for leter in ['A', 'B', 'C', 'F']:\n",
    "            df_dict = pd.DataFrame(columns = [\"name1\", \"name2\", \"frames\"])\n",
    "            df_dict['name1'] = df_clust[leter+'Position1'] \n",
    "            df_dict['name2'] = df_clust[leter+'Position2']\n",
    "            df_dict['frames'] = [[1]]*len(df_dict)\n",
    "            df_dict['color'] = df_clust['color']\n",
    "            df_dict['value'] = df_clust[dyn]\n",
    "            leter_edges = df_dict.to_dict(orient=\"records\")\n",
    "\n",
    "            #Appending edges\n",
    "            if flare_template:\n",
    "                flare_template[leter+'edges'] = leter_edges\n",
    "                jsondict = flare_template\n",
    "            else:\n",
    "                jsondict = { leter+'edges' : leter_edges }\n",
    "\n",
    "        #Writing json\n",
    "        jsonpath = folderpath + dyn + \"_top.json\"\n",
    "        with open(jsonpath, 'w') as jsonfile:\n",
    "            dump(jsondict, jsonfile, ensure_ascii=False, indent = 4)\n",
    "\n",
    "        \n",
    "def frequencies(df):\n",
    "    \"\"\"\n",
    "    Creates an interaction frequency numpy matrix from \n",
    "    \"\"\"\n",
    "\n",
    "    # Transpose matrix\n",
    "    df_t = df.transpose() \n",
    "    \n",
    "    # Create dictionary table with position tuple as keys and interaction-by-simulation-freq array as value\n",
    "    freq_table = { tuple(col.split(\"\\n\\n\")):list(df_t[col].values) for col in df_t }\n",
    "        \n",
    "    # Convert previous dictionary to numpy array, and traspose it\n",
    "    freq_matrix = (array([freq_table[(r1, r2)] for (r1, r2) in freq_table])).T\n",
    "\n",
    "    # Reorder according to clustering\n",
    "    return freq_matrix\n",
    "\n",
    "def clustering(clusters, dend_matrix, labels, linkagefun):\n",
    "    \"\"\"\n",
    "    Find the color threshold needed for the dendrogram to have \"clusters\" number of clusters. \n",
    "    Also define to which cluster each simulation belongs\n",
    "    \"\"\"\n",
    "    Z = linkagefun(dend_matrix)\n",
    "    color_threshold = Z[-1*clusters][2]+0.0000000001 #Cut slightly above the tree node\n",
    "    \n",
    "    # Defining to which cluster belongs to each simulation\n",
    "    T = fcluster(Z, t=clusters, criterion='maxclust')\n",
    "    clustdict = { \"cluster\" + str(clust) : [] for clust in T }\n",
    "    for sim,clust in zip(labels,T):\n",
    "         clustdict[\"cluster\" + str(clust)].append(sim)\n",
    "\n",
    "    return(color_threshold, clustdict)\n",
    "\n",
    "def black_or_white(bgcolor):\n",
    "    \"\"\"\n",
    "    Text with this color background should be in black or white font?\n",
    "    \"\"\"\n",
    "    ary_bgcolors = re.findall(r\"[\\w']+\", bgcolor)\n",
    "    R = int(ary_bgcolors[1])\n",
    "    G = int(ary_bgcolors[2])\n",
    "    B = int(ary_bgcolors[3])\n",
    "    Lumi = (sum([R,G,B])/3)\n",
    "\n",
    "    if Lumi > 125:\n",
    "        colorfont = 'rgb(0,0,0)'\n",
    "    else:\n",
    "        colorfont = 'rgb(255,255,255)'\n",
    "\n",
    "    return colorfont\n",
    "\n",
    "def hoverlabels_axis(fig, recept_info, recept_info_order, default_color, annotations = []):\n",
    "    \"\"\"\n",
    "    Makes hover labels from figure correspond to Y-axis labels, and make Y-axis labels correspond to dendrogram\n",
    "    colors.\n",
    "    \"\"\"\n",
    "    \n",
    "    def define_annotation_list(y_pos, bgcolor, text, colorfont, name, hovertext):\n",
    "        \"\"\"\n",
    "        Create a list of annotation objects. This annotations are meant to replace the axis labels as names of simulations\n",
    "        \"\"\"\n",
    "        return dict(\n",
    "            x = -0,\n",
    "            y = y_pos,\n",
    "            xanchor = 'left',\n",
    "            text = text,\n",
    "            hovertext = hovertext,\n",
    "            showarrow = False,\n",
    "            captureevents = True,\n",
    "            bgcolor = bgcolor,\n",
    "            font = { 'size' : 12, 'color' : colorfont },\n",
    "            height = 14\n",
    "        )\n",
    "\n",
    "    def prepare_entry(hoverentry, fig, ypos, name_index, ligname_index, recept_info, pdb_index):\n",
    "        \"\"\"\n",
    "        Creates xaxis-annotations and hoverlabels based on the information contained by this dendrogram branch\n",
    "        \"\"\"                \n",
    "        dynid = dendro_leaves[int((ypos-5)/10)]\n",
    "        nodyn_id = dynid.replace('dyn','')\n",
    "        pdbcode = recept_info[dynid][pdb_index]\n",
    "        simname = recept_info[dynid][name_index]\n",
    "        ligname = recept_info[dynid][ligname_index]\n",
    "        bgcolor = hoverentry['marker']['color']\n",
    "        anot_text = \"%s (%s)<b style='display: none'>%s</b>\" % (simname, pdbcode, dynid)\n",
    "        hovertext = str(\"complex with %s (dynID: %s)\" % (ligname, nodyn_id)) if (ligname) else  str(\"apoform (dynID: %s)\" % (nodyn_id))\n",
    "\n",
    "        # Annotation to corresponding simulation\n",
    "        colorfont = black_or_white(bgcolor)\n",
    "        annotations.append(define_annotation_list(ypos, bgcolor, anot_text, colorfont, dynid, hovertext))\n",
    "\n",
    "        return(fig, annotations)\n",
    "    \n",
    "    dendro_leaves = fig['layout']['yaxis']['ticktext']\n",
    "\n",
    "    # Adapting hovertool to what I want from it\n",
    "    name_index = recept_info_order['upname']\n",
    "    pdb_index = recept_info_order['pdb_id']\n",
    "    ligname_index = recept_info_order['lig_sname']\n",
    "    occuped_positions = dict()\n",
    "    for hoverentry in fig['data']:\n",
    "\n",
    "        # Silenciate all default hover entries. \n",
    "        hoverentry['hoverinfo'] = 'none'\n",
    "        \n",
    "        # If entry reaches end of plot (not intermediate node)\n",
    "        if (hoverentry['x'][0] == -0) and (int(hoverentry['y'][0])%10 == 5):\n",
    "            \n",
    "            #If entry Y-corodinate is not already occuped by another one, or if it's wrongly occuped by a middle dendrogram which reaches bottom of plot\n",
    "            if (hoverentry['y'][0] not in occuped_positions) or (hoverentry['marker']['color'] != default_color):\n",
    "\n",
    "                occuped_positions[hoverentry['y'][0]] = hoverentry['marker']['color']\n",
    "                (fig, annotations) = prepare_entry(hoverentry, fig, hoverentry['y'][0], name_index, ligname_index, recept_info, pdb_index)\n",
    "\n",
    "                #If this entry reaches two labels at the same time (terminal U node), create yet another entry\n",
    "                if (hoverentry['x'][3] == -0) and (int(hoverentry['y'][3])%10 == 5): \n",
    "                    (fig, annotations) = prepare_entry(hoverentry, fig, hoverentry['y'][3], name_index, ligname_index, recept_info, pdb_index)\n",
    "\n",
    "    fig['layout']['annotations'] = annotations\n",
    "\n",
    "    return fig\n",
    "\n",
    "def annotate_clusters(fig, default_color = \"\"):\n",
    "    \"\"\"\n",
    "    Put an annotation the nodes on top of clusters\n",
    "    \"\"\"\n",
    "    prevcolor = \"\"\n",
    "    min_x = 0\n",
    "    clustcount = -1\n",
    "    clustcoords = []\n",
    "    xcords = []\n",
    "    annotations = []\n",
    "    taken_ycords = set()\n",
    "    \n",
    "    # Sorting by y coordenate (needed for later)\n",
    "    fig['data'] = sorted(fig['data'], key=lambda x: x['y'][0])\n",
    "    \n",
    "    #Iterate over all vector forms in the figure and find the ones that are cluster tops\n",
    "    for entry in fig['data']:\n",
    "\n",
    "        currentcolor = entry['marker']['color']\n",
    "        current_min_x = min(entry['x'])\n",
    "        current_max_x = max(entry['x'])\n",
    "        # For skipping upper-dendrogram, non-cluster branches\n",
    "        if (currentcolor == default_color) and ((max(entry['x']) != -0.0) or (entry['y'][0]%10 == 0)):\n",
    "            continue\n",
    "\n",
    "        #Check for false 'single-node, default color' clusters\n",
    "        if ((entry['y'][0] in taken_ycords) or (entry['y'][0] in taken_ycords)) and (currentcolor == default_color):\n",
    "            continue\n",
    "            \n",
    "        # If there has been a color change ...\n",
    "        #... OR it is a single-node cluster\n",
    "        if (prevcolor != currentcolor) or ((currentcolor == default_color) and (max(entry['x']) == -0.0) ):\n",
    "            clustcount += 1\n",
    "            xcords.append(\"\")\n",
    "            min_x = 0\n",
    "            clustcoords.append({})\n",
    "            \n",
    "        # If new entry is higher (inside the tree) than previous, select as candidate for cluster node        \n",
    "        if current_min_x <= min_x:\n",
    "\n",
    "            min_x = current_min_x\n",
    "            clustcoords[clustcount]['clusnode_x'] = entry['x'][1]\n",
    "            xcords[clustcount] = (clustcoords[clustcount]['clusnode_x'])\n",
    "            clustcoords[clustcount]['clusnode_y'] = (entry['y'][1] + entry['y'][2])/2\n",
    "            clustcoords[clustcount]['clustnumber'] = clustcount\n",
    "            clustcoords[clustcount]['color'] = currentcolor\n",
    "            clustcoords[clustcount]['xanchor'] = 'right'\n",
    "            \n",
    "            #For single-branch clusters\n",
    "            if (currentcolor == default_color) and (current_max_x == -0): \n",
    "                index_x = np.where(entry['x'] == current_max_x) \n",
    "                clustcoords[clustcount]['clusnode_y'] = entry['y'][index_x][0]\n",
    "                #If the branch contains two single-node clusters(very rare case), append another cluster label\n",
    "                if (entry['x'][0] == -0) and (entry['x'][3] == -0) and (entry['y'][2]%10 != 0):\n",
    "                    clustcount += 1\n",
    "                    clustcoords.append({\n",
    "                        'clusnode_x' : entry['x'][2],\n",
    "                        'clusnode_y' : entry['y'][2],\n",
    "                        'clustnumber' : clustcount,\n",
    "                        'color' : currentcolor,\n",
    "                        'xanchor' : 'right'\n",
    "                   })\n",
    "                    xcords.append(clustcoords[clustcount]['clusnode_x'])\n",
    "        \n",
    "        #Add occuped y-coords\n",
    "        for ycord in entry['y']:\n",
    "            if ycord%10 == 5:\n",
    "                taken_ycords.add(ycord)\n",
    "\n",
    "        prevcolor = currentcolor\n",
    "    \n",
    "    # Annotate with \"clusterN\" the vector forms found in previous loop\n",
    "    for clust in clustcoords:\n",
    "        colorfont = black_or_white(clust['color'])\n",
    "        annotations.append(dict(\n",
    "            x = clust['clusnode_x'],\n",
    "            y = clust['clusnode_y'],\n",
    "            xanchor = clust['xanchor'],\n",
    "            text = \"cluster \" + str(clust['clustnumber']+1),\n",
    "            showarrow = False,\n",
    "            bgcolor = clust['color'],\n",
    "            font = { 'size' : 12, 'color' : colorfont },\n",
    "            height = 14\n",
    "        ))\n",
    "\n",
    "    return annotations\n",
    "\n",
    "def flareplot_json(df, clustdict, folderpath, flare_template = False):\n",
    "    \"\"\"\n",
    "    Create json entries for significative positions (top10 mean frequency) of each cluster produced\n",
    "    \"\"\"\n",
    "    os.makedirs(folderpath,  exist_ok = True)\n",
    "    colors_auld = ['#800000', '#860000', '#8c0000', '#930000', '#990000', '#9f0000', '#a60000', '#ac0000', '#b20000', '#b90000', '#bf0000', '#c50000', '#cc0000', '#d20000', '#d80000', '#df0000', '#e50000', '#eb0000', '#f20000', '#f80000', '#ff0000', '#ff0700', '#ff0e00', '#ff1500', '#ff1c00', '#ff2300', '#ff2a00', '#ff3100', '#ff3800', '#ff3f00', '#ff4600', '#ff4d00', '#ff5400', '#ff5b00', '#ff6200', '#ff6900', '#ff7000', '#ff7700', '#ff7e00', '#ff8500', '#ff8c00', '#ff9100', '#ff9700', '#ff9d00', '#ffa300', '#ffa800', '#ffae00', '#ffb400', '#ffba00', '#ffbf00', '#ffc500', '#ffcb00', '#ffd100', '#ffd600', '#ffdc00', '#ffe200', '#ffe800', '#ffed00', '#fff300', '#fff900', '#ffff00', '#f2ff00', '#e5ff00', '#d8ff00', '#ccff00', '#bfff00', '#b2ff00', '#a5ff00', '#99ff00', '#8cff00', '#7fff00', '#72ff00', '#66ff00', '#59ff00', '#4cff00', '#3fff00', '#33ff00', '#26ff00', '#19ff00', '#0cff00', '#00ff00', '#0afc0a', '#15fa15', '#1ff81f', '#2af62a', '#34f434', '#3ff13f', '#49ef49', '#54ed54', '#5eeb5e', '#69e969', '#74e674', '#7ee47e', '#89e289', '#93e093', '#9ede9e', '#a8dba8', '#b3d9b3', '#bdd7bd', '#c8d5c8', '#d3d3d3']\n",
    "    colors_ylorrd = ['#800026', '#850026', '#8a0026', '#8f0026', '#940026', '#990026', '#9e0026', '#a30026', '#a80026', '#ad0026', '#b20026', '#b70026', '#bd0026', '#c00225', '#c30424', '#c60623', '#c90822', '#cc0a21', '#d00d21', '#d30f20', '#d6111f', '#d9131e', '#dc151d', '#df171c', '#e31a1c', '#e51e1d', '#e7221e', '#e9271f', '#eb2b20', '#ed2f21', '#ef3423', '#f13824', '#f33c25', '#f54126', '#f74527', '#f94928', '#fc4e2a', '#fc532b', '#fc582d', '#fc5d2e', '#fc6330', '#fc6831', '#fc6d33', '#fc7234', '#fc7836', '#fc7d37', '#fc8239', '#fc873a', '#fd8d3c', '#fd903d', '#fd933e', '#fd9640', '#fd9941', '#fd9c42', '#fd9f44', '#fda245', '#fda546', '#fda848', '#fdab49', '#fdae4a', '#feb24c', '#feb54f', '#feb853', '#febb56', '#febf5a', '#fec25d', '#fec561', '#fec864', '#fecc68', '#fecf6b', '#fed26f', '#fed572', '#fed976', '#feda79', '#fedc7d', '#fede80', '#fedf84', '#fee187', '#fee38b', '#fee48e', '#fee692', '#fee895', '#fee999', '#feeb9c', '#ffeda0', '#ffeea3', '#fff0a7', '#fff1ab', '#fff3ae', '#fff4b2', '#fff6b6', '#fff7b9', '#fff9bd', '#fffac1', '#fffcc4', '#fffdc8', '#ffffcc']\n",
    "    colors_inferno = ['#000003', '#000004', '#000006', '#010007', '#010109', '#01010B', '#02010E', '#020210', '#030212', '#040314', '#040316', '#050418', '#06041B', '#07051D', '#08061F', '#090621', '#0A0723', '#0B0726', '#0D0828', '#0E082A', '#0F092D', '#10092F', '#120A32', '#130A34', '#140B36', '#160B39', '#170B3B', '#190B3E', '#1A0B40', '#1C0C43', '#1D0C45', '#1F0C47', '#200C4A', '#220B4C', '#240B4E', '#260B50', '#270B52', '#290B54', '#2B0A56', '#2D0A58', '#2E0A5A', '#300A5C', '#32095D', '#34095F', '#350960', '#370961', '#390962', '#3B0964', '#3C0965', '#3E0966', '#400966', '#410967', '#430A68', '#450A69', '#460A69', '#480B6A', '#4A0B6A', '#4B0C6B', '#4D0C6B', '#4F0D6C', '#500D6C', '#520E6C', '#530E6D', '#550F6D', '#570F6D', '#58106D', '#5A116D', '#5B116E', '#5D126E', '#5F126E', '#60136E', '#62146E', '#63146E', '#65156E', '#66156E', '#68166E', '#6A176E', '#6B176E', '#6D186E', '#6E186E', '#70196E', '#72196D', '#731A6D', '#751B6D', '#761B6D', '#781C6D', '#7A1C6D', '#7B1D6C', '#7D1D6C', '#7E1E6C', '#801F6B', '#811F6B', '#83206B', '#85206A', '#86216A', '#88216A', '#892269', '#8B2269', '#8D2369', '#8E2468', '#902468', '#912567', '#932567', '#952666', '#962666', '#982765', '#992864', '#9B2864', '#9C2963', '#9E2963', '#A02A62', '#A12B61', '#A32B61', '#A42C60', '#A62C5F', '#A72D5F', '#A92E5E', '#AB2E5D', '#AC2F5C', '#AE305B', '#AF315B', '#B1315A', '#B23259', '#B43358', '#B53357', '#B73456', '#B83556', '#BA3655', '#BB3754', '#BD3753', '#BE3852', '#BF3951', '#C13A50', '#C23B4F', '#C43C4E', '#C53D4D', '#C73E4C', '#C83E4B', '#C93F4A', '#CB4049', '#CC4148', '#CD4247', '#CF4446', '#D04544', '#D14643', '#D24742', '#D44841', '#D54940', '#D64A3F', '#D74B3E', '#D94D3D', '#DA4E3B', '#DB4F3A', '#DC5039', '#DD5238', '#DE5337', '#DF5436', '#E05634', '#E25733', '#E35832', '#E45A31', '#E55B30', '#E65C2E', '#E65E2D', '#E75F2C', '#E8612B', '#E9622A', '#EA6428', '#EB6527', '#EC6726', '#ED6825', '#ED6A23', '#EE6C22', '#EF6D21', '#F06F1F', '#F0701E', '#F1721D', '#F2741C', '#F2751A', '#F37719', '#F37918', '#F47A16', '#F57C15', '#F57E14', '#F68012', '#F68111', '#F78310', '#F7850E', '#F8870D', '#F8880C', '#F88A0B', '#F98C09', '#F98E08', '#F99008', '#FA9107', '#FA9306', '#FA9506', '#FA9706', '#FB9906', '#FB9B06', '#FB9D06', '#FB9E07', '#FBA007', '#FBA208', '#FBA40A', '#FBA60B', '#FBA80D', '#FBAA0E', '#FBAC10', '#FBAE12', '#FBB014', '#FBB116', '#FBB318', '#FBB51A', '#FBB71C', '#FBB91E', '#FABB21', '#FABD23', '#FABF25', '#FAC128', '#F9C32A', '#F9C52C', '#F9C72F', '#F8C931', '#F8CB34', '#F8CD37', '#F7CF3A', '#F7D13C', '#F6D33F', '#F6D542', '#F5D745', '#F5D948', '#F4DB4B', '#F4DC4F', '#F3DE52', '#F3E056', '#F3E259', '#F2E45D', '#F2E660', '#F1E864', '#F1E968', '#F1EB6C', '#F1ED70', '#F1EE74', '#F1F079', '#F1F27D', '#F2F381', '#F2F485', '#F3F689', '#F4F78D', '#F5F891', '#F6FA95', '#F7FB99', '#F9FC9D', '#FAFDA0', '#FCFEA4']\n",
    "    colors_magma = ['#000003', '#000004', '#000006', '#010007', '#010109', '#01010B', '#02020D', '#02020F', '#030311', '#040313', '#040415', '#050417', '#060519', '#07051B', '#08061D', '#09071F', '#0A0722', '#0B0824', '#0C0926', '#0D0A28', '#0E0A2A', '#0F0B2C', '#100C2F', '#110C31', '#120D33', '#140D35', '#150E38', '#160E3A', '#170F3C', '#180F3F', '#1A1041', '#1B1044', '#1C1046', '#1E1049', '#1F114B', '#20114D', '#221150', '#231152', '#251155', '#261157', '#281159', '#2A115C', '#2B115E', '#2D1060', '#2F1062', '#301065', '#321067', '#341068', '#350F6A', '#370F6C', '#390F6E', '#3B0F6F', '#3C0F71', '#3E0F72', '#400F73', '#420F74', '#430F75', '#450F76', '#470F77', '#481078', '#4A1079', '#4B1079', '#4D117A', '#4F117B', '#50127B', '#52127C', '#53137C', '#55137D', '#57147D', '#58157E', '#5A157E', '#5B167E', '#5D177E', '#5E177F', '#60187F', '#61187F', '#63197F', '#651A80', '#661A80', '#681B80', '#691C80', '#6B1C80', '#6C1D80', '#6E1E81', '#6F1E81', '#711F81', '#731F81', '#742081', '#762181', '#772181', '#792281', '#7A2281', '#7C2381', '#7E2481', '#7F2481', '#812581', '#822581', '#842681', '#852681', '#872781', '#892881', '#8A2881', '#8C2980', '#8D2980', '#8F2A80', '#912A80', '#922B80', '#942B80', '#952C80', '#972C7F', '#992D7F', '#9A2D7F', '#9C2E7F', '#9E2E7E', '#9F2F7E', '#A12F7E', '#A3307E', '#A4307D', '#A6317D', '#A7317D', '#A9327C', '#AB337C', '#AC337B', '#AE347B', '#B0347B', '#B1357A', '#B3357A', '#B53679', '#B63679', '#B83778', '#B93778', '#BB3877', '#BD3977', '#BE3976', '#C03A75', '#C23A75', '#C33B74', '#C53C74', '#C63C73', '#C83D72', '#CA3E72', '#CB3E71', '#CD3F70', '#CE4070', '#D0416F', '#D1426E', '#D3426D', '#D4436D', '#D6446C', '#D7456B', '#D9466A', '#DA4769', '#DC4869', '#DD4968', '#DE4A67', '#E04B66', '#E14C66', '#E24D65', '#E44E64', '#E55063', '#E65162', '#E75262', '#E85461', '#EA5560', '#EB5660', '#EC585F', '#ED595F', '#EE5B5E', '#EE5D5D', '#EF5E5D', '#F0605D', '#F1615C', '#F2635C', '#F3655C', '#F3675B', '#F4685B', '#F56A5B', '#F56C5B', '#F66E5B', '#F6705B', '#F7715B', '#F7735C', '#F8755C', '#F8775C', '#F9795C', '#F97B5D', '#F97D5D', '#FA7F5E', '#FA805E', '#FA825F', '#FB8460', '#FB8660', '#FB8861', '#FB8A62', '#FC8C63', '#FC8E63', '#FC9064', '#FC9265', '#FC9366', '#FD9567', '#FD9768', '#FD9969', '#FD9B6A', '#FD9D6B', '#FD9F6C', '#FDA16E', '#FDA26F', '#FDA470', '#FEA671', '#FEA873', '#FEAA74', '#FEAC75', '#FEAE76', '#FEAF78', '#FEB179', '#FEB37B', '#FEB57C', '#FEB77D', '#FEB97F', '#FEBB80', '#FEBC82', '#FEBE83', '#FEC085', '#FEC286', '#FEC488', '#FEC689', '#FEC78B', '#FEC98D', '#FECB8E', '#FDCD90', '#FDCF92', '#FDD193', '#FDD295', '#FDD497', '#FDD698', '#FDD89A', '#FDDA9C', '#FDDC9D', '#FDDD9F', '#FDDFA1', '#FDE1A3', '#FCE3A5', '#FCE5A6', '#FCE6A8', '#FCE8AA', '#FCEAAC', '#FCECAE', '#FCEEB0', '#FCF0B1', '#FCF1B3', '#FCF3B5', '#FCF5B7', '#FBF7B9', '#FBF9BB', '#FBFABD', '#FBFCBF']\n",
    "    colors_ylgnbl = ['#081d58', '#0a1e5d', '#0c2062', '#0f2267', '#11246c', '#142671', '#162876', '#182a7b', '#1b2c80', '#1d2e85', '#20308a', '#22328f', '#253494', '#243795', '#243b97', '#243e99', '#24429a', '#23459c', '#23499e', '#234c9f', '#2350a1', '#2253a3', '#2257a4', '#225aa6', '#225ea8', '#2162aa', '#2166ac', '#206aae', '#206fb0', '#1f73b2', '#1f77b4', '#1f7bb6', '#1e80b8', '#1e84ba', '#1d88bc', '#1d8cbe', '#1d91c0', '#2094c0', '#2397c0', '#269ac1', '#299dc1', '#2ca0c1', '#2fa3c2', '#32a6c2', '#35a9c2', '#38acc3', '#3bafc3', '#3eb2c3', '#41b6c4', '#46b7c3', '#4bb9c2', '#50bbc1', '#55bdc1', '#5abfc0', '#60c1bf', '#65c3be', '#6ac5be', '#6fc7bd', '#74c9bc', '#79cbbb', '#7fcdbb', '#85cfba', '#8bd1b9', '#91d4b9', '#97d6b8', '#9dd8b8', '#a3dbb7', '#a9ddb6', '#afdfb6', '#b5e2b5', '#bbe4b5', '#c1e6b4', '#c7e9b4', '#caeab3', '#cdebb3', '#d0ecb3', '#d3eeb3', '#d6efb2', '#daf0b2', '#ddf1b2', '#e0f3b2', '#e3f4b1', '#e6f5b1', '#e9f6b1', '#edf8b1', '#eef8b4', '#f0f9b7', '#f1f9bb', '#f3fabe', '#f4fac1', '#f6fbc5', '#f7fcc8', '#f9fccb', '#fafdcf', '#fcfdd2', '#fdfed5', '#ffffd9']\n",
    "    colors = colors_ylorrd\n",
    "    color_len = len(colors) -1\n",
    "    for clust in clustdict.keys():\n",
    "\n",
    "        # Select top interactions based on its mean frequency. Also asign color based on mean value\n",
    "        df_clust = df.filter(items = clustdict[clust] + ['APosition1', 'APosition2', 'BPosition1', 'BPosition2','CPosition1', 'CPosition2','FPosition1', 'FPosition2',])\n",
    "        df_clust['mean'] = df_clust.mean(axis = 1, numeric_only = True)\n",
    "        mean_threshold = min(df_clust['mean'].nlargest(20).tolist())\n",
    "        df_clust['color'] = df_clust['mean'].apply(lambda x: colors[color_len-round(x*color_len/100)]) #There are 101 colors avalible in list\n",
    "\n",
    "        #Filter top 5 in df_clust\n",
    "        df_clust = df_clust.nlargest(20,'mean')\n",
    "\n",
    "        # 'Edge' entry for json file\n",
    "        df_dict = pd.DataFrame(columns = [\"name1\", \"name2\", \"frames\"])\n",
    "        df_dict['name1'] = df_clust['APosition1'] \n",
    "        df_dict['name2'] = df_clust['APosition2']\n",
    "        df_dict['frames'] = [[1]]*len(df_dict)\n",
    "        df_dict['color'] = df_clust['color']\n",
    "        df_dict['value'] = df_clust['mean']\n",
    "        edges = df_dict.to_dict(orient=\"records\")\n",
    "\n",
    "        # Appending edges to flare plot template, if any submitted\n",
    "        if flare_template:\n",
    "            flare_template['edges'] = edges\n",
    "            jsondict = flare_template\n",
    "        else:\n",
    "            jsondict = { 'edges' : edges }\n",
    "\n",
    "        #'Edge' multi-entries, based on the 4 GPCR nomenclatures\n",
    "        for leter in ['A', 'B', 'C', 'F']:\n",
    "            df_dict = pd.DataFrame(columns = [\"name1\", \"name2\", \"frames\"])\n",
    "            df_dict['name1'] = df_clust[leter+'Position1'] \n",
    "            df_dict['name2'] = df_clust[leter+'Position2']\n",
    "            df_dict['frames'] = [[1]]*len(df_dict)\n",
    "            df_dict['color'] = df_clust['color']\n",
    "            df_dict['value'] = df_clust['mean']\n",
    "            leter_edges = df_dict.to_dict(orient=\"records\")\n",
    "\n",
    "            #Appending edges\n",
    "            if flare_template:\n",
    "                flare_template[leter+'edges'] = leter_edges\n",
    "                jsondict = flare_template\n",
    "            else:\n",
    "                jsondict = { leter+'edges' : leter_edges }\n",
    "\n",
    "        #Writing json\n",
    "        jsonpath = folderpath + clust + \".json\"\n",
    "        with open(jsonpath, 'w') as jsonfile:\n",
    "            dump(jsondict, jsonfile, ensure_ascii=False, indent = 4)\n",
    "\n",
    "def dendrogram_clustering(dend_matrix, labels, height, width, filename, clusters, recept_info, recept_info_order): \n",
    "\n",
    "    # Define linkage function (we'll be using the default one for plotly). \n",
    "    linkagefun=lambda x: linkage(x, 'complete')\n",
    "    (thres,clustdict) = clustering(clusters, dend_matrix, labels, linkagefun)\n",
    "\n",
    "    # Create color scale from the \"category20\" color scale. Not working because color_scale plotly option is inoperative\n",
    "    colors_category20 = ['rgb(31, 119, 180)', 'rgb(174, 199, 232)', 'rgb(255, 127, 14)', 'rgb(255, 187, 120)', 'rgb(44, 160, 44)', 'rgb(152, 223, 138)', 'rgb(214, 39, 40)', 'rgb(255, 152, 150)', 'rgb(148, 103, 189)', 'rgb(197, 176, 213)', 'rgb(140, 86, 75)', 'rgb(196, 156, 148)', 'rgb(227, 119, 194)', 'rgb(247, 182, 210)', 'rgb(127, 127, 127)', 'rgb(199, 199, 199)', 'rgb(188, 189, 34)', 'rgb(219, 219, 141)', 'rgb(23, 190, 207)', 'rgb(158, 218, 229)']\n",
    "    colors = colors_category20[0:clusters]\n",
    "\n",
    "    # Setting figures\n",
    "    fig = create_dendrogram(\n",
    "        dend_matrix,\n",
    "        orientation='right',\n",
    "        labels=labels,\n",
    "        linkagefun=linkagefun,\n",
    "        color_threshold = thres,\n",
    "        hovertext = labels,\n",
    "    )\n",
    "\n",
    "    fig['layout'].update({\n",
    "        'width':width, \n",
    "        'height':height,\n",
    "        'hoverdistance' : 10,\n",
    "        'plot_bgcolor' : \"#FFFFFF\"\n",
    "        })\n",
    "\n",
    "    fig['layout']['margin'].update({\n",
    "        'r' : 150,\n",
    "        'l' : 100,\n",
    "        't' : 200,#This problem with the phantom margin has to be solved at some point\n",
    "        'b' : 0,\n",
    "        'pad' : 0,\n",
    "        'autoexpand' : False,\n",
    "        })\n",
    "\n",
    "    fig['layout']['xaxis'].update({\n",
    "        'showline': False,\n",
    "        'showticklabels': False,\n",
    "        'ticks' : '',\n",
    "        'fixedrange' : True,\n",
    "        'automargin' : False\n",
    "        })\n",
    "\n",
    "    fig['layout']['yaxis'].update({\n",
    "        'side' : 'right',\n",
    "        'showline': False,\n",
    "        'ticks' : '',\n",
    "        'tickfont' : {\n",
    "            'size' : 15,\n",
    "            'color' : 'white'\n",
    "            },\n",
    "        'fixedrange' : True,\n",
    "        'automargin' : False\n",
    "        })\n",
    "\n",
    "    #Annotating cluster nodes\n",
    "    annotations = annotate_clusters(fig, 'rgb(0,116,217)') # Default color for tree\n",
    "\n",
    "    # Correcting hoverlabels\n",
    "    fig = hoverlabels_axis(fig, recept_info, recept_info_order, 'rgb(0,116,217)', annotations)\n",
    "\n",
    "    # Taking order for plot rows\n",
    "    dendro_leaves = fig['layout']['yaxis']['ticktext']\n",
    "\n",
    "    # Writing dendrogram on file\n",
    "    fig.write_html(filename, auto_open=False,config={\n",
    "        \"displayModeBar\": \"hover\",\n",
    "        \"showAxisDragHandles\": False,\n",
    "        \"showAxisRangeEntryBoxes\": False,\n",
    "        \"scrollZoom\": False,\n",
    "        \"showTips\" : False,\n",
    "        \"modeBarButtons\": [[\"toImage\"]]\n",
    "    })\n",
    "    return (list(dendro_leaves),clustdict)\n",
    "\n",
    "def create_dyntoname_file(dyn_dend_order, recept_info, recept_info_order, options_path):\n",
    "    \"\"\"\n",
    "    Creates a list of tuples, each one containing dynID-receptor names pairs\n",
    "    Needed to display menu dropdown's receptor names in same order as dendrogram\n",
    "    \"\"\"\n",
    "    unique_name_index = recept_info_order['receptor_unique_name']\n",
    "    dyn_names = [ recept_info[dyn][unique_name_index] for dyn in dyn_dend_order ]\n",
    "    dyn_to_names = list(zip(dyn_dend_order, list(dyn_names)))\n",
    "    dyn_to_names.reverse()\n",
    "    with open(options_path+\"name_to_dyn_dict.json\", \"w\") as dyn_names_file:\n",
    "        dump(dyn_to_names, dyn_names_file, ensure_ascii=False, indent = 4)\n",
    "\n",
    "def add_restypes(df, compl_data, recept_info, recept_info_order):\n",
    "    \"\"\"\n",
    "    Add a new column with the residue type (ARG, CYS, TRP) of each position in each simulation\n",
    "    \"\"\"\n",
    "    AAs =  {'C': 'CYS', 'D': 'ASP', 'S': 'SER', 'Q': 'GLN', 'K': 'LYS',\n",
    "     'I': 'ILE', 'P': 'PRO', 'T': 'THR', 'F': 'PHE', 'N': 'ASN', \n",
    "     'G': 'GLY', 'H': 'HIS', 'L': 'LEU', 'R': 'ARG', 'W': 'TRP', \n",
    "     'A': 'ALA', 'V': 'VAL', 'E': 'GLU', 'Y': 'TYR', 'M': 'MET'}\n",
    "    GPCRclass_numbers = {'A':1, 'B':2, 'C':3, 'F':4}\n",
    "    class_index = recept_info_order['gpcr_class']\n",
    "\n",
    "    def get_restype_and_realpos(dynid_col, pos_col):\n",
    "        \"\"\"\n",
    "        Return residue type of position and the position identifier for this position in this protein\n",
    "        It's a bit complex, for I need to distinguish which GPCR class nomenclature uses this protein\n",
    "        \"\"\"\n",
    "        restype_list = []\n",
    "        prot_pos = []\n",
    "        for dynid,pos in zip(dynid_col, pos_col):\n",
    "            if pos == 'Ligand':\n",
    "                restype_list.append('')\n",
    "                prot_pos.append('Ligand')\n",
    "            else: \n",
    "                GPCRclass_number = GPCRclass_numbers[recept_info[dynid][class_index]] \n",
    "                class_pos_array = pos.split('\\n')\n",
    "                class_pos = class_pos_array[0]+class_pos_array[GPCRclass_number]\n",
    "\n",
    "                if class_pos in compl_data[dynid]['gpcr_pdb']: \n",
    "                    restype = compl_data[dynid]['gpcr_pdb'][class_pos][-1]\n",
    "                    restype_list.append(restype)\n",
    "                    prot_pos.append(class_pos)\n",
    "                else:\n",
    "                    #print(\"Position %s not found in %s\" %(class_pos, dynid)) #Too much output\n",
    "                    restype_list.append(\"(N/A)\")\n",
    "                    prot_pos.append(class_pos)\n",
    "\n",
    "        return(restype_list,prot_pos)\n",
    "\n",
    "    #Split Position column\n",
    "    new = df['Position'].str.split(\"\\n\\n\", n = 1, expand = True)\n",
    "    df['Position 1'] = new[0]\n",
    "    df['Position 2'] = new[1]\n",
    "\n",
    "    #Add residue type and protein position column\n",
    "    (restype_1, protein_Position_1) = get_restype_and_realpos(df['Id'], df['Position 1'].values)\n",
    "    df['restype_1'] = restype_1\n",
    "    df['protein_Position 1'] = protein_Position_1\n",
    "    (restype_2, protein_Position_2) = get_restype_and_realpos(df['Id'], df['Position 2'].values)\n",
    "    df['restype_2'] = restype_2\n",
    "    df['protein_Position 2'] = protein_Position_2\n",
    "    \n",
    "    df['restypes'] = df['restype_1'] +\" \"+ df['restype_2']  \n",
    "    df['protein_Position'] = df['protein_Position 1'] +\" \"+ df['protein_Position 2']\n",
    "    df['restypePosition'] = df['restype_1'] + df['protein_Position 1'] + \" \" + df['restype_2'] + df['protein_Position 2']\n",
    "    \n",
    "    #Drop Position, proteinPosition and restype columns once they are not needed\n",
    "    df.drop(columns = ['Position 1','Position 2','restype_1','restype_2','protein_Position 1','protein_Position 2'], inplace = True)\n",
    "  \n",
    "    return df\n",
    "\n",
    "def new_columns(df, itype):\n",
    "    \"\"\"\n",
    "    Adding Position1 and Position2 columns from A nomenclature system to dataframe, in subsitution of\n",
    "    Position column, which included both.\n",
    "    \"\"\"\n",
    "\n",
    "    def split_by_class(position_col):\n",
    "        \"\"\"\n",
    "        Split 2x\\n26\\n12\\n12\\n12 into 2x26 2x12 2x12 2x12 2x12\n",
    "        \"\"\"\n",
    "        name = position_col.name\n",
    "        positions = position_col.values\n",
    "        pos_by_class = {\"A\"+name :[], \"B\"+name :[], \"C\"+name :[], \"F\"+name :[]}\n",
    "        number_letter = [\"0\",'A','B', 'C', 'F']\n",
    "        for pos in positions:\n",
    "            splited_pos = pos.split(\"x\")\n",
    "            for i in [1,2,3,4]:\n",
    "                if pos == \"Ligand\":\n",
    "                    pos_by_class[number_letter[i]+name].append(\"Ligand\")\n",
    "                else:\n",
    "                    pos_by_class[number_letter[i]+name].append(splited_pos[0]+\"x\"+splited_pos[i])\n",
    "\n",
    "        return(pd.DataFrame.from_dict(pos_by_class))\n",
    "\n",
    "    #Delete non-main itypes\n",
    "    df = df[df['itype']==itype]\n",
    "    \n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "    df_newcols1 =  split_by_class(df[\"Position1\"])\n",
    "    df_newcols2 =  split_by_class(df[\"Position2\"])\n",
    "    df = pd.concat([df, df_newcols1, df_newcols2], axis = 1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def sort_simulations(df_ts, dyn_dend_order):\n",
    "    \"\"\"\n",
    "    Sorts the simulations in the dataframe according to the order in the list dyn_dend_order\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a dictionary with the order of each simulation row in the plot \n",
    "    dyn_dend_order_dict = { dyn_name : dyn_dend_order.index(dyn_name) for dyn_name in dyn_dend_order }\n",
    "\n",
    "    # Adding column based in new order recieved from clustering\n",
    "    df_ts['clust_order'] =  df_ts['Id'].apply(lambda x: dyn_dend_order_dict[x])\n",
    "\n",
    "    #Sorting by ballesteros Id's (helixloop column) and clustering order\n",
    "    df_ts['helixloop'] = df_ts['Position'].apply(lambda x: re.sub(r'^(\\d)x',r'\\g<1>0x',x)) \n",
    "    df_ts = df_ts.sort_values([\"helixloop\",'clust_order'])\n",
    "\n",
    "    #Drop sort columns once used\n",
    "    df_ts.drop(['helixloop','clust_order'], axis = 1, inplace = True)\n",
    "    \n",
    "    return df_ts\n",
    "\n",
    "def reverse_positions(df):\n",
    "    \"\"\"\n",
    "    Appends a copy of the dataframe with the Position pair of the interaction being reversed (5x43-7x89 for 7x89-5x43)\n",
    "    \"\"\"\n",
    "    df_rev = df.copy(deep = True)\n",
    "    divided_positions = df_rev['Position'].str.split('\\n\\n',expand = True)\n",
    "    df_rev['Position'] = divided_positions[1] + \"\\n\\n\" + divided_positions[0]\n",
    "    df_double = pd.concat([df, df_rev])\n",
    "    return df_double\n",
    "\n",
    "def create_hovertool(itype, itypes_order, hb_itypes, typelist):\n",
    "    \"\"\"\n",
    "    Creates a list in hovertool format from the two dictionaries above\n",
    "    \"\"\"\n",
    "\n",
    "    #Creating hovertool listzzzz\n",
    "    hoverlist = [('Name', '@Name'),\n",
    "                 ('PDB id', '@pdb_id'),\n",
    "                 ('Position', '@restypePosition'),\n",
    "                 (typelist[itype], \"@{\" + itype + '}{0.00}%')\n",
    "                ]\n",
    "\n",
    "    #Hover tool:\n",
    "    hover = HoverTool(\n",
    "        tooltips=hoverlist\n",
    "    )\n",
    "\n",
    "    return hover\n",
    "  \n",
    "def define_figure(width, height, dataframe, hover, itype):\n",
    "    \"\"\"\n",
    "    Prepare bokeh figure heatmap as intended\n",
    "    \"\"\"\n",
    "\n",
    "    # Mapper colors\n",
    "    colors_auld = ['#800000', '#860000', '#8c0000', '#930000', '#990000', '#9f0000', '#a60000', '#ac0000', '#b20000', '#b90000', '#bf0000', '#c50000', '#cc0000', '#d20000', '#d80000', '#df0000', '#e50000', '#eb0000', '#f20000', '#f80000', '#ff0000', '#ff0700', '#ff0e00', '#ff1500', '#ff1c00', '#ff2300', '#ff2a00', '#ff3100', '#ff3800', '#ff3f00', '#ff4600', '#ff4d00', '#ff5400', '#ff5b00', '#ff6200', '#ff6900', '#ff7000', '#ff7700', '#ff7e00', '#ff8500', '#ff8c00', '#ff9100', '#ff9700', '#ff9d00', '#ffa300', '#ffa800', '#ffae00', '#ffb400', '#ffba00', '#ffbf00', '#ffc500', '#ffcb00', '#ffd100', '#ffd600', '#ffdc00', '#ffe200', '#ffe800', '#ffed00', '#fff300', '#fff900', '#ffff00', '#f2ff00', '#e5ff00', '#d8ff00', '#ccff00', '#bfff00', '#b2ff00', '#a5ff00', '#99ff00', '#8cff00', '#7fff00', '#72ff00', '#66ff00', '#59ff00', '#4cff00', '#3fff00', '#33ff00', '#26ff00', '#19ff00', '#0cff00', '#00ff00', '#0afc0a', '#15fa15', '#1ff81f', '#2af62a', '#34f434', '#3ff13f', '#49ef49', '#54ed54', '#5eeb5e', '#69e969', '#74e674', '#7ee47e', '#89e289', '#93e093', '#9ede9e', '#a8dba8', '#b3d9b3', '#bdd7bd', '#c8d5c8', '#d3d3d3']\n",
    "    colors_ylorrd = ['#800026', '#850026', '#8a0026', '#8f0026', '#940026', '#990026', '#9e0026', '#a30026', '#a80026', '#ad0026', '#b20026', '#b70026', '#bd0026', '#c00225', '#c30424', '#c60623', '#c90822', '#cc0a21', '#d00d21', '#d30f20', '#d6111f', '#d9131e', '#dc151d', '#df171c', '#e31a1c', '#e51e1d', '#e7221e', '#e9271f', '#eb2b20', '#ed2f21', '#ef3423', '#f13824', '#f33c25', '#f54126', '#f74527', '#f94928', '#fc4e2a', '#fc532b', '#fc582d', '#fc5d2e', '#fc6330', '#fc6831', '#fc6d33', '#fc7234', '#fc7836', '#fc7d37', '#fc8239', '#fc873a', '#fd8d3c', '#fd903d', '#fd933e', '#fd9640', '#fd9941', '#fd9c42', '#fd9f44', '#fda245', '#fda546', '#fda848', '#fdab49', '#fdae4a', '#feb24c', '#feb54f', '#feb853', '#febb56', '#febf5a', '#fec25d', '#fec561', '#fec864', '#fecc68', '#fecf6b', '#fed26f', '#fed572', '#fed976', '#feda79', '#fedc7d', '#fede80', '#fedf84', '#fee187', '#fee38b', '#fee48e', '#fee692', '#fee895', '#fee999', '#feeb9c', '#ffeda0', '#ffeea3', '#fff0a7', '#fff1ab', '#fff3ae', '#fff4b2', '#fff6b6', '#fff7b9', '#fff9bd', '#fffac1', '#fffcc4', '#fffdc8', '#ffffcc']\n",
    "    colors_grorrd = ['#800026', '#850026', '#8a0026', '#8f0026', '#940026', '#990026', '#9e0026', '#a30026', '#a80026', '#ad0026', '#b20026', '#b70026', '#bd0026', '#c00225', '#c30424', '#c60623', '#c90822', '#cc0a21', '#d00d21', '#d30f20', '#d6111f', '#d9131e', '#dc151d', '#df171c', '#e31a1c', '#e51e1d', '#e7221e', '#e9271f', '#eb2b20', '#ed2f21', '#ef3423', '#f13824', '#f33c25', '#f54126', '#f74527', '#f94928', '#fc4e2a', '#fc532b', '#fc582d', '#fc5d2e', '#fc6330', '#fc6831', '#fc6d33', '#fc7234', '#fc7836', '#fc7d37', '#fc8239', '#fc873a', '#fd8d3c', '#fd903d', '#fd933e', '#fd9640', '#fd9941', '#fd9c42', '#fd9f44', '#fda245', '#fda546', '#fda848', '#fdab49', '#fdae4a', '#feb24c', '#feb54f', '#feb853', '#febb56', '#febf5a', '#fec25d', '#fec561', '#fec864', '#fecc68', '#fecf6b', '#fed26f', '#fed572', '#fed976', '#feda79', '#fedc7d', '#fede80', '#fedf84', '#fee187', '#fee38b', '#fee48e', '#fee692', '#fee895', '#fee999', '#feeb9c', '#ffeda0', '#fbeaa4', '#f7e8a8', '#f4e6ac', '#f0e4b1', '#ece2b5', '#e9e0b9', '#e5ddbd', '#e1dbc2', '#ded9c6', '#dad7ca', '#d6d5ce', '#d3d3d3']\n",
    "    colors_inferno = ['#000003', '#000004', '#000006', '#010007', '#010109', '#01010B', '#02010E', '#020210', '#030212', '#040314', '#040316', '#050418', '#06041B', '#07051D', '#08061F', '#090621', '#0A0723', '#0B0726', '#0D0828', '#0E082A', '#0F092D', '#10092F', '#120A32', '#130A34', '#140B36', '#160B39', '#170B3B', '#190B3E', '#1A0B40', '#1C0C43', '#1D0C45', '#1F0C47', '#200C4A', '#220B4C', '#240B4E', '#260B50', '#270B52', '#290B54', '#2B0A56', '#2D0A58', '#2E0A5A', '#300A5C', '#32095D', '#34095F', '#350960', '#370961', '#390962', '#3B0964', '#3C0965', '#3E0966', '#400966', '#410967', '#430A68', '#450A69', '#460A69', '#480B6A', '#4A0B6A', '#4B0C6B', '#4D0C6B', '#4F0D6C', '#500D6C', '#520E6C', '#530E6D', '#550F6D', '#570F6D', '#58106D', '#5A116D', '#5B116E', '#5D126E', '#5F126E', '#60136E', '#62146E', '#63146E', '#65156E', '#66156E', '#68166E', '#6A176E', '#6B176E', '#6D186E', '#6E186E', '#70196E', '#72196D', '#731A6D', '#751B6D', '#761B6D', '#781C6D', '#7A1C6D', '#7B1D6C', '#7D1D6C', '#7E1E6C', '#801F6B', '#811F6B', '#83206B', '#85206A', '#86216A', '#88216A', '#892269', '#8B2269', '#8D2369', '#8E2468', '#902468', '#912567', '#932567', '#952666', '#962666', '#982765', '#992864', '#9B2864', '#9C2963', '#9E2963', '#A02A62', '#A12B61', '#A32B61', '#A42C60', '#A62C5F', '#A72D5F', '#A92E5E', '#AB2E5D', '#AC2F5C', '#AE305B', '#AF315B', '#B1315A', '#B23259', '#B43358', '#B53357', '#B73456', '#B83556', '#BA3655', '#BB3754', '#BD3753', '#BE3852', '#BF3951', '#C13A50', '#C23B4F', '#C43C4E', '#C53D4D', '#C73E4C', '#C83E4B', '#C93F4A', '#CB4049', '#CC4148', '#CD4247', '#CF4446', '#D04544', '#D14643', '#D24742', '#D44841', '#D54940', '#D64A3F', '#D74B3E', '#D94D3D', '#DA4E3B', '#DB4F3A', '#DC5039', '#DD5238', '#DE5337', '#DF5436', '#E05634', '#E25733', '#E35832', '#E45A31', '#E55B30', '#E65C2E', '#E65E2D', '#E75F2C', '#E8612B', '#E9622A', '#EA6428', '#EB6527', '#EC6726', '#ED6825', '#ED6A23', '#EE6C22', '#EF6D21', '#F06F1F', '#F0701E', '#F1721D', '#F2741C', '#F2751A', '#F37719', '#F37918', '#F47A16', '#F57C15', '#F57E14', '#F68012', '#F68111', '#F78310', '#F7850E', '#F8870D', '#F8880C', '#F88A0B', '#F98C09', '#F98E08', '#F99008', '#FA9107', '#FA9306', '#FA9506', '#FA9706', '#FB9906', '#FB9B06', '#FB9D06', '#FB9E07', '#FBA007', '#FBA208', '#FBA40A', '#FBA60B', '#FBA80D', '#FBAA0E', '#FBAC10', '#FBAE12', '#FBB014', '#FBB116', '#FBB318', '#FBB51A', '#FBB71C', '#FBB91E', '#FABB21', '#FABD23', '#FABF25', '#FAC128', '#F9C32A', '#F9C52C', '#F9C72F', '#F8C931', '#F8CB34', '#F8CD37', '#F7CF3A', '#F7D13C', '#F6D33F', '#F6D542', '#F5D745', '#F5D948', '#F4DB4B', '#F4DC4F', '#F3DE52', '#F3E056', '#F3E259', '#F2E45D', '#F2E660', '#F1E864', '#F1E968', '#F1EB6C', '#F1ED70', '#F1EE74', '#F1F079', '#F1F27D', '#F2F381', '#F2F485', '#F3F689', '#F4F78D', '#F5F891', '#F6FA95', '#F7FB99', '#F9FC9D', '#FAFDA0', '#FCFEA4']\n",
    "    colors_magma = ['#000003', '#000004', '#000006', '#010007', '#010109', '#01010B', '#02020D', '#02020F', '#030311', '#040313', '#040415', '#050417', '#060519', '#07051B', '#08061D', '#09071F', '#0A0722', '#0B0824', '#0C0926', '#0D0A28', '#0E0A2A', '#0F0B2C', '#100C2F', '#110C31', '#120D33', '#140D35', '#150E38', '#160E3A', '#170F3C', '#180F3F', '#1A1041', '#1B1044', '#1C1046', '#1E1049', '#1F114B', '#20114D', '#221150', '#231152', '#251155', '#261157', '#281159', '#2A115C', '#2B115E', '#2D1060', '#2F1062', '#301065', '#321067', '#341068', '#350F6A', '#370F6C', '#390F6E', '#3B0F6F', '#3C0F71', '#3E0F72', '#400F73', '#420F74', '#430F75', '#450F76', '#470F77', '#481078', '#4A1079', '#4B1079', '#4D117A', '#4F117B', '#50127B', '#52127C', '#53137C', '#55137D', '#57147D', '#58157E', '#5A157E', '#5B167E', '#5D177E', '#5E177F', '#60187F', '#61187F', '#63197F', '#651A80', '#661A80', '#681B80', '#691C80', '#6B1C80', '#6C1D80', '#6E1E81', '#6F1E81', '#711F81', '#731F81', '#742081', '#762181', '#772181', '#792281', '#7A2281', '#7C2381', '#7E2481', '#7F2481', '#812581', '#822581', '#842681', '#852681', '#872781', '#892881', '#8A2881', '#8C2980', '#8D2980', '#8F2A80', '#912A80', '#922B80', '#942B80', '#952C80', '#972C7F', '#992D7F', '#9A2D7F', '#9C2E7F', '#9E2E7E', '#9F2F7E', '#A12F7E', '#A3307E', '#A4307D', '#A6317D', '#A7317D', '#A9327C', '#AB337C', '#AC337B', '#AE347B', '#B0347B', '#B1357A', '#B3357A', '#B53679', '#B63679', '#B83778', '#B93778', '#BB3877', '#BD3977', '#BE3976', '#C03A75', '#C23A75', '#C33B74', '#C53C74', '#C63C73', '#C83D72', '#CA3E72', '#CB3E71', '#CD3F70', '#CE4070', '#D0416F', '#D1426E', '#D3426D', '#D4436D', '#D6446C', '#D7456B', '#D9466A', '#DA4769', '#DC4869', '#DD4968', '#DE4A67', '#E04B66', '#E14C66', '#E24D65', '#E44E64', '#E55063', '#E65162', '#E75262', '#E85461', '#EA5560', '#EB5660', '#EC585F', '#ED595F', '#EE5B5E', '#EE5D5D', '#EF5E5D', '#F0605D', '#F1615C', '#F2635C', '#F3655C', '#F3675B', '#F4685B', '#F56A5B', '#F56C5B', '#F66E5B', '#F6705B', '#F7715B', '#F7735C', '#F8755C', '#F8775C', '#F9795C', '#F97B5D', '#F97D5D', '#FA7F5E', '#FA805E', '#FA825F', '#FB8460', '#FB8660', '#FB8861', '#FB8A62', '#FC8C63', '#FC8E63', '#FC9064', '#FC9265', '#FC9366', '#FD9567', '#FD9768', '#FD9969', '#FD9B6A', '#FD9D6B', '#FD9F6C', '#FDA16E', '#FDA26F', '#FDA470', '#FEA671', '#FEA873', '#FEAA74', '#FEAC75', '#FEAE76', '#FEAF78', '#FEB179', '#FEB37B', '#FEB57C', '#FEB77D', '#FEB97F', '#FEBB80', '#FEBC82', '#FEBE83', '#FEC085', '#FEC286', '#FEC488', '#FEC689', '#FEC78B', '#FEC98D', '#FECB8E', '#FDCD90', '#FDCF92', '#FDD193', '#FDD295', '#FDD497', '#FDD698', '#FDD89A', '#FDDA9C', '#FDDC9D', '#FDDD9F', '#FDDFA1', '#FDE1A3', '#FCE3A5', '#FCE5A6', '#FCE6A8', '#FCE8AA', '#FCEAAC', '#FCECAE', '#FCEEB0', '#FCF0B1', '#FCF1B3', '#FCF3B5', '#FCF5B7', '#FBF7B9', '#FBF9BB', '#FBFABD', '#FBFCBF']\n",
    "    colors_ylgnbl = ['#081d58', '#0a1e5d', '#0c2062', '#0f2267', '#11246c', '#142671', '#162876', '#182a7b', '#1b2c80', '#1d2e85', '#20308a', '#22328f', '#253494', '#243795', '#243b97', '#243e99', '#24429a', '#23459c', '#23499e', '#234c9f', '#2350a1', '#2253a3', '#2257a4', '#225aa6', '#225ea8', '#2162aa', '#2166ac', '#206aae', '#206fb0', '#1f73b2', '#1f77b4', '#1f7bb6', '#1e80b8', '#1e84ba', '#1d88bc', '#1d8cbe', '#1d91c0', '#2094c0', '#2397c0', '#269ac1', '#299dc1', '#2ca0c1', '#2fa3c2', '#32a6c2', '#35a9c2', '#38acc3', '#3bafc3', '#3eb2c3', '#41b6c4', '#46b7c3', '#4bb9c2', '#50bbc1', '#55bdc1', '#5abfc0', '#60c1bf', '#65c3be', '#6ac5be', '#6fc7bd', '#74c9bc', '#79cbbb', '#7fcdbb', '#85cfba', '#8bd1b9', '#91d4b9', '#97d6b8', '#9dd8b8', '#a3dbb7', '#a9ddb6', '#afdfb6', '#b5e2b5', '#bbe4b5', '#c1e6b4', '#c7e9b4', '#caeab3', '#cdebb3', '#d0ecb3', '#d3eeb3', '#d6efb2', '#daf0b2', '#ddf1b2', '#e0f3b2', '#e3f4b1', '#e6f5b1', '#e9f6b1', '#edf8b1', '#eef8b4', '#f0f9b7', '#f1f9bb', '#f3fabe', '#f4fac1', '#f6fbc5', '#f7fcc8', '#f9fccb', '#fafdcf', '#fcfdd2', '#fdfed5', '#ffffd9']\n",
    "    colors = colors_grorrd\n",
    "    colors.reverse()\n",
    "    mapper = LinearColorMapper(palette=colors, low=0, high=100)\n",
    "\n",
    "    #Bokeh figure\n",
    "    p = figure(\n",
    "        plot_width= width,\n",
    "        plot_height=height,\n",
    "        #title=\"Example freq\",\n",
    "        y_range=list(dataframe.Id.drop_duplicates()),\n",
    "        x_range=list(dataframe.Position.drop_duplicates()),\n",
    "        tools=[\"hover\",\"tap\",\"save\",\"reset\",\"wheel_zoom\"], \n",
    "        x_axis_location=\"above\",\n",
    "        active_drag=None,\n",
    "        toolbar_location=\"right\",\n",
    "        toolbar_sticky = False,\n",
    "        min_border_top = 200,#leave some space for x-axis artificial labels\n",
    "        min_border_bottom = 0,\n",
    "    )\n",
    "\n",
    "    # Create rectangle for heatmap\n",
    "    mysource = ColumnDataSource(dataframe)\n",
    "    p.rect(\n",
    "        y=\"Id\", \n",
    "        x=\"Position\",\n",
    "        width=1, \n",
    "        height=1, \n",
    "        source=mysource,\n",
    "        line_color=\"white\", \n",
    "        fill_color=transform(itype, mapper),\n",
    "\n",
    "        # set visual properties for selected glyphs\n",
    "        selection_line_color=\"black\",\n",
    "        selection_fill_color=transform(itype, mapper),\n",
    "        # set visual properties for non-selected glyphs\n",
    "        nonselection_fill_color=transform(itype, mapper),\n",
    "        nonselection_fill_alpha=1,\n",
    "        nonselection_line_alpha=1,\n",
    "        nonselection_line_color=\"white\"\n",
    "        )\n",
    "\n",
    "    #Very poor way of creating X-axis labels. Necessary for having linejumps inside the axis labels\n",
    "    x_cord = 0\n",
    "    y_cord = len(list(dataframe.Id.drop_duplicates()))+11#Position: 11 spaces above the plot's top border\n",
    "    foolabel = Label(x=-1,\n",
    "                     y=y_cord,\n",
    "                     text='\\nA: \\nB: \\nC: \\nF: \\n\\n\\nA: \\nB: \\nC: \\nF: \\n',\n",
    "                     render_mode='css', \n",
    "                     border_line_alpha=1.0,\n",
    "                     text_font_size = \"10pt\",\n",
    "                     background_fill_color = \"#FFFFFF\")\n",
    "    p.add_layout(foolabel)\n",
    "\n",
    "    #Fore every unique position in the set, add a label in axis\n",
    "    for position in list(dataframe.Position.drop_duplicates()):\n",
    "        position = position.replace(\"Ligand\",\"Lig\\n\\n\\n\\n\\n\")\n",
    "        foolabel = Label(x=x_cord,\n",
    "                         y=y_cord,\n",
    "                         text=position,\n",
    "                         render_mode='css', \n",
    "                         border_line_alpha=1.0,\n",
    "                         background_fill_color = \"#FFFFFF\",\n",
    "                         text_font_size = \"10pt\")\n",
    "        p.add_layout(foolabel)\n",
    "        x_cord +=1\n",
    "\n",
    "    # Setting axis\n",
    "    p.axis.axis_line_color = None\n",
    "    p.axis.major_tick_line_color = None\n",
    "    p.xaxis.major_label_text_font_size = \"10pt\"\n",
    "    p.yaxis.major_label_text_font_size = \"10pt\"\n",
    "    p.yaxis.visible = False\n",
    "    p.xaxis.visible = False\n",
    "    p.axis.major_label_standoff = 0\n",
    "    p.xaxis.major_label_orientation = 1\n",
    "\n",
    "    # Adding hover\n",
    "    p.add_tools(hover)\n",
    "\n",
    "    # Needed later\n",
    "    return(mysource,p)\n",
    "\n",
    "def select_tool_callback(recept_info, recept_info_order, dyn_gpcr_pdb, itype, typelist, mysource):\n",
    "    \"\"\"\n",
    "    Prepares the javascript script necessary for the side-window\n",
    "    \"\"\"\n",
    "    \n",
    "    #Create data source\n",
    "    df_ri=pd.DataFrame(recept_info)\n",
    "    ri_source=ColumnDataSource(df_ri)\n",
    "    df_rio=pd.DataFrame(recept_info_order, index=[0])\n",
    "    rio_source=ColumnDataSource(df_rio)\n",
    "    df_gnum=pd.DataFrame(dyn_gpcr_pdb)\n",
    "    gnum_source=ColumnDataSource(df_gnum)\n",
    "\n",
    "    #Select tool and callback: (SIMPLIFIED)\n",
    "    mysource.js_events_callbacks = CustomJS(\n",
    "        args={\"r_info\":ri_source,\"ro_info\":rio_source,\"gnum_info\":gnum_source,\"itype\":itype, \"typelist\" : typelist},\n",
    "        code=\"\"\"\n",
    "            var sel_ind = cb_obj.selected[\"1d\"].indices;\n",
    "            var plot_bclass=$(\"#retracting_parts\").attr(\"class\");\n",
    "            if (sel_ind.length != 0){\n",
    "                var data = cb_obj.data;\n",
    "                var ri_data=r_info.data;\n",
    "                var rio_data=ro_info.data;\n",
    "                var gnum_data=gnum_info.data;\n",
    "                var recept_name=data[\"Name\"][sel_ind];\n",
    "                var recept_id=data[\"Id\"][sel_ind];\n",
    "                var pos = data[\"protein_Position\"][sel_ind];\n",
    "                var restypepos = data[\"restypePosition\"][sel_ind];\n",
    "                var freq_type=data[itype][sel_ind];\n",
    "                var pos_array = pos.split(\" \");\n",
    "                var pos_string = pos_array.join(\"_\")\n",
    "                var pos_ind_array = pos_array.map(value => { return gnum_data['index'].indexOf(value); });\n",
    "                var pdb_pos_array = pos_ind_array.map(value => { return gnum_data[recept_name][value]; });\n",
    "                var lig=ri_data[recept_id][rio_data['lig_sname']];\n",
    "                var lig_lname=ri_data[recept_id][rio_data['lig_lname']];\n",
    "                var recept=ri_data[recept_id][rio_data['upname']];\n",
    "                var dyn_id_pre=ri_data[recept_id][rio_data['dyn_id']];\n",
    "                var dyn_id=dyn_id_pre.match(/\\d*$/)[0];\n",
    "                var prot_id=ri_data[recept_id][rio_data['prot_id']];\n",
    "                var prot_lname=ri_data[recept_id][rio_data['prot_lname']];\n",
    "                var comp_id=ri_data[recept_id][rio_data['comp_id']];\n",
    "                var struc_fname=ri_data[recept_id][rio_data['struc_fname']];\n",
    "                var struc_file=ri_data[recept_id][rio_data['struc_f']];\n",
    "                var traj_fnames=ri_data[recept_id][rio_data['traj_fnames']];\n",
    "                var traj_f=ri_data[recept_id][rio_data['traj_f']];\n",
    "                var pdb_id=ri_data[recept_id][rio_data['pdb_id']];\n",
    "                var pdb_id_nochain = pdb_id.split(\".\")[0];\n",
    "                var delta=ri_data[recept_id][rio_data['delta']];\n",
    "                $('#ngl_iframe')[0].contentWindow.$('body').trigger('createNewRef', [struc_file, traj_fnames, traj_f ,lig, delta, pos, pdb_pos_array]);\n",
    "             \n",
    "                if (plot_bclass != \"col-xs-9\"){\n",
    "                    $(\"#retracting_parts\").attr(\"class\",\"col-xs-9\");\n",
    "                    $(\"#first_col\").attr(\"class\",\"col-xs-7\");\n",
    "                    $(\"#second_col\").attr(\"class\",\"col-xs-5\");\n",
    "                    $(\"#info\").css({\"visibility\":\"visible\",\"position\":\"relative\",\"z-index\":\"auto\"});\n",
    "                }\n",
    "                \n",
    "                //Show NA comment if there is a NA in the position\n",
    "                if(/N\\/A/.test(restypepos)){\n",
    "                    $('#na_comment').show();\n",
    "                }\n",
    "\n",
    "                //Setting type specific frequencies\n",
    "                $( \"#freq_\" + itype).html(freq_type.toFixed(2) + \"%\");\n",
    "                if (itype == \"all\") {\n",
    "                    for (my_type in typelist) {\n",
    "                        freq_type = data[my_type][sel_ind];\n",
    "                        $( \"#freq_\" + my_type).html(parseFloat(freq_type).toFixed(2) + \"%\");\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                $(\"#recept_val\").html(prot_lname + \" (\"+recept+\")\");\n",
    "                $(\"#pos_val\").html(restypepos);\n",
    "                $(\"#pdb_id\").html(pdb_id);\n",
    "                $(\"#pdb_link\").attr(\"href\",\"https://www.rcsb.org/structure/\" + pdb_id_nochain)\n",
    "                if (Boolean(lig)) {\n",
    "                    $(\"#lig_val\").html(lig_lname + \" (\"+lig+\")\");\n",
    "                    $(\"#lig_link\").show();\n",
    "                    $(\"#lig_link\").attr(\"href\",\"../../../dynadb/compound/id/\"+comp_id);\n",
    "                }\n",
    "                else {\n",
    "                    $(\"#lig_val\").html(\"None\");\n",
    "                    $(\"#lig_link\").hide();\n",
    "                }\n",
    "                $(\"#viewer_link\").attr(\"href\",\"../../../view/\"+dyn_id+\"/\"+pos_string);\n",
    "                $(\"#recept_link\").attr(\"href\",\"../../../dynadb/protein/id/\"+prot_id);\n",
    "                \n",
    "\n",
    "            } else {\n",
    "                if (plot_bclass != \"col-xs-12\"){\n",
    "                    $(\"#retracting_parts\").attr(\"class\",\"col-xs-12\");\n",
    "                    $(\"#info\").css({\"visibility\":\"hidden\",\"position\":\"absolute\",\"z-index\":\"-1\"});\n",
    "                } \n",
    "            }           \n",
    "        \"\"\")\n",
    "\n",
    "    return mysource\n",
    "\n",
    "def create_csvfile(options_path, recept_info,df):\n",
    "    \"\"\"\n",
    "    This function creates the CSV file to be donwloaded from web\n",
    "    \"\"\"\n",
    "    df_csv = df.copy()\n",
    "    df_csv.index.names = ['Interacting positions']\n",
    "\n",
    "    #Change dynX by full name of receptor, adding the dynid if there is more than a simulation for that receptor\n",
    "    df_csv.columns = df_csv.columns.map(lambda x: recept_info[x][13])\n",
    "\n",
    "    #Sorting by ballesteros Id's (helixloop column) and clustering order\n",
    "    df_csv['Interacting positions'] = df_csv.index\n",
    "    df_csv['helixloop'] = df_csv['Interacting positions'].apply(lambda x: re.sub(r'^(\\d)x',r'\\g<1>0x',x)) \n",
    "    df_csv = df_csv.sort_values([\"helixloop\"])\n",
    "\n",
    "    #Change jumplines by 'x' to avoid formatting problems\n",
    "    def new_index(cell):\n",
    "        cell = cell.replace('\\n\\n', '  ')\n",
    "        cell = cell.replace('\\n', 'x')\n",
    "        cell = cell.replace('xx', 'x')\n",
    "        return cell\n",
    "\n",
    "    df_csv['Interacting positions'] =  df_csv['Interacting positions'].apply(lambda x: new_index(x))\n",
    "    df_csv.index = df_csv['Interacting positions']\n",
    "\n",
    "    #Drop columns\n",
    "    df_csv.drop(columns = ['helixloop','Interacting positions'], inplace = True)\n",
    "\n",
    "    #Store dataframe as csv\n",
    "    df_csv.to_csv(path_or_buf = options_path+\"dataframe.csv\", float_format='%.1f')\n",
    "\n",
    "############\n",
    "## Variables\n",
    "############\n",
    "\n",
    "#itype sets\n",
    "itypes = set((\"wb\", \"wb2\", \"sb\",\"hp\",\"pc\",\"ps\",\"ts\",\"vdw\", \"hb\", \"hbbb\",\"hbsb\",\"hbss\",\"hbls\",\"hblb\",\"all\"))\n",
    "nolg_itypes = set((\"sb\",\"pc\",\"ts\",\"ps\",\"hbbb\",\"hbsb\",\"hbss\",\"hp\"))\n",
    "noprt_itypes = set((\"hbls\",\"hblb\"))\n",
    "ipartners = set((\"lg\",\"prt\",\"prt_lg\"))\n",
    "\n",
    "# Basepath for files\n",
    "#basepath = \"/home/daranda/gpcrmd_vagrant/shared/sites/files/Precomputed/get_contacts_files/\"\n",
    "basepath = \"/home/vitus/gpcrmd/cairo/files/Precomputed/get_contacts_files/\"\n",
    "\n",
    "typelist =  {\n",
    "    'sb' : 'salt bridge',\n",
    "    \"pc\" : 'pi-cation',\n",
    "    \"ps\" : 'pi-stacking',\n",
    "    'ts' : 't-stacking',\n",
    "    \"vdw\" : 'van der waals',\n",
    "    'hp' : 'hydrophobic',\n",
    "    \"hbbb\" : 'backbone to backbone HB',\n",
    "    \"hbsb\" : 'sidechain to backbone HB',\n",
    "    \"hbss\" : 'sidechain to sidechain HB',\n",
    "    \"hbls\" : 'ligand to sidechain HB',\n",
    "    \"hblb\" : 'ligand to backbone HB',\n",
    "    \"wb\" : 'water bridge',\n",
    "    \"wb2\" : 'extended water bridge',\n",
    "    \"hb\" : 'hydrogen bonds',\n",
    "    'all' : 'all types',\n",
    "}\n",
    "hb_itypes = {\n",
    "    \"hbbb\" : 'backbone to backbone',\n",
    "    \"hbsb\" : 'sidechain to backbone',\n",
    "    \"hbss\" : 'sidechain to sidechain',\n",
    "    \"hbls\" : 'ligand to sidechain',\n",
    "    \"hblb\" : 'ligand to backbone',\n",
    "}\n",
    "other_itypes = {\n",
    "    'hp' : 'hydrophobic',\n",
    "    'sb' : 'salt bridge',\n",
    "    \"pc\" : 'pi-cation',\n",
    "    \"ps\" : 'pi-stacking',\n",
    "    'ts' : 't-stacking',\n",
    "    \"vdw\" : 'van der waals',\n",
    "    \"wb\" : 'water bridge',\n",
    "    \"wb2\" : 'extended water bridge',\n",
    "\n",
    "}\n",
    "\n",
    "itypes_order = [\n",
    "    (\"Non-polar\", \n",
    "        (\n",
    "            (\"vdw\",\"van der waals\"),\n",
    "            ('hp', \"hydrophobic\")\n",
    "        )\n",
    "    ),\n",
    "    (\"Polar/Electrostatic\", \n",
    "        (\n",
    "            (\"hb\", \"hydrogen bond\"),\n",
    "            (\"wb\", \"water bridge\"),\n",
    "            (\"wb2\", \"extended water bridge\"),\n",
    "            ('sb', \"salt bridge\"),\n",
    "            (\"pc\", \"pi-cation\")\n",
    "        )\n",
    "    ),\n",
    "    (\"Stacking\",\n",
    "        (\n",
    "            (\"ps\", \"pi-stacking\"),\n",
    "            ('ts', \"t-stacking\")\n",
    "        )\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.0004508495330810547 seconds after dicts ---\n",
      "Computing contmaps inputs for wb-prt_lg\n",
      "--- 1.4391746520996094 seconds after loading files ---\n",
      "--- 2.0752971172332764 seconds after filtering ligand ---\n",
      "--- 2.152259111404419 seconds end---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "itype=\"wb\"\n",
    "ligandonly=\"prt_lg\"\n",
    "\n",
    "#Declaring dictionaries with types\n",
    "#basepath = \"/home/daranda/gpcrmd_vagrant/shared/sites/files/Precomputed/get_contacts_files/\"\n",
    "basepath = \"/home/vitus/gpcrmd/cairo/files/Precomputed/get_contacts_files/\"\n",
    "typelist =  {\n",
    "    'sb' : 'salt bridge',\n",
    "    \"pc\" : 'pi-cation',\n",
    "    \"ps\" : 'pi-stacking',\n",
    "    'ts' : 't-stacking',\n",
    "    \"vdw\" : 'van der waals',\n",
    "    'hp' : 'hydrophobic',\n",
    "    \"hbbb\" : 'backbone to backbone HB',\n",
    "    \"hbsb\" : 'sidechain to backbone HB',\n",
    "    \"hbss\" : 'sidechain to sidechain HB',\n",
    "    \"hbls\" : 'ligand to sidechain HB',\n",
    "    \"hblb\" : 'ligand to backbone HB',\n",
    "    \"wb\" : 'water bridge',\n",
    "    \"wb2\" : 'extended water bridge',\n",
    "    \"hb\" : 'hydrogen bonds',\n",
    "    'all' : 'all types',\n",
    "}\n",
    "hb_itypes = {\n",
    "    \"hbbb\" : 'backbone to backbone',\n",
    "    \"hbsb\" : 'sidechain to backbone',\n",
    "    \"hbss\" : 'sidechain to sidechain',\n",
    "    \"hbls\" : 'ligand to sidechain',\n",
    "    \"hblb\" : 'ligand to backbone',\n",
    "}\n",
    "other_itypes = {\n",
    "    'hp' : 'hydrophobic',\n",
    "    'sb' : 'salt bridge',\n",
    "    \"pc\" : 'pi-cation',\n",
    "    \"ps\" : 'pi-stacking',\n",
    "    'ts' : 't-stacking',\n",
    "    \"vdw\" : 'van der waals',\n",
    "    \"wb\" : 'water bridge',\n",
    "    \"wb2\" : 'extended water bridge',\n",
    "\n",
    "}\n",
    "\n",
    "itypes_order = [\n",
    "    (\"Non-polar\", \n",
    "        (\n",
    "            (\"vdw\",\"van der waals\"),\n",
    "            ('hp', \"hydrophobic\")\n",
    "        )\n",
    "    ),\n",
    "    (\"Polar/Electrostatic\", \n",
    "        (\n",
    "            (\"hb\", \"hydrogen bond\"),\n",
    "            (\"wb\", \"water bridge\"),\n",
    "            (\"wb2\", \"extended water bridge\"),\n",
    "            ('sb', \"salt bridge\"),\n",
    "            (\"pc\", \"pi-cation\")\n",
    "        )\n",
    "    ),\n",
    "    (\"Stacking\",\n",
    "        (\n",
    "            (\"ps\", \"pi-stacking\"),\n",
    "            ('ts', \"t-stacking\")\n",
    "        )\n",
    "    )\n",
    "]\n",
    "print(\"--- %s seconds after dicts ---\" % (time.time() - start_time))\n",
    "\n",
    "# Creating set_itypes and loading data\n",
    "if itype == \"all\":\n",
    "    set_itypes =  set((\"sb\", \"pc\", \"ps\", \"ts\", \"vdw\", \"hp\", \"hb\", \"hbbb\", \"hbsb\", \"hbss\", \"wb\", \"wb2\", \"hbls\", \"hblb\", \"all\"))\n",
    "    df_raw = None\n",
    "    for itype_df in set_itypes:\n",
    "        df_raw_itype = pd.read_csv(str(basepath + \"contact_tables/compare_\" + itype_df + \".tsv\"), sep=\"\\s+\")\n",
    "        df_raw = pd.concat([df_raw, df_raw_itype])\n",
    "else: \n",
    "    set_itypes = { itype }\n",
    "    df_raw = pd.read_csv(str(basepath + \"contact_tables/compare_\" + itype + \".tsv\"), sep=\"\\s+\")\n",
    "\n",
    "print(\"Computing contmaps inputs for %s-%s\" % (itype, ligandonly))\n",
    "    \n",
    "#Loading files\n",
    "compl_data = json_dict(str(basepath + \"compl_info.json\"))\n",
    "flare_template = json_dict(basepath + \"template.json\")\n",
    "\n",
    "print(\"--- %s seconds after loading files ---\" % (time.time() - start_time))\n",
    "\n",
    "# Adapting to Mariona's format\n",
    "df_original = adapt_to_marionas(df_raw)\n",
    "\n",
    "# If is working with total frequency and all interaction partners, create a new flareplot template file\n",
    "if (itype=='all') and (ligandonly=='prt_lg'):\n",
    "    flareplot_template(df_original, basepath)\n",
    "\n",
    "# Filtering out non-ligand interactions if option ligandonly is True\n",
    "if ligandonly == \"lg\":\n",
    "    ligandfilter = df_original['Position'].str.contains('Ligand')\n",
    "    df_original = df_original[ligandfilter]\n",
    "elif ligandonly == \"prt\":\n",
    "    ligandfilter = ~df_original['Position'].str.contains('Ligand')\n",
    "    df_original = df_original[ligandfilter]\n",
    "\n",
    "print(\"--- %s seconds after filtering ligand ---\" % (time.time() - start_time))\n",
    "\n",
    "#Filter out same helix interactions\n",
    "df_original = filter_same_helix(df_original)\n",
    "\n",
    "#Removing low-frequency contacts\n",
    "df_original = filter_lowfreq(df_original, itype)\n",
    "    \n",
    "#Add \\n between GPCR nomenclatures, to show it multiline in the heatmap axis   \n",
    "df_original = set_new_axis(df_original)\n",
    "\n",
    "# Excluding non-standard (and by standard I'm saying \"made by us\") simulations\n",
    "(df_complete, df_standard) = split_by_standard(df_original, compl_data)\n",
    "print(\"--- %s seconds end---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/protwis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-12bf6c32b267>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#If doesn't exists yet, create base input folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moptions_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%scontmaps_inputs/%s/%s/%s/\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstnd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mligandonly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# If there are no interactions with this ligandonly-itype combination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/protwis'"
     ]
    }
   ],
   "source": [
    "for (stnd,df) in ((\"cmpl\", df_complete), (\"stnd\", df_standard)):\n",
    "    \n",
    "    #If doesn't exists yet, create base input folder\n",
    "    options_path = \"%scontmaps_inputs/%s/%s/%s/\" %(basepath, itype, stnd, ligandonly)\n",
    "    os.makedirs(options_path, exist_ok=True)\n",
    "\n",
    "    # If there are no interactions with this ligandonly-itype combination\n",
    "    if df.empty:\n",
    "        print(\"No interactions avalible for this molecular partners and interaction type: %s and %s\" % (ligandonly, itype) )\n",
    "        continue\n",
    "    print(\"--- %s seconds at start---\" % (time.time() - start_time))\n",
    "\n",
    "    # Setting columns 'Position', 'leter+Position1' and 'leter+Position2' in df for jsons files\n",
    "    df_columned = new_columns(df, itype)\n",
    "    df_columned.to_pickle(options_path+\"dataframe_customflareplot.pkl\")\n",
    "    \n",
    "    #Dropping away Position columns, once they are not needed\n",
    "    df_drop = df.drop(['Position1','Position2'], 1)\n",
    "    \n",
    "    # Stack matrix (one row for each interaction pair and dynamic. Colnames are position, dynid and itypes)\n",
    "    df_ts = stack_matrix(df_drop, set_itypes)\n",
    "    \n",
    "    #Dropping away non main-type interaction rows.\n",
    "    df_drop = df_drop[df_drop['itype'] == itype]\n",
    "    df_drop.drop('itype',axis=1, inplace=True)\n",
    "    print(\"--- %s seconds after removing_entries-and_freqsdict---\" % (time.time() - start_time))\n",
    "\n",
    "    # Set position as row index of the dataframe\n",
    "    df_drop = df_drop.set_index('Position')    \n",
    "\n",
    "    # Labels for dendogram\n",
    "    dendlabels_dyns = list(df_drop.columns)\n",
    "    \n",
    "    # Making one-simulation flareplots. Only done in cmpl to avoid repeating same Simulations\n",
    "    if stnd == \"cmpl\":\n",
    "        sim_jsons_path = '%scontmaps_inputs/%s/simulation_jsons/%s/' % (basepath, itype, ligandonly)\n",
    "        dyn_flareplots(df_columned, sim_jsons_path, dendlabels_dyns, itype, flare_template)\n",
    "    \n",
    "    #Computing frequency matrix\n",
    "    dend_matrix = frequencies(df_drop)\n",
    "    print(\"--- %s seconds after frequencty matrix---\" % (time.time() - start_time))\n",
    "    (recept_info,recept_info_order,df_ts,dyn_gpcr_pdb,index_dict)=improve_receptor_names(df_ts,compl_data)\n",
    "    \n",
    "    # Apending column with PDB ids\n",
    "    pdb_id = recept_info_order['pdb_id']\n",
    "    df_ts['pdb_id'] = df_ts['Id'].apply(lambda x: recept_info[x][pdb_id])\n",
    "    \n",
    "    #Storing dataframe with results in a CSV file, downloadable from web\n",
    "    create_csvfile(options_path, recept_info,df_drop)\n",
    "    print(\"--- %s seconds after csv---\" % (time.time() - start_time))\n",
    "\n",
    "    # Add residue types to dataframe\n",
    "    df_ts = add_restypes(df_ts, compl_data, recept_info, recept_info_order)\n",
    "    print(\"--- %s seconds after add_restypes---\" % (time.time() - start_time))\n",
    "\n",
    "    #Preparing dendrogram folders and parameters\n",
    "    dendfolder = options_path + \"dendrograms/\" \n",
    "    os.makedirs(dendfolder, exist_ok = True)\n",
    "    dend_height = int( int(df.shape[1]) * 17)\n",
    "    dend_width = 450\n",
    "\n",
    "\n",
    "    print(\"--- %s seconds  before dendrogram---\" % (time.time() - start_time))\n",
    "    # Computing several dendrograms and corresponding json files\n",
    "    for cluster in [2]:\n",
    "        print(\"\\tcomputing dendrogram: \" + str(cluster) + \" clusters. \" + str(time.time() - start_time) +  \" seconds\")\n",
    "        dendfile = (\"%s%iclusters_dendrogram.html\" % (dendfolder, cluster))\n",
    "        (dyn_dend_order, clustdict) = dendrogram_clustering(dend_matrix, dendlabels_dyns, dend_height, dend_width, dendfile, cluster, recept_info, recept_info_order)\n",
    "        # Write dynamicID-cluster dictionary on a json\n",
    "        clustdir = \"%sflarejsons/%sclusters/\" % (options_path, cluster)\n",
    "        os.makedirs(clustdir, exist_ok= True)\n",
    "        with open(clustdir + \"clustdict.json\", 'w') as clusdictfile:\n",
    "            dump(clustdict, clusdictfile, ensure_ascii=False, indent = 4)\n",
    "\n",
    "        #Jsons for the flareplots of this combinations of clusters\n",
    "        print(\"\\tcomputing jsons: \" + str(cluster) + \" clusters. \"  + str(time.time() - start_time) +  \"seconds\")\n",
    "        flareplot_json(df_columned, clustdict, clustdir, flare_template)\n",
    "        print(\"--- %s seconds  after dendrogram---\" % (time.time() - start_time))\n",
    "    \n",
    "    #Store Simulation names and dyn on file\n",
    "    create_dyntoname_file(dyn_dend_order, recept_info, recept_info_order, options_path)\n",
    "    \n",
    "    for rev in [\"norev\"]:\n",
    "\n",
    "        # If rev option is setted to rev, duplicate all lines with the reversed-position version \n",
    "        #(4x32-2x54 duplicates to 2x54-4x32)\n",
    "        if rev == \"rev\":\n",
    "            df_ts_rev = reverse_positions(df_ts)\n",
    "        else:\n",
    "            df_ts_rev = df_ts\n",
    "        \n",
    "        df_ts_rev = sort_simulations(df_ts_rev, dyn_dend_order)\n",
    "        print(\"--- %s seconds sorting---\" % (time.time() - start_time))\n",
    "\n",
    "        #Taking some variables for dataframe slicing\n",
    "        max_columns = 45\n",
    "        pairs_number = df_drop.shape[0]\n",
    "        inter_number = df_ts_rev.shape[0]\n",
    "        inter_per_pair = (inter_number/pairs_number)/2 if rev == \"rev\" else inter_number/pairs_number\n",
    "        number_heatmaps = ceil((inter_number/inter_per_pair)/max_columns)\n",
    "        \n",
    "        #Create heatmap folder if not yet exists\n",
    "        heatmap_path_jupyter = \settings.MEDIA_ROOT + "Precomputed/get_contacts_files/contmaps_inputs/%s/%s/%s/heatmaps/%s/\" % (itype,stnd,ligandonly,rev)\n",
    "        heatmap_path = \"%sheatmaps/%s/\" % (options_path,rev)\n",
    "        os.makedirs(heatmap_path, exist_ok=True)\n",
    "\n",
    "        #Saving dataframe for future uses in customized heatmaps\n",
    "        df_ts_rev.to_pickle(heatmap_path+\"dataframe_for_customized.pkl\")\n",
    "        \n",
    "        #Make heatmaps each 50 interacting pairs\n",
    "        div_list = []\n",
    "        heatmap_filename_list = []\n",
    "        number_heatmap_list = []\n",
    "        prev_slicepoint = 0\n",
    "        for i in range(1,number_heatmaps+1):\n",
    "            number_heatmap_list.append(str(i))\n",
    "\n",
    "            #Slice dataframe. Also definig heigth and width of the heatmap\n",
    "            slicepoint = int(i*inter_per_pair*max_columns)\n",
    "            if i == number_heatmaps:\n",
    "                df_slided = df_ts_rev[prev_slicepoint:]\n",
    "            else:\n",
    "                df_slided = df_ts_rev[prev_slicepoint:slicepoint]\n",
    "            w = int(df_slided.shape[0]/inter_per_pair*20+40)\n",
    "            prev_slicepoint = slicepoint\n",
    "            h=dend_height\n",
    "\n",
    "            # Define bokeh figure and hovertool\n",
    "            \n",
    "            hover = create_hovertool(itype, itypes_order, hb_itypes, typelist)\n",
    "            mysource,p = define_figure(w, h, df_slided, hover, itype)\n",
    "            print(\"--- %s seconds create_figure---\" % (time.time() - start_time))\n",
    "\n",
    "            # Creating javascript for side-window\n",
    "            mysource = select_tool_callback(recept_info, recept_info_order, dyn_gpcr_pdb, itype, typelist, mysource)\n",
    "\n",
    "            # Extract bokeh plot components and store them in lists\n",
    "            script, div = components(p)\n",
    "            div_list.append(div.lstrip())\n",
    "            heatmap_filename = \"%s%iheatmap.html\" % (heatmap_path_jupyter,i)\n",
    "            heatmap_filename_list.append(heatmap_filename)\n",
    "\n",
    "            # Write heatmap on file\n",
    "            heatmap_filename = \"%s%iheatmap.html\" % (heatmap_path,i)\n",
    "            with open(heatmap_filename, 'w') as heatmap:\n",
    "                heatmap.write(script)\n",
    "\n",
    "        # Write lists as python variables in a python file\n",
    "        variables_file = \"%svariables.py\" % (heatmap_path)\n",
    "        with open(variables_file, 'w') as varfile:\n",
    "            varfile.write(\"div_list = [\\'%s\\']\\n\" % \"\\',\\'\".join(div_list))\n",
    "            varfile.write(\"heatmap_filename_list = [\\'%s\\']\\n\" % \"\\',\\'\".join(heatmap_filename_list))\n",
    "            varfile.write(\"number_heatmaps_list = [\\'%s\\']\\n\" % \"\\',\\'\".join(number_heatmap_list))\n",
    "\n",
    "            #Show figures in notebook\n",
    "    reset_output()        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
